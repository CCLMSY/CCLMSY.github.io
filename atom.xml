<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>CCLMSY💫</title>
  
  
  <link href="https://www.cclmsy.cc/atom.xml" rel="self"/>
  
  <link href="https://www.cclmsy.cc/"/>
  <updated>2025-09-30T05:26:36.003Z</updated>
  <id>https://www.cclmsy.cc/</id>
  
  <author>
    <name>深翼💫</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>推免回忆录</title>
    <link href="https://www.cclmsy.cc/posts/tm.html"/>
    <id>https://www.cclmsy.cc/posts/tm.html</id>
    <published>2025-09-23T16:00:00.000Z</published>
    <updated>2025-09-30T05:26:36.003Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>谨以本篇，记录我在夏令营和预推免期间，在部分院校的经历、想法和感受。</p><ul><li>缩写/术语参考：<a href="https://csbaoyan.top/%E4%BF%9D%E7%A0%94%E6%8C%87%E5%8D%97/%E4%BF%9D%E7%A0%94%E9%BB%91%E8%AF%9D">保研黑话|CSWiki</a></li><li>由于部分院校签署了保密协议，所有内容均不涉及具体考核试题、面试问题等。</li><li>所有评价仅个人看法，不代表实际情况，不供参考。</li></ul><h3 id="录取"><a href="#录取" class="headerlink" title="录取"></a>录取</h3><p>923上午接补录，上岸梦校！</p><p>夏令营始于BUAA SE，拟录取终于BUAA SE。<br>有始，有终。</p><p><img src="https://source.cclmsy.cc/posts/others/buaase_offer.png" alt="录取"></p><h3 id="BG"><a href="#BG" class="headerlink" title="BG"></a>BG</h3><ul><li>本科：四非高rk，CET6&lt;480</li><li>竞赛：ACM省银、ICPC区域铜、ICPC邀请铜</li><li>科研：无专利论文，深度学习入门，论文复现</li><li>项目：一个Unity游戏、一个插件、4个校创</li><li>兴趣方向：人工智能（生成式人工智能，多模态大模型/CV，etc.） &gt; 软件工程、具身智能 &gt; Others</li><li>意愿：计科&gt;软工≈AI；学硕=专硕&gt;工程硕&gt;直博</li></ul><p>不考虑直博一方面是因为科研经历太少，风险太大；另一方面也是想早点出去赚钱。</p><p>一开始只想做AI+软件工程/CV相关的方向。<br>九月中参加了一个具身智能方面的会议，引起了我对这个方向的兴趣，再加上高中时候就参加过机器人的创客竞赛，觉得这个方向也不错（虽然最终也不是）。</p><h2 id="夏令营"><a href="#夏令营" class="headerlink" title="夏令营"></a>夏令营</h2><p>今年诸多院校开始调整夏令营，包括取消夏令营、线上夏令营、不发offer之类。<br>好在大部分还是有这么个形式，可以多了解一些院校和导师，或体验一下考核。</p><p>海投985和硬核211，考虑到竞争压力，基本上投的都是专硕。</p><div class="table-container"><table><thead><tr><th style="text-align:center">学校/院系</th><th style="text-align:center">结果</th></tr></thead><tbody><tr><td style="text-align:center">北京航空航天大学 软件学院</td><td style="text-align:center">不发offer</td></tr><tr><td style="text-align:center">浙江大学 软件学院</td><td style="text-align:center">普营</td></tr><tr><td style="text-align:center">北京邮电大学 计算机学院</td><td style="text-align:center">欢迎报考</td></tr><tr><td style="text-align:center">北京交通大学 计算机学院</td><td style="text-align:center">放弃入营</td></tr><tr><td style="text-align:center">中山大学 软件学院</td><td style="text-align:center">默拒</td></tr></tbody></table></div><h3 id="北京航空航天大学-软件学院"><a href="#北京航空航天大学-软件学院" class="headerlink" title="北京航空航天大学 软件学院"></a>北京航空航天大学 软件学院</h3><blockquote><p>位于首都的梦校，软件工程第五轮评估A+，和清北坐一桌。</p></blockquote><p>暑期学校活动，不发offer，极稀有的线上机考入营。<br>机考不筛人，1000+人同台竞技（最终有AC的大概600+），一共7题，前42名参加线下营。<br>我5题+手快，顺利入营，也是第一个营。</p><p>线下营7/3~7/4，入营大礼包给了一件ANTA的T恤、北航手提包、流体熊钥匙扣和飞机徽章。<br>第1天中午报道领取大礼包，下午参观校史馆、博物馆、实验室；<br>第2天上午听各位老师的学术报告，下午分组讨论。</p><p><img src="https://source.cclmsy.cc/posts/others/buaase_xly1.jpg" alt="BUAA流体熊钥匙扣"></p><p>最终根据分组讨论的表现，每个组会评5个奖。<br>整个参与过程的体验很好，老师们都很友善。<br>也是我推免过程中唯一有伴手礼的院校（人文关怀这一块）。</p><h3 id="浙江大学-软件学院"><a href="#浙江大学-软件学院" class="headerlink" title="浙江大学 软件学院"></a>浙江大学 软件学院</h3><blockquote><p>坐落于家乡的梦校，新校区建成，附加浙大Title，一举成为今年推免最热院校之一。</p></blockquote><p>今年太热门了，老师的选择也很多，四非很难套到老师。<br>夏令营入营后，给几个老师致邮均未获回复。</p><p>大模型与工业智能营（共8个营）钉钉群里有680+个人，可见规模之大。<br>今年形式上没变，7/1~7/10线上营，在若干题目中选做一个项目，题目可能设置1~3阶段（不过目测要优营得完整完成）。<br>不评卓越营员（offer）了，宣称优营率10%左右。<br>四非鼠鼠必须要取得优营才能拿到预推免入场券。</p><p>BUAA SE夏令营回来才开始着手课题，一半的时间还是比较紧张。<br>最后完成了某题的全部阶段，但是并没有做得很好，最后也没能拿到优营。</p><h3 id="北京邮电大学-计算机学院"><a href="#北京邮电大学-计算机学院" class="headerlink" title="北京邮电大学 计算机学院"></a>北京邮电大学 计算机学院</h3><blockquote><p>两电一邮的邮，计算机通信实力不俗，中9水平，冲。</p></blockquote><p>夏令营是组面，填报3个组，入了某组面试。</p><p>面试就是正常的BG面、英语面和专业面，拷打强度不高。<br>由于夏令营不能公布位次等，最终收获了“欢迎报考”，根据预推免反馈应该是中高位次。</p><h3 id="北京交通大学-计算机学院"><a href="#北京交通大学-计算机学院" class="headerlink" title="北京交通大学 计算机学院"></a>北京交通大学 计算机学院</h3><blockquote><p>次9水平，稳。</p></blockquote><p>据说是参观交流营，不发offer。</p><p>入营，根据小道消息，确实和录取不挂钩；<br>再加上已经订好机票了，因此放弃参营。</p><h3 id="中山大学-软件学院"><a href="#中山大学-软件学院" class="headerlink" title="中山大学 软件学院"></a>中山大学 软件学院</h3><blockquote><p>名校，但是软工第五轮评估B，但是名校，冲了。<br>我小学阶段最好的天才朋友在这里就读。</p></blockquote><p>报名夏令营后会收到一封论文研读的邮件，要求n篇论文中选择1篇研读完，以组会分享的形式录制视频发邮件反馈。<br>据说“作为筛选入营名单的参考材料之一，不计入考核”。</p><p>选了，读了，做了PPT，录了视频，发了邮件，填了问卷，收到了自动回复邮件……<br>……<br>视频邮件至今都是未读状态，也没有明确的拒绝入营。</p><p>最寒心的一集。</p><p><img src="https://source.cclmsy.cc/posts/others/sysuse_unread.png" alt="中山大学软件学院邮件未读"></p><h3 id="线上营"><a href="#线上营" class="headerlink" title="线上营"></a>线上营</h3><blockquote><p>有人天真的以为这是一场巨大的服从性测试，只要全程听下来就能提升预推免入面概率。<br>最后入线上宣讲营的院校，预推免都没入面……</p></blockquote><p>这部分没什么好讲的，都是点击就送不筛人，也就是开个宣传讲座或者学术报告之类的让你参加。</p><p>包括：SYSU AI、SDU CS/SE、SCUT等</p><h2 id="预推免"><a href="#预推免" class="headerlink" title="预推免"></a>预推免</h2><blockquote><p>夏令营是缩水的，推免名额是增加的，招生指标是不变的，保研是越来越卷的，四非鼠鼠是越来越难入面的。</p></blockquote><p>由于夏令营大幅缩水、推免名额增加，大量92大佬涌入预推免，压缩了普通院校的鼠鼠们的生存空间。<br>同等BG下，以往的可稳院校变得不稳了，可冲院校变得更难冲了。</p><p>预推免也主打一个海投，几乎把中等211以上的院校都投了一轮。</p><div class="table-container"><table><thead><tr><th style="text-align:center">学校/院系</th><th style="text-align:center">结果</th></tr></thead><tbody><tr><td style="text-align:center">苏州大学 计算机学院</td><td style="text-align:center">放弃offer</td></tr><tr><td style="text-align:center">合肥工业大学 计算机学院</td><td style="text-align:center">放弃wl</td></tr><tr><td style="text-align:center">华东师范大学 卓越工程师学院</td><td style="text-align:center">放弃入面</td></tr><tr><td style="text-align:center">东北大学 软件学院</td><td style="text-align:center">放弃入面</td></tr><tr><td style="text-align:center">北京邮电大学 计算机学院</td><td style="text-align:center">被等额推荐创死</td></tr><tr><td style="text-align:center">天津大学 智能与计算学部（软件学院）</td><td style="text-align:center">第三批wl</td></tr><tr><td style="text-align:center">北京航空航天大学 软件学院</td><td style="text-align:center">高位wl上岸</td></tr></tbody></table></div><h3 id="苏州大学-计算机学院"><a href="#苏州大学-计算机学院" class="headerlink" title="苏州大学 计算机学院"></a>苏州大学 计算机学院</h3><blockquote><p>211，计算机第五轮评估A，稳。</p></blockquote><p>Bar不高，两批线下机试可选。<br>机试3小时10题，Leetcode风格，在一个cpp文件里补全函数，框架都给出了。<br>C++学的扎实的话随便过，我第一批上午场100分钟AK提前出场。</p><p>弱com，过了机试就可以联系导师，具体考核看导师，NLP组肯定是要硬核面试的。<br>AK出场后，联系了非NLP组的老师，做NLP和多模态大模型的，方向90+%match，水平很好，很年轻很聊得来。<br>当时还怀揣着冲击梦校的想法，首次通话就和老师明确说明了自己的想法和入营情况，老师还是给我发了offer。</p><p>经常保研的同学肯定知道，手上有offer和没有offer，心态是截然不同的，这份offer也成为了我冲击强校的底气。<br>虽然最终没有去苏大，也因为候补上岸晚，23号才鸽，但是真的很感谢老师的认可和支持！！！</p><p>（也听说苏大超发了offer，希望没有影响老师招生QwQ）</p><h3 id="合肥工业大学-计算机学院"><a href="#合肥工业大学-计算机学院" class="headerlink" title="合肥工业大学 计算机学院"></a>合肥工业大学 计算机学院</h3><blockquote><p>211，计算机强校，不输985，稳。</p></blockquote><p>线上面试，纯BG面，拷打强度不高。<br>因为已经有苏大导师的offer，面试就重在参与了。<br>后来收到消息，接受了复试通知之后还要进行2轮面试…</p><p>面试分组是不透明的，成绩/排名是不公布的，发短信通知是养鱼的，电话是只打给小部分人的。</p><p>也没联系导师，没什么好说的，跑路！</p><h3 id="东北大学"><a href="#东北大学" class="headerlink" title="东北大学"></a>东北大学</h3><blockquote><p>位于沈阳的985，曾经打过铁的地方。</p></blockquote><p>FCFS，由于投递很晚，第四批才入面。</p><p>由于和BUAA SE冲突，也没联系导师，遂跑路。</p><h3 id="北京邮电大学-计算机学院-1"><a href="#北京邮电大学-计算机学院-1" class="headerlink" title="北京邮电大学 计算机学院"></a>北京邮电大学 计算机学院</h3><blockquote><p>两电一邮的邮，计算机通信实力不俗，中9水平，通信实力很强，但不是我的兴趣方向。</p></blockquote><p>纯弱com，由于已经经过夏令营面试，没有进一步的考核了。</p><p>9月18日凌晨接到通知，今年招生名额大幅减少，且导师等额推荐，如果被推荐还鸽会直接导致老师少一个招生指标。<br>我的位次应该比较高，说是可能可以争取到一个名额来推荐我，让我9点之前做出决定。<br>虽然海投，但是我确实不是那种为了offer就随意养鱼，特别是这种影响导师招生的情况。</p><p>由于手上没有985offer，bupt的Title也确实能打，那一晚我就不得不面临2个选择：</p><ol><li>接受推荐，让老师去争取，如果争取到就会：<ul><li>放弃冲击985的机会</li><li>为了Title去读一个自己不感兴趣的方向 </li></ul></li><li>完全放弃，去赌手上还攥着的一个末位wl、第三批天大智算和BUAA SE。</li></ol><p>一夜未眠，还是选择了接受，只是后来确实也没有争取到。<br>几天后又告诉我有直博的机会，但考虑到方向不match，且自己没有直博意愿，遂放弃。</p><p>塞翁失马焉知非福。<br>如果真的有机会，我当天就退了机票结束保研，去读一个不感兴趣的方向后悔3年，也没有被BUAA SE录取的可能了。</p><h3 id="华东师范大学-软件学院-卓越工程师学院"><a href="#华东师范大学-软件学院-卓越工程师学院" class="headerlink" title="华东师范大学 软件学院/卓越工程师学院"></a>华东师范大学 软件学院/卓越工程师学院</h3><blockquote><p>985，软件工程第五轮评估A+，卓工的硕是工程硕（联培）</p></blockquote><p>在华师读硕士的大佬学长推荐了一个导师，做代码大模型的。<br>但发邮件时写了“多模态大模型”，导师第一次表示方向不match（其实我是想做大模型的，具体方向不重要）。<br>经过二次邮件诚挚解释后，老师未计前嫌，给我打了电话。<br>老师人很好交流，沟通交流后表示欢迎报名。<br>srds，最终因为BG太弱没有入面//</p><p>卓工16号接到入面通知，虽然我没有选“工程硕博专项”，但实际上还是联培。<br>鉴于当时没有985offer，就打算去试试。<br>通知19~20号面试，当天就把火车票订了，后面又订了飞去北京面试的机票。</p><p>结果出发的前一晚18号，接到天大智算的面试通知。<br>考虑到不想去联培，遂放弃，追梦天大。</p><h3 id="天津大学-智能与计算学部（软件学院）"><a href="#天津大学-智能与计算学部（软件学院）" class="headerlink" title="天津大学 智能与计算学部（软件学院）"></a>天津大学 智能与计算学部（软件学院）</h3><blockquote><p>985，软件工程第五轮评估A-，冲。</p></blockquote><p>本来第二批计算机过初筛了，结果发入群通知的那晚完全没看Google邮箱。<br>第二天看到之后，进群填表晚了半小时，成功把自己坑死了……</p><p>好在追加了志愿，报了智算的软工，第三批也过了初筛，进入线上机试。<br>机试2小时5道题，前4题很常规，第5题稍微用到点算法，也是1小时AK。<br>18号收到入面通知，紧急退票改签，19号飞天津，中途中转大连还吃了顿海鲜//</p><p>预推免20号全天。<br>上午线下机试，和线上一样2小时5题，也是1小时AK。<br>下午面试纯BG面，</p><p>最终第三批高位wl，不过据说天大超发offer，补录也应该从第一批开始，因此基本寄了。</p><h3 id="北京航空航天大学-软件学院-1"><a href="#北京航空航天大学-软件学院-1" class="headerlink" title="北京航空航天大学 软件学院"></a>北京航空航天大学 软件学院</h3><blockquote><p>位于首都的梦校，软件工程第五轮评估A+，和清北坐一桌。<br>我是BUAA SE的坚定拥护者。</p></blockquote><p>全国独一份，为像我这种弱BG的ACMer提供机会的院校。</p><p>预推免官网12号才发通知，也没有上<a href="https://ddl.csbaoyan.top/">计算机保研DDL</a>，得自己关注。<br>北航软院的教务效率极高，问答文档和审核文档更新非常及时，也足够人性化（不会因为差几分钟就拒绝审核）。</p><p>复试不筛人（点击报名就送），入面依靠线下机试筛人，机试去了200人左右（硕+博）。</p><p>线下机试一共8题，20×3+10×3+5×2分值，1.5个小时，纯C语言编程。<br>我大概1小时多一点，写了6题，90分，最终也是被机试带飞了。<br>T7T8用纯C写确实硬核，T7全场只过了2个，T8防AK。<br>斩杀线应该在70分左右，入面120人左右。</p><p>分到第二天上午面试，面试前通宵复习了。<br>北航软院的面试是我参加过最硬核的面试，英语+数学+专业+BG，360°全方位无死角拷打。</p><ul><li>英语面问了2个问题，有一个前一天准备了文稿但是没背，被问到的时候贼悔；</li><li>数学面问了2个问题，比较基础，没有考特别深入的内容（毕竟不是数学专业）；</li><li>专业面问了4个科目，最擅长的科目没问，几乎打在盲点上，被问穿了；</li><li>BG面主要陈述竞赛、科研经历和项目经历，不过老师们似乎更关注科研和项目（打A确实也没什么好问的）。</li></ul><p>思政和英语是同一个老师问的，老师很温柔，提醒我不要紧张（但是鼠鼠压力真的很大）。<br>数学面提问的老师也很好，回答完之后会鼓励说“答得很好”，在专业面问题的时候也有提示。<br>这两位老师真的都很好，是那种会让我感觉不来好可惜的QwQ。</p><p>面试确实寄完了，但是被机试带飞了，专硕高位候补。<br>今年学硕42录23，录取线划到231.2；专硕64录23，录取线划到240.4，比专硕还高10分QwQ。</p><p>看到名单的时候悔死，如果报学硕已经上岸了，专硕按照去年情况（只鸽1个）是候补不到我的。<br>如果因为自己犯蠢把自己害死真的会T^T。</p><p>923上午接补录，上岸梦校！</p><p>夏令营始于BUAA SE，拟录取终于BUAA SE。<br>有始，有终。</p><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><h3 id="关于感受"><a href="#关于感受" class="headerlink" title="关于感受"></a>关于感受</h3><p>夏令营结束之后还没有特别着急，觉得自己到了预推免机会还很多，7~8月空档期还顺便去实了个习。<br>结果预推免填报完，慢慢开始发现事情不对劲起来了。</p><p>今年形势巨变，夏令营缩水，推免名额增加，大量92大佬涌入预推免。<br>根据以往的经验，我能拿到offer的院校，很多投递之后甚至都没有入营入面。</p><p>9月，9号-16号，这一周是我最煎熬的日子。<br>大部分院校预推免报名截止时间到了，可是我的收件箱始终都是空空如也。</p><p>当时也不知道BUAA SE能入复试。<br>我每一天都在不停的确认报名是否审核通过、其他同学有没有收到入面邮件。<br>苏大很好，苏大的老师也很好，可是我始终抱着去往985的期望，真的不甘心止步于此。<br>每当夜里想起，觉得很难给自己这三年的努力一个满意交待，就会整晚睡不着觉。<br>但好在17号开始陆续收到院校的入面通知，才缓解焦虑的情绪，逐渐调整好状态。</p><p>没报保研辅导机构，绿群从5月被lru后就没进过，全程就只能自己瞎琢磨。</p><p>我陶瓷导师很少，更少在入营/入复试之前联系导师。<br>联系到的每个导师，我也很慎重的给老师承诺，只和一个老师说了“我一定会来”，虽然没有候补上。<br>我也会在第一次沟通时，表明我手上的offer以及入面和夏令营情况。<br>这就导致我无法衷心选择诸如HUST这样的纯弱com院校，面对BUPT的等额推荐机会时也纠结了一通宵。<br>这种方式无疑是会让我失去一些机会的，但也让我避免了很多不必要的麻烦。</p><p>期间也犯了很多次愚蠢的低级错误，疯狂踩雷，有被自己狠狠蠢到：</p><ol><li>陶瓷导师，姓氏未改/方向不贴切</li><li>给A校发的材料里包含了报考B校的校名</li><li>面试未准备多份材料</li><li>缺乏面试经验，表现极其紧张</li><li>未及时查看邮件，错过重要通知</li><li>错过了国家奖学金申请</li><li>etc.</li></ol><p>最终还是在磕磕绊绊跌跌撞撞中，幸运的上岸了梦校。</p><h3 id="关于接下来想做的事情"><a href="#关于接下来想做的事情" class="headerlink" title="关于接下来想做的事情"></a>关于接下来想做的事情</h3><ul><li>gap到国庆结束，好好放松一段时间，调整一下状态</li><li>开始着手毕业设计，争取能早点完成</li><li>空余时间刷CET6&gt;=550，争取入学之后免修英语</li><li>提前研读一下组内论文，学习一些相关技术</li><li>健身！本科期间确实缺乏运动，胖了xx斤</li><li>更新<a href="https://cclmsy.cc/handwritten">手写信</a>，记录一些重要的人和事</li><li>fix/optimize：博客和小项目</li></ul><h3 id="祝愿"><a href="#祝愿" class="headerlink" title="祝愿"></a>祝愿</h3><p>谢谢你看到这里，也祝愿你前程似锦！</p><!-- ## 推文### 保研心得> 在组织基本面良好的前提下，通过强化核心优势形成竞争力。——反木桶原理尽管保研是一场考验综合素质的选拔，需要兼顾学业（GPA排名）、竞赛、科研/项目/实习、英语六级和软实力等方面。但在其他方面都还过的去的情况下，还是需要要找准自己的核心竞争力。科研基础，竞赛就不基础；排名基础，六级就不基础。找到自己的核心竞争力后，需要重点关注考察这方面的院校，了解院校的入围标准作为努力目标，针对性准备，形成差异化优势。两年多的ACM训练经历，使我在各个院校的机试中游刃有余，也成为了我进入面试、斩获offer的关键。但由于在科研方面的积累较少，我就难以取得注重科研经历的院校的青睐。### 保研期间印象最深刻的事情> 人们对事物的记忆依赖于第一印象、峰值情绪与最终感受。——首因效应&峰终效应北航软院暑期学校是我的第一个夏令营。1000+人线上同台竞技（最终有过题的大概600+），一共7题，前42名参加线下营，我有幸入围。整个推免过程中唯一有伴手礼的院校（人文关怀这一块）。北航软院预推免也是我的最后一个预推免。极少数报名不卡BG的院校，突出的机试拯救了我稀烂的面试，在对面试表现的极度懊悔中获知自己位列候补第2。最顶峰的时刻莫过于923接到候补录取电话，上岸的那一刻。推免始于BUAA SE夏令营，终于BUAA SE预推免。有始，有终。### 学长寄语> 竹子用了4年的时间，竹芽仅仅长了3cm；第5年破土而出，6周就能达到15米。——竹子定律不仅仅是保研，考研、就业、创业亦是如此。或许有时你已经做出了很多努力却看不到成效，但学到的知识、积累的经验并不会因为短时间内没有被具象化而消失。不要因为一时的沉寂而动摇，你所有的积累都是在地下深处扎根。 -->]]></content>
    
    
    <summary type="html">四非鼠鼠上岸梦校BUAA</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>论文笔记|Video-LLaMA：An Instruction-tuned Audio-Visual Language Model for Video Understanding</title>
    <link href="https://www.cclmsy.cc/posts/2306.02858.html"/>
    <id>https://www.cclmsy.cc/posts/2306.02858.html</id>
    <published>2025-07-16T16:00:00.000Z</published>
    <updated>2025-07-18T11:17:56.833Z</updated>
    
    <content type="html"><![CDATA[<p>论文：<a href="https://arxiv.org/abs/2306.02858">Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding</a></p><p>阿里达摩院的一个多模态大语言模型产品Video-LLaMA，它针对的任务是多模态视频理解。</p><h1 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h1><p>要使LLMs理解视频，需要全面处理包括视觉输入、听觉输入和文本输出在内的不同模态，这比仅理解图像或仅理解音频任务更具挑战性</p><ul><li>Multi-modal Large Language Models (MLLMs) </li><li>现有方法：只有一种额外模态输入和文本对齐</li><li>针对视频理解的work：不使用音频部分</li></ul><p>Video-LLaMA可以理解视频中视觉和听觉内容。</p><p>不同于采用外部感知将视听信号转化为文本信号，作者构建了一个端到端模型，可以在单个框架内处理来自多种模态的数据</p><h1 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h1><ol><li>LLMs<ul><li>本文基础</li><li>Video-LLaMA赋予LLM视频、音频理解能力</li></ul></li><li>MLLMs<ol><li>将LLM作为控制器，识别用户意图并决定调用现有的多模态工具，整合结果全面响应</li><li>训练基础多模态大模型，核心是将其他模态的预训练基础模型与文本型大型语言模型对齐</li></ol><ul><li>Video-LLaMA属于第二类，训练模型以提供视觉、音频理解能力</li></ul></li></ol><h1 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h1><p>Video-LLaMA将视频帧和音频分别处理，整个架构分成两个分支：视觉语言分支和音频语言分支</p><p>分别将视频帧和音频信号转换为与LLM文本输入兼容的查询表示</p><h2 id="Vision-Language-Branch"><a href="#Vision-Language-Branch" class="headerlink" title="Vision-Language Branch"></a>Vision-Language Branch</h2><h3 id="1-Frozen-pre-trained-image-encoder"><a href="#1-Frozen-pre-trained-image-encoder" class="headerlink" title="1. Frozen pre-trained image encoder"></a>1. Frozen pre-trained image encoder</h3><p>冻结的预训练图像编码器，从视频帧提取出视觉特征。</p><script type="math/tex; mode=display">V = [v_1, v_2, ..., v_N] , v_i \in \R^{K_f\times d_f}</script><p>v_i表示第i帧用K_f个patch表示的视觉特征，d_f是每个patch的维度。</p><h3 id="2-PE-layer"><a href="#2-PE-layer" class="headerlink" title="2. PE layer"></a>2. PE layer</h3><p>上一层产出的presentations未考虑时序信息，PE层为每个v_i添加位置嵌入（时间信息）</p><h3 id="3-Video-Q-Former"><a href="#3-Video-Q-Former" class="headerlink" title="3. Video Q-Former"></a>3. Video Q-Former</h3><p>Video Query-Transformer（Q-Former）使用和BLIP2的Q-Former的同款架构，将位置编码后的帧表征聚合为视频级别的嵌入表示。</p><script type="math/tex; mode=display">\hat V \in \R^{K_v \times d_v}</script><h3 id="4-Linear"><a href="#4-Linear" class="headerlink" title="4. Linear"></a>4. Linear</h3><p>使视频表征适应 LLM 的输入，将视频嵌入向量转换为视频查询向量，与 LLM 的文本嵌入对齐</p><p>一个线性层将视频嵌入转换为视频查询向量，与文本嵌入的维度对齐。</p><h3 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h3><p>实现部分，冻结的预训练图像编码器使用Blip2的预训练视觉组件（包含来自 EVA-CLIP 的 ViTG/14 和一个预训练的 Q-former）</p><p>其余组件，包括位置嵌入层、视频 Q-former 和线性层，均经过随机初始化和优化，以便将冻结视觉编码器的输出与冻结的 LLM 良好地连接起来。</p><h2 id="Audio-Language-Branch"><a href="#Audio-Language-Branch" class="headerlink" title="Audio-Language Branch"></a>Audio-Language Branch</h2><p>整体结构和视觉语言分支基本相同，处理音频信号。</p><h3 id="1-Frozen-pre-trained-audio-encoder"><a href="#1-Frozen-pre-trained-audio-encoder" class="headerlink" title="1. Frozen pre-trained audio encoder"></a>1. Frozen pre-trained audio encoder</h3><p>冻结的预训练音频编码器，计算短片段原始音频的特征。</p><script type="math/tex; mode=display">A = [a_1, a_2, ..., a_M]</script><h3 id="2-PE-layer-1"><a href="#2-PE-layer-1" class="headerlink" title="2. PE layer"></a>2. PE layer</h3><p>向音频片段注入时间信息</p><h3 id="3-Audio-Q-Former"><a href="#3-Audio-Q-Former" class="headerlink" title="3. Audio Q-Former"></a>3. Audio Q-Former</h3><p>Audio Q-Former 也使用Q-Former的同款架构</p><p>利用带有位置信息的音频片段之间的交互，来生成固定长度的音频特征。</p><script type="math/tex; mode=display">\hat A \in \R^{K_a \times d_a}</script><h3 id="4-Linear-1"><a href="#4-Linear-1" class="headerlink" title="4. Linear"></a>4. Linear</h3><p>将音频嵌入向量转换为音频查询向量，与文本嵌入的维度对齐。</p><h3 id="Implementation-1"><a href="#Implementation-1" class="headerlink" title="Implementation"></a>Implementation</h3><p>实现部分，冻结的预训练音频编码器使用 Pre-trained ImageBind</p><p>短片段原始音频：均匀采样M个2秒短音频片段，使用128个mel频谱图像将每个2秒音频剪辑转换为频谱图</p><p>其他部分的处理和视觉语言分支相同。</p><h1 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h1><h2 id="Video-Language"><a href="#Video-Language" class="headerlink" title="Video-Language"></a>Video-Language</h2><p>预训练使用的数据集：</p><ul><li>Webvid-2M：大规模短视频数据集，包含来自素材网站的文本描述</li><li>CC595k: 经过过滤的图像-文本数据集</li></ul><p>问题：相当一部分文本描述不足以反映视频的全部内容，视频的视觉语义与描述的文本语义并非完全一致。</p><p>预训练阶段的目标是利用海量数据使视频特征尽可能地包含视觉知识</p><p>将视觉文本对齐和指令遵循能力留待下一阶段完成</p><p>使用高质量的指示数据对模型进行微调：</p><ul><li>图像细节描述 from MiniGPT-4</li><li>图像指令 from LLaVA</li><li>视频指令 from Video-Chat</li></ul><p>细节描述：训练模型能够对图像或视频生成详尽、全面、事实性的文本描述，尽可能多地捕捉和描述图像/视频中的所有可见元素、它们的属性、空间关系、发生的动作以及上下文</p><p>指令：理解并遵循用户的特定指令或回答用户提出的具体问题，针对该指令或问题的简明、准确的回答或执行结果</p><h2 id="Audio-Language"><a href="#Audio-Language" class="headerlink" title="Audio-Language"></a>Audio-Language</h2><p>音频-语言分支中可学习参数的目标是将冻结的音频编码器的输出嵌入与LLM的嵌入空间对齐。</p><p>直接使用音频-文本数据训练音频-语言分支非常具有挑战性，因为这类数据非常稀缺。</p><p>天才的想法：ImageBind具备将不同模态的嵌入对齐到同一共享空间的卓越能力</p><p>直接用视觉‑文本数据来训练音频‑语言分支，甚至处理和训练流程都直接照搬//</p><p>训练的结果：虽然训练时没见过音频数据，推理过程中展现出理解音频的能力</p><h2 id="思考：为什么可以使用视觉文本数据训练音频-语言分支？"><a href="#思考：为什么可以使用视觉文本数据训练音频-语言分支？" class="headerlink" title="思考：为什么可以使用视觉文本数据训练音频-语言分支？"></a>思考：为什么可以使用视觉文本数据训练音频-语言分支？</h2><ul><li>一切的基础：ImageBind的多模态对齐能力<ul><li>读到架构部分的时候还奇怪为什么音频-语言分支要用ImageBind这样一个名字长得像视觉语言处理器作为编码器，一切都有迹可循</li></ul></li><li>视频的画面通常和语音同步对应，可以近似替代音频数据，训练效果应该会比较相近</li></ul><h1 id="LLM"><a href="#LLM" class="headerlink" title="LLM"></a>LLM</h1><p>最后，视频和音频信息与文本嵌入连接在一起，作为视频软提示，引导LLMs生成基于视频内容的文本。</p><h1 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h1><h2 id="1-视听整合感知能力"><a href="#1-视听整合感知能力" class="headerlink" title="1. 视听整合感知能力"></a>1. 视听整合感知能力</h2><p>在包含一个视频的一个对话中，各提出一个关于音频和视频的指令，Video-LLaMA都可以答上来，说明其具备良好的视听整合感知能力。</p><h2 id="2-捕捉视频内时间动态的能力"><a href="#2-捕捉视频内时间动态的能力" class="headerlink" title="2. 捕捉视频内时间动态的能力"></a>2. 捕捉视频内时间动态的能力</h2><p>Video-LLaMA可以捕捉到船向右行进、女孩将手指放在嘴唇上等时间动态。</p><h2 id="3-理解静态图片的能力"><a href="#3-理解静态图片的能力" class="headerlink" title="3. 理解静态图片的能力"></a>3. 理解静态图片的能力</h2><p>能理解“男人在车顶拿着熨斗烫衣服”的非常规内容；细致描写小狗动作，同时将动作和“与人类友好互动”联系起来。</p><h2 id="4-常识性内容"><a href="#4-常识性内容" class="headerlink" title="4. 常识性内容"></a>4. 常识性内容</h2><p>能够认出地标性建筑“美国国会大厦”</p><p>甚至认出影视《权力的游戏》中由基特-哈灵顿扮演的琼恩-雪诺和由艾米莉亚-克拉克扮演的丹妮莉丝-坦格利安，甚至清楚在剧中，他们有着浪漫的关系。他们第一次见面是在第七季，在第八季中，他们对彼此的吸引力与日俱增。</p><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>提出Video-LLaMA，一个使LLM能够同时处理给定视频的视觉和听觉内容，并与人类进行对话的多模态框架</p><h1 id="Limitations"><a href="#Limitations" class="headerlink" title="Limitations"></a>Limitations</h1><ol><li>感知能力有限：当前训练数据集的质量和规模限制了Video‑LLaMA的表现。我们正在积极构建高质量的音视频文本对齐数据集以提升模型的感知能力。</li><li>处理长视频能力有限。长视频（如电影、电视剧）包含大量信息，对计算资源要求更高。这一挑战仍是研究界积极攻克的关键问题。</li><li>幻觉问题。Video‑LLaMA继承了冻结的大语言模型的幻觉问题。</li><li>整个work内容简单，缺乏科学的评估和与SOTA/baseline的对比</li><li>Webvid-2M素材来自网络、短视频文本描述抽象不切题，数据质量低，且可能含有有害内容。<ul><li>尽管指令微调使用了“更高质量”的数据 ，但初始预训练在 WebVid-2M（200 万视频 ）上庞大</li></ul></li><li>使用视觉-语言数据训练ImageBind的音频-语言分支这种做法虽然在结果上看到成效，但仍然缺乏充分的理论支持和实验验证。</li></ol>]]></content>
    
    
    <summary type="html">阅读论文《Video-LLaMA：An Instruction-tuned Audio-Visual Language Model for Video Understanding》</summary>
    
    
    
    <category term="论文笔记" scheme="https://www.cclmsy.cc/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="论文笔记" scheme="https://www.cclmsy.cc/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    <category term="MLLLM" scheme="https://www.cclmsy.cc/tags/MLLLM/"/>
    
  </entry>
  
  <entry>
    <title>论文笔记|视幻觉评估数据集PhD：A ChatGPT-Prompted Visual hallucination Evaluation Dataset</title>
    <link href="https://www.cclmsy.cc/posts/2403.11116.html"/>
    <id>https://www.cclmsy.cc/posts/2403.11116.html</id>
    <published>2025-06-24T16:00:00.000Z</published>
    <updated>2025-07-21T05:35:10.046Z</updated>
    
    <content type="html"><![CDATA[<p>论文：<a href="https://arxiv.org/abs/2403.11116">PhD: A ChatGPT-Prompted Visual hallucination Evaluation Dataset</a></p><div class="table-container"><table><thead><tr><th style="text-align:center">缩写</th><th style="text-align:center">全称</th><th style="text-align:center">直译</th></tr></thead><tbody><tr><td style="text-align:center">VHE</td><td style="text-align:center">Visual Hallucination Evaluation</td><td style="text-align:center">视觉幻觉评估</td></tr><tr><td style="text-align:center">hitem</td><td style="text-align:center">Hallucination item</td><td style="text-align:center">幻觉项</td></tr><tr><td style="text-align:center">CS</td><td style="text-align:center">Commen-sense</td><td style="text-align:center">反常识</td></tr><tr><td style="text-align:center">CCS</td><td style="text-align:center">Counter-commen-sense</td><td style="text-align:center">反常识</td></tr><tr><td style="text-align:center">VQA</td><td style="text-align:center">Visual Question Answering</td><td style="text-align:center">视觉问答</td></tr><tr><td style="text-align:center">GT</td><td style="text-align:center">ground-truth</td><td style="text-align:center">正确答案/真实信息</td></tr></tbody></table></div><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>MLLM以LLM为内核，由于LLM具有幻觉问题，MLLM也会出现幻觉问题。</p><p>VHE主要向MLLLM提出视觉问题，以特定单词或短语诱导MLLM产生和视觉内容不一致的反应。</p><p>本文为VHE开发了一个新的数据集，目标为低级（对象、属性）到中级（情感、位置、计数）的客观VHE评估。</p><p>MLLM视觉幻觉主要原因：</p><ol><li>Visual Ambiguity(视觉模糊性)：MLLM使用基于ViT的编码器，从给定图像中提取<strong>高层次特征</strong>，缺乏足够的细节来执行精细任务（精确计数）</li><li>Inconsistency in muti-modal input(多模态输入不一致)：LLM内核<strong>偏向</strong>多模态输入中的<strong>文本部分</strong>，视觉信息更可能被忽略。</li><li>Counter-commen-sense(反常识内容)：LLM内核严重依赖其内部的“常识”</li></ol><p>新数据集PhD通过改编数据集<a href="https://arxiv.org/abs/1703.09684">TDIUC</a>和利用ChatGPT辅助半自动化管道构建</p><p>贡献：</p><ol><li>PhD数据集：根据产生幻觉的3个原因，创建的包含5种任务、4种评估模式的数据集<ul><li>包含14648日常图像、750CCS图像和102564个VQA三元组，同类数据集规模最大</li><li>每个样本提供了hitem的信息</li></ul></li><li>提供了由ChatGPT辅助，极少人工干预的半自动化数据集构建管道</li><li>在15种开源MLLM、3种私有MLLM、2种幻觉缓解方法上进行评估，整体展示PhD数据集在VHE上的有效性</li></ol><h2 id="2-Related-work"><a href="#2-Related-work" class="headerlink" title="2. Related work"></a>2. Related work</h2><p>现有数据集分类：</p><ol><li>级别<ul><li>低级（对象、属性）~中级（情感、位置、计数）：评价MLLM的基本视觉功能</li><li>高级：知识密集度高，包括数学解题、地理信息理解、备忘录解读、历史民俗等</li></ul></li><li>评价方式<ul><li>客观评价：将模型输出和基本事实对比，以YES/NO形式进行</li><li>主观评价：需要人或LLM来评估模型输出 </li></ul></li></ol><p>PhD属于低级到中级的客观评价数据集。</p><p>该部分现有数据集的不足：</p><ol><li>POPE、ROME：hitem选择基于训练数据中的标签共现率（脱离图像）</li><li>NOPE、CIEM：缺乏hitem选择</li><li>AMBER：人工标注</li></ol><h2 id="3-Method"><a href="#3-Method" class="headerlink" title="3. Method"></a>3. Method</h2><p><img src="https://source.cclmsy.cc/posts/notes/papers/2403.11116/image-1.png" alt="alt text"></p><h3 id="3-1-Task-specific-Hitem-Selection-针对具体任务的Hitem选择"><a href="#3-1-Task-specific-Hitem-Selection-针对具体任务的Hitem选择" class="headerlink" title="3.1 Task-specific Hitem Selection 针对具体任务的Hitem选择"></a>3.1 Task-specific Hitem Selection 针对具体任务的Hitem选择</h3><p><img src="https://source.cclmsy.cc/posts/notes/papers/2403.11116/image.png" alt="alt text"></p><ol><li>Subject-Attribute Extraction：使用ChatGPT从TDIUC问答对中提取主体和属性</li><li>Candidate Hitem Generation：根据属性生成词汇表，排除GT</li><li>Visual-based Hitem Ranking：使用CLIP模型对候选hitem进行排序，选择与图像相关性最高的hitem<ul><li>文本输入：hitem+主体</li><li>未来可使用性能更好的模型</li></ul></li><li>Manual Inspection：原始TDIUC问答对可能有误，此时丢弃VQA</li></ol><p>成果：取得1452个更具多样化和挑战性的hitems</p><h3 id="3-2-Hitem-embedded-Qestion-Generation-嵌入Hitem的问答生成"><a href="#3-2-Hitem-embedded-Qestion-Generation-嵌入Hitem的问答生成" class="headerlink" title="3.2 Hitem-embedded Qestion Generation 嵌入Hitem的问答生成"></a>3.2 Hitem-embedded Qestion Generation 嵌入Hitem的问答生成</h3><p>给定主体和一个选定的hitem，ChatGPT生成一个问题，答案为“No”</p><p>使用GT生成的问题，答案则为“Yes”</p><h3 id="3-3-Specious-Incorrect-Context-Generation-似是而非（或错误）的内容生成"><a href="#3-3-Specious-Incorrect-Context-Generation-似是而非（或错误）的内容生成" class="headerlink" title="3.3 Specious(Incorrect) Context Generation 似是而非（或错误）的内容生成"></a>3.3 Specious(Incorrect) Context Generation 似是而非（或错误）的内容生成</h3><p>描述和图片不矛盾时，也可能不完全一致，如摩托静止（图中）和疾驰（描述）</p><p><img src="https://source.cclmsy.cc/posts/notes/papers/2403.11116/image-2.png" alt="alt text"></p><ol><li>Specious Cont Generation：使用ChatGPT生成与图像内容不一致的上下文<ul><li>specious text：似是而非，轻微不一致，但不直接矛盾 </li><li>Prompt：“请为给定问题生成[specious text]，使其能回答问题，但可能无法反映当前的实际情况，从而specious”</li></ul></li><li>Text Composition：将生成的specious text与原始caption衔接，新的上下文只有小部分与图像轻微不一致</li><li>Manual Inspection：人工抽查，如果质量不高则丢弃样本</li></ol><h3 id="3-4-CCS-Image-Generation-反常识图像生成"><a href="#3-4-CCS-Image-Generation-反常识图像生成" class="headerlink" title="3.4 CCS Image Generation 反常识图像生成"></a>3.4 CCS Image Generation 反常识图像生成</h3><p><img src="https://source.cclmsy.cc/posts/notes/papers/2403.11116/image-3.png" alt="alt text"></p><ol><li>CCS Description Generation：使用ChatGPT生成CCS描述，同时生成CS描述<ul><li>手写特定任务样例，为ChatGPT生成提供参考</li></ul></li><li>Text2Image：CCS描述生成相应图像，人工解决故障</li><li>Question Generation：使用ChatGPT生成，CCS问题答案为“Yes”，CS问题答案为“No”</li></ol><h3 id="3-5-Dataset-Overview-amp-PhD-Index-数据集概览与索引"><a href="#3-5-Dataset-Overview-amp-PhD-Index-数据集概览与索引" class="headerlink" title="3.5 Dataset Overview &amp; PhD Index 数据集概览与索引"></a>3.5 Dataset Overview &amp; PhD Index 数据集概览与索引</h3><p><img src="https://source.cclmsy.cc/posts/notes/papers/2403.11116/image-4.png" alt="alt text"></p><p>四种评估模式：</p><ol><li>PhD-base: 不含上下文的日常图像</li><li>PhD-sec(specious): 含似是而非上下文的日常图像</li><li>PhD-icc(incorrect): 含错误上下文的日常图像</li><li>PhD-ccs: 反常识图像问题</li></ol><p>4种评估模式×5种任务=20种模式-任务组合</p><p>PhD指标：调和平均数$\dfrac{2Recall<em>{yes}Recall</em>{no}}{Recall<em>{yes}+Recall</em>{no}}$</p><h2 id="4-Evaluating-MLLMs-on-PhD"><a href="#4-Evaluating-MLLMs-on-PhD" class="headerlink" title="4. Evaluating MLLMs on PhD"></a>4. Evaluating MLLMs on PhD</h2><h3 id="4-1-Setup"><a href="#4-1-Setup" class="headerlink" title="4.1 Setup"></a>4.1 Setup</h3><p>测试模型：</p><ul><li>15种开源MLLM（全量）</li><li>3种私有MLLM（2k随机采样）</li><li>支持LLaVa-1.6-L、Qwen-VL的2种幻觉缓解方法VCD、Woodpecker（2k随机采样）</li></ul><p>使用MLLM指定提示词形式；对于sec、icc，附加指令“图文不一致，以图片为准”</p><h3 id="4-2-总体PhD评估"><a href="#4-2-总体PhD评估" class="headerlink" title="4.2 总体PhD评估"></a>4.2 总体PhD评估</h3><p>全面了解哪种MLLM产生的幻觉最少。</p><p><img src="https://source.cclmsy.cc/posts/notes/papers/2403.11116/image-5.png" alt="alt text"></p><p>PhD辨别能力强，例如对GPT-4o和顶级开源MLLM的指标差距比POPE和AMBER的评估更明显</p><p>PhD数据集在任务和评估模式有细分，支持针对性分析</p><h3 id="4-3-PhD面向模式评估"><a href="#4-3-PhD面向模式评估" class="headerlink" title="4.3 PhD面向模式评估"></a>4.3 PhD面向模式评估</h3><p><img src="https://source.cclmsy.cc/posts/notes/papers/2403.11116/image-6.png" alt="alt text"></p><p>base模式下，具有更强视觉输入的模型表现更好，可以通过2种方式实现：</p><ol><li>更强的视觉编码器</li><li>支持更高分辨率的视觉输入</li></ol><p>仅使用较大的LLM不一定能获得更好的MLLM：虽然大型的LLM能更好地理解用户指令，但在MLLM中应用还需要针对性的VL对齐训练。</p><p>开源MLLM在PhD-icc和PhD-sec上性能普遍较低，因为多模式输入下，MLLM内核偏向文本部分。</p><p><img src="https://source.cclmsy.cc/posts/notes/papers/2403.11116/image-7.png" alt="alt text"></p><p>使用更大的LLM可在PhD-icc和PhD-sec上获得更好的结果，但更依赖内部知识，导致在无上下文的PhD-base和PhD-ccs上性能下降。</p><p>（Woodpecker使模型表现更均衡）</p><h3 id="4-4-PhD面向任务评估"><a href="#4-4-PhD面向任务评估" class="headerlink" title="4.4 PhD面向任务评估"></a>4.4 PhD面向任务评估</h3><p><img src="https://source.cclmsy.cc/posts/notes/papers/2403.11116/image-8.png" alt="alt text"></p><p>MLLM幻觉程度和任务水平相关，总体指标从高到低：情感 &gt; 计数 &gt; 位置 &gt; 属性 &gt; 对象</p><p>情感任务复杂微妙、计数任务要求精确，难度较高；在有文本或CCS干扰时尤其吃力。</p><p>模型在每种模式-任务组合都有一个得分，有助于针对性分析完善。热力图：</p><p><img src="https://source.cclmsy.cc/posts/notes/papers/2403.11116/image-9.png" alt="alt text"></p><h3 id="4-5-MLLM答案倾向性"><a href="#4-5-MLLM答案倾向性" class="headerlink" title="4.5 MLLM答案倾向性"></a>4.5 MLLM答案倾向性</h3><p>MLLM的PhD分数和YES率的斯皮尔曼相关性：</p><p><img src="https://source.cclmsy.cc/posts/notes/papers/2403.11116/image-10.png" alt="alt text"></p><p>结果表示，MLLM表现和YES率存在较强负相关，YES率越高，PhD分数越低。</p><p>解决VH问题需要注重平衡输出倾向，增强模型输出NO的能力。</p><h2 id="5-笔记"><a href="#5-笔记" class="headerlink" title="5. 笔记"></a>5. 笔记</h2><h3 id="5-1-PhD数据集的优点"><a href="#5-1-PhD数据集的优点" class="headerlink" title="5.1 PhD数据集的优点"></a>5.1 PhD数据集的优点</h3><ol><li>同类数据集规模最大</li><li>涵盖5种任务、4种评估模式，支持针对性分析</li><li>AI辅助半自动化数据集构建管道，极大地减少人工干预<ul><li>人工干预环节主要集中在质量审查</li></ul></li><li>针对痛点，直面MLLM的幻觉成因，评估有效性高<ul><li>联系到CLUE中提到的MLLM具有来自语言先验和非图像中心区域的偏差问题；此外，考虑到了图片可能包含CCS内容</li></ul></li></ol><h3 id="5-2-疑问"><a href="#5-2-疑问" class="headerlink" title="5.2 疑问"></a>5.2 疑问</h3><h4 id="原文-3-1"><a href="#原文-3-1" class="headerlink" title="原文 3.1"></a>原文 3.1</h4><p>Vocabulary Construction per task，颜色属性需要人工指定（manually specify）一些，然后ChatGPT自动生成一些日常词汇。</p><p>不同对象（家具、载具）、属性（大小、颜色），每一个任务的词汇表生成都需要人工指定一些吗？</p><p>关于环节顺序，个人认为应该是先进行Subject-Attribute Extraction，再根据Subject/Attribute构建词汇表？</p>]]></content>
    
    
    <summary type="html">阅读论文《PhD：A ChatGPT-Prompted Visual hallucination Evaluation Dataset》</summary>
    
    
    
    <category term="论文笔记" scheme="https://www.cclmsy.cc/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="论文笔记" scheme="https://www.cclmsy.cc/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    <category term="MLLLM" scheme="https://www.cclmsy.cc/tags/MLLLM/"/>
    
    <category term="数据集" scheme="https://www.cclmsy.cc/tags/%E6%95%B0%E6%8D%AE%E9%9B%86/"/>
    
  </entry>
  
  <entry>
    <title>《操作系统》课程笔记</title>
    <link href="https://www.cclmsy.cc/posts/operating_system.html"/>
    <id>https://www.cclmsy.cc/posts/operating_system.html</id>
    <published>2025-06-16T16:00:00.000Z</published>
    <updated>2025-07-20T12:46:18.896Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、导论"><a href="#一、导论" class="headerlink" title="一、导论"></a>一、导论</h2><h3 id="1-计算机系统的组成部分"><a href="#1-计算机系统的组成部分" class="headerlink" title="1. 计算机系统的组成部分"></a>1. 计算机系统的组成部分</h3><p><img src="https://source.cclmsy.cc/posts/notes/course/operating_system/image.png" alt="alt text"></p><h3 id="2-操作系统的概念"><a href="#2-操作系统的概念" class="headerlink" title="2. 操作系统的概念"></a>2. 操作系统的概念</h3><p>操作系统(OS)也称内核(Kernel)，是一直运行在计算机上的程序。</p><p>四大特征：并发、共享、虚拟、异步</p><p>作用(系统视角)：</p><ul><li>资源分配器：为各用户和进程分配资源，提高资源利用率</li><li>控制程序：控制各个进程的执行，确保系统稳定运行</li></ul><p>功能：</p><ol><li>进程管理：创建、删除、挂起、重启进程；提供进程同步机制、进程通信机制、死锁处理机制</li><li>内存管理：记录内存分配情况；决定哪些进程可以进入内存；提供内存分配和回收机制</li><li>存储管理</li></ol><h3 id="3-存储层次"><a href="#3-存储层次" class="headerlink" title="3. 存储层次"></a>3. 存储层次</h3><p>寄存器(Register)、<strong>高速缓存(Cache)、内存(Memory)</strong>、磁盘(Disk)、硬盘、光盘、磁带</p><ul><li>内存：CPU可直接访问的唯一大容量存储区域</li><li>Cache：CPU-内存存储层次</li></ul><p>属性：容量、速度、价格、易失性</p><h3 id="4-多道程序设计"><a href="#4-多道程序设计" class="headerlink" title="4. 多道程序设计"></a>4. 多道程序设计</h3><p>多道程序设计(Multiprogramming)是操作系统<strong>最重要的特点</strong>，通过组织作业使CPU总有一个作业可以执行。</p><p>在内存中同时存放多个程序，使得CPU可以在一个程序等待I/O操作时，切换到另一个程序执行，从而提高CPU的利用率。</p><h3 id="5-双重模式和特权指令"><a href="#5-双重模式和特权指令" class="headerlink" title="5. 双重模式和特权指令"></a>5. 双重模式和特权指令</h3><p>双重模式：</p><p>为了区分操作系统代码和用户代码执行，至少需要两种模式：<strong>内核模式</strong>（又称管理模式、系统模式、特权模式）和<strong>用户模式</strong>，通过模式位（0/1）来区分。</p><p>当应用程序需要操作系统的服务时，<strong>必须</strong>从用户模式切换到内核模式。</p><p>特权指令(Privileged Instructions)：</p><p>只有在内核模式下才能执行的指令。</p><p>特权指令：切换到用户模式、I/O控制相关、访问特殊寄存器的指令、定时器管理、中断管理、内存管理（如改变内存分配图）、设置时钟日期等</p><p>易混淆的非特权指令：</p><ul><li>访管指令：由用户程序发起的一种特殊指令，用于请求操作系统执行某些需要特殊权限才能访问的操作，会从内核模式切换到内核模式，将控制权交给操作系统内核执行相应操作，然后再返回用户模式</li><li>主机和磁盘间通过DMA传送数据的指令</li><li>改变磁盘空间分配图（区别于改变内存分配图）</li><li>写程序计数器PC、寄存器清0、取指令、取操作数、写内存</li></ul><h3 id="6-定时器"><a href="#6-定时器" class="headerlink" title="6. 定时器"></a>6. 定时器</h3><p>定时器(Timer)确保操作系统维持对CPU的控制，防止用户程序：</p><ol><li>陷入死循环</li><li>不调用系统服务，但不将控制返还给操作系统</li></ol><p>操作系统在将控制权交给用户之前，应确保设置好定时器以便产生中断。</p><h2 id="二、操作系统结构"><a href="#二、操作系统结构" class="headerlink" title="二、操作系统结构"></a>二、操作系统结构</h2><h3 id="1-操作系统服务"><a href="#1-操作系统服务" class="headerlink" title="1. 操作系统服务"></a>1. 操作系统服务</h3><p>1~6方便用户使用；7~9提高系统效率。</p><ol><li>用户界面(User Interface)：提供用户与操作系统交互的方式。</li><li>程序执行：加载程序到内存并运行，能结束执行（不论是正常还是异常）</li><li>I/O操作：提供对I/O设备的访问和控制</li><li>文件系统操作：创建、删除、读写文件和目录</li><li>通信：提供进程间通信机制，如管道、消息队列、共享内存等<ul><li>方式：共享内存、消息交换</li></ul></li><li>错误检测：检测和处理错误，确保系统稳定运行</li><li>资源分配：为各个进程分配CPU时间、内存空间、I/O设备等资源</li><li>记账：记录资源使用类型和数量</li><li>保护与安全：确保系统资源的安全性和完整性，防止未授权访问</li></ol><h3 id="2-命令解释程序"><a href="#2-命令解释程序" class="headerlink" title="2. 命令解释程序"></a>2. 命令解释程序</h3><p>命令解释程序(Command Interpreter)也被称为外壳(Shell)，用于获取并执行用户的下一条指令的程序/</p><ul><li>命令行界面(Command Line Interface, CLI)</li><li>图形用户界面(Graphical User Interface, GUI)</li><li>批处理(Batch)</li></ul><h3 id="3-系统调用类型"><a href="#3-系统调用类型" class="headerlink" title="3. 系统调用类型"></a>3. 系统调用类型</h3><p>系统调用是操作系统提供给应用程序的唯一程序接口</p><p>类型：进程控制;文件管理;设备管理;信息维护;通信。</p><h2 id="三、进程-Process"><a href="#三、进程-Process" class="headerlink" title="三、进程(Process)"></a>三、进程(Process)</h2><h3 id="1-进程"><a href="#1-进程" class="headerlink" title="1. 进程"></a>1. 进程</h3><p>进程是正在执行的程序的实例，包括：代码段、数据段、堆栈段、堆、进程控制块(PCB)。</p><h4 id="进程控制块-PCB"><a href="#进程控制块-PCB" class="headerlink" title="进程控制块(PCB)"></a>进程控制块(PCB)</h4><p>进程存在的唯一标识，包含：</p><ul><li>进程状态(State)：新的、运行、等待、就绪、终止</li><li>程序计数器(Program Counter, PC)：指向下一条要执行的指令</li><li>CPU寄存器(Registers)：保存进程执行时的寄存器状态</li><li>CPU调度信息：进程优先级，调度队列指针等</li><li>内存管理信息：页表、段表、基地址等</li><li>记账信息、I/O信息</li></ul><h4 id="上下文切换"><a href="#上下文切换" class="headerlink" title="上下文切换"></a>上下文切换</h4><p>上下文切换：进程间切换的过程，保存当前进程的状态到PCB1中，并从PCB2中恢复下一个进程的状态。</p><h3 id="2-进程状态与转换"><a href="#2-进程状态与转换" class="headerlink" title="2. 进程状态与转换"></a>2. 进程状态与转换</h3><ul><li>新的(new)：进程正在创建中</li><li>运行(running)：指令正在执行（一次只能有一个进程可在一个CPU上运行）</li><li>等待(waiting)：进程正在等待某个事件发生（如I/O操作完成、收到信号等）</li><li>就绪(ready)：进程已准备好运行，等待分配处理器</li><li>终止(terminated)：进程已完成执行</li></ul><p><img src="https://source.cclmsy.cc/posts/notes/course/operating_system/image-1.png" alt="alt text"></p><ul><li>因时间片用完暂停：运行-&gt;就绪</li><li>因I/O操作暂停：运行-&gt;等待</li><li>进程打印结束：等待-&gt;就绪</li></ul><h3 id="3-进程调度"><a href="#3-进程调度" class="headerlink" title="3. 进程调度"></a>3. 进程调度</h3><p>调度队列：</p><ul><li>作业队列：系统中的所有进程</li><li>就绪队列：处于就绪状态等待运行的进程</li><li>设备队列：等待特定I/O设备的进程</li></ul><p>调度程序：</p><ul><li>短期调度（CPU调度）：从<strong>队列</strong>中选择一个进程并为之分配CPU<ul><li>快速执行，频繁发生，通常每隔几毫秒</li></ul></li><li>长期调度（作业调度）：从<strong>磁盘缓冲池</strong>中选择进程并将其加载到内存以便执行<ul><li>控制多道程序程度（内存中的进程数）</li><li>选择进程：合理搭配CPU密集型和I/O密集型进程</li></ul></li><li>中期调度：将进程从<strong>内存或CPU竞争</strong>中移出<ul><li>降低多道程序程度</li></ul></li></ul><h3 id="4-进程创建-终止"><a href="#4-进程创建-终止" class="headerlink" title="4. 进程创建/终止"></a>4. 进程创建/终止</h3><p>进程创建：<code>fork()</code>、<code>vfork()</code>、<code>clone()</code>等系统调用</p><ul><li>创建新进程时，父进程的所有资源（代码、数据、堆栈）都被复制到子进程中</li><li>子进程fork()返回值为0，父进程返回子进程的PID</li><li>子进程拥有自己的PCB和独立的地址空间</li></ul><p>进程终止：正常结束<code>exit()</code>；异常结束<code>abort()</code></p><p>级联终止：当父进程终止时，所有子进程也会被终止</p><p>父进程等待：<code>wait()</code>系统调用</p><ul><li>注意：exec()系列函数会用新程序替换当前进程的代码段、数据段和堆栈段，但保留PCB和进程ID，不会创建新进程。</li></ul><h3 id="5-进程协作-通信"><a href="#5-进程协作-通信" class="headerlink" title="5. 进程协作/通信"></a>5. 进程协作/通信</h3><p>如果一个进程能影响其他进程或被其他进程影响，那么该进程就是<strong>协作</strong>的，否则就是<strong>独立</strong>的。</p><p>协作进程需要一种进程间通信机制（Inter-Process Communication, IPC）来交换信息，有2种基本方式：</p><ul><li>共享内存：多个进程可以访问同一块内存区域<ul><li>快，仅在建立共享内存时需要系统调用</li></ul></li><li>消息传递：通过发送和接收消息来交换信息<ul><li>交换少量数据时有用，无需避免冲突</li></ul></li></ul><p>生产者-消费者模型：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//生产者</span></span><br><span class="line"><span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">    <span class="keyword">while</span>(((in+<span class="number">1</span>) % N) == out); <span class="comment">//等待缓冲区有空位</span></span><br><span class="line">    buffer[in] = produce_item(); <span class="comment">//生产一个项目</span></span><br><span class="line">    in = (in + <span class="number">1</span>) % N; <span class="comment">//更新输入指针</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 消费者</span></span><br><span class="line"><span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">    <span class="keyword">while</span> (in == out); <span class="comment">//等待缓冲区有项目</span></span><br><span class="line">    consume_item(buffer[out]); <span class="comment">//消费一个项目</span></span><br><span class="line">    out = (out + <span class="number">1</span>) % N; <span class="comment">//更新输出指针</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="四、线程-Thread"><a href="#四、线程-Thread" class="headerlink" title="四、线程(Thread)"></a>四、线程(Thread)</h2><h3 id="1-线程"><a href="#1-线程" class="headerlink" title="1. 线程"></a>1. 线程</h3><p>线程是CPU处理的基本单位，由：线程ID、程序计数器、寄存器集合和栈组成</p><h3 id="2-线程与进程"><a href="#2-线程与进程" class="headerlink" title="2. 线程与进程"></a>2. 线程与进程</h3><p>进程是操作系统分配资源的基本单位，而线程是CPU处理的基本单位</p><p>同一进程 的 不同线程 之间<strong>共享代码段、数据段、文件</strong>等，<strong>私有寄存器和栈</strong>。</p><h3 id="3-多线程的优点"><a href="#3-多线程的优点" class="headerlink" title="3. 多线程的优点"></a>3. 多线程的优点</h3><ol><li>响应度高：即使部分阻塞或执行冗长操作，仍然可以继续执行，增加对用户的响应程度</li><li>资源共享：进程只能通过（共享内存、消息传递）等方式共享资源，而线程默认允许共享内存和资源</li><li>经济：进程创建所需的内存和资源分配高，线程共享资源，创建和切换开销小</li><li>可伸缩性：多线程程序可以更好地利用多核处理器的并行处理能力</li></ol><h3 id="4-用户线程和内核线程"><a href="#4-用户线程和内核线程" class="headerlink" title="4. 用户线程和内核线程"></a>4. 用户线程和内核线程</h3><p>用户线程在内核之上支持，并通过用户级线程库来实现。<br>线程库提供对用户线程的创建、调度和管理的支持，而无需内核支持。</p><p>三种基本的用户级线程库：POSIX Pthreads、Win32 Threads、Java Threads。</p><p>内核由操作系统直接支持，内核在其空间内执行内核线程的创建、调度和管理。</p><p>实例：Windows XP/2000、Solaris、Linux等操作系统都支持内核线程。</p><p>多线程模型：用户线程和内核线程的映射关系（1:1、M:1、M:N）</p><h2 id="五、进程调度"><a href="#五、进程调度" class="headerlink" title="五、进程调度"></a>五、进程调度</h2><h3 id="1-基本概念"><a href="#1-基本概念" class="headerlink" title="1. 基本概念"></a>1. 基本概念</h3><h4 id="1-1-CPU-I-O执行周期"><a href="#1-1-CPU-I-O执行周期" class="headerlink" title="1.1 CPU-I/O执行周期"></a>1.1 CPU-I/O执行周期</h4><p>进程执行包括周期地交替进行：CPU执行和I/O等待</p><p>短CPU区间出现的频率较高，长CPU区间则很少。<br>I/O为主的程序通常短CPU区间很多，而CPU为主的程序可能有少量的长CPU区间。</p><h4 id="1-2-CPU调度程序"><a href="#1-2-CPU调度程序" class="headerlink" title="1.2 CPU调度程序"></a>1.2 CPU调度程序</h4><p>当CPU变为空闲时，操作系统就必须从就绪队列中选择一个进程来执行。<br>进程的选择由短期调度程序（Short-term scheduler,或CPU调度程序）执行。</p><p>当出现下面任何情形之一时，需要CPU调度：</p><ol><li>进程从运行状态转入等待状态（I/O请求）</li><li>进程从运行状态转入就绪状态（出现中断）</li><li>进程从等待状态转入就绪状态（I/O完成）</li><li>进程终止</li></ol><p>如果调度只发生在1,4情形，则称为非抢占式调度；<br>如果在2,3情形发生调度，则称为抢占式调度。</p><h4 id="1-3-调度程序-分派程序"><a href="#1-3-调度程序-分派程序" class="headerlink" title="1.3 调度程序/分派程序"></a>1.3 调度程序/分派程序</h4><p>调度程序（Dispatcher，又称分派程序）是一个模块，用来将CPU控制权交给短期调度程序选择的进程，功能包括：</p><ol><li>切换上下文：保存当前进程的状态，并加载新进程的状态</li><li>切换到用户模式</li><li>跳转到用户程序的合适位置，以便重新启动程序</li></ol><p>每次进程切换都需要使用调度程序，速度应尽可能快。</p><p>调度延迟/分派延迟：停止一个进程而启动另一个进程所需的时间。</p><h3 id="2-调度准则"><a href="#2-调度准则" class="headerlink" title="2. 调度准则"></a>2. 调度准则</h3><ul><li>最大化：CPU利用率、吞吐量</li><li>最小化：<ul><li>平均周转时间：从进程提交到进程完成的时间</li><li>平均等待时间：程在就绪队列中等待所花的时间，平均等待时间=平均周转时间-平均执行时间</li><li>平均响应时间：从进程提交到进程第一次开始执行的时间</li></ul></li></ul><h3 id="3-调度算法"><a href="#3-调度算法" class="headerlink" title="3. 调度算法"></a>3. 调度算法</h3><ul><li>非抢占式：一旦进程开始执行，除非它完成，否则不会被抢占</li><li>抢占式：如果一个新到达的进程满足抢占条件，则抢占当前进程</li></ul><h4 id="3-1-先到先服务（FCFS）"><a href="#3-1-先到先服务（FCFS）" class="headerlink" title="3.1 先到先服务（FCFS）"></a>3.1 先到先服务（FCFS）</h4><p>先到先服务（First-Come, First-Served, FCFS）是最简单的调度算法。</p><p>按照进程到达就绪队列的顺序进行调度。</p><p>问题：护航效应：长进程可能会阻塞短进程，导致平均等待时间增加。</p><h4 id="3-2-最短作业优先"><a href="#3-2-最短作业优先" class="headerlink" title="3.2 最短作业优先"></a>3.2 最短作业优先</h4><p>最短作业优先（Shortest Job First, SJF），是最佳的调度算法之一。</p><p>基于进程执行时间的调度算法，选择预计执行时间最短的进程进行调度。</p><p>分为非抢占式（最短作业优先SJF）和抢占式（最短剩余时间调度SRTF）</p><p>SJF算法是最佳的，但是它不能在短期CPU调度的层次上实现，因为没有办法知道下一个CPU请求的长度。</p><p>问题：饥饿现象/无穷阻塞：长进程可能永远得不到执行。</p><h4 id="3-3-优先级调度"><a href="#3-3-优先级调度" class="headerlink" title="3.3 优先级调度"></a>3.3 优先级调度</h4><p>优先级调度（Priority Scheduling）为每个进程分配一个优先级，调度时选择优先级最高的进程。</p><p>分为非抢占式和抢占式。</p><p>SJF算法是通用优先级调度算法的一个特例，只不过SJF算法的优先级是通过预测CPU区间的长短来实现的。</p><p>问题：饥饿现象/无穷阻塞</p><p>解决办法：老化：逐渐增大在系统中等待很长时间的进程的优先级。</p><h4 id="3-4-轮转调度（RR）"><a href="#3-4-轮转调度（RR）" class="headerlink" title="3.4 轮转调度（RR）"></a>3.4 轮转调度（RR）</h4><p>轮转调度（Round Robin, RR）是最常用的抢占式调度算法。</p><p>将一个较小的时间单元定义为时间片（Time Quantum），每个进程在时间片内执行。</p><p>如果时间片用完，进程被抢占并放回就绪队列的末尾。</p><p>优点：响应时间小、不会出现护航效应和饥饿现象。</p><p>RR依赖于时间片大小，过大则和FCFS相同，过小则会导致频繁的上下文切换</p><p>注：考试中时间片默认为2s</p><h4 id="3-5-多级队列调度"><a href="#3-5-多级队列调度" class="headerlink" title="3.5 多级队列调度"></a>3.5 多级队列调度</h4><p>将就绪队列划分为多个独立队列，根据进程的某些属性分配到不同队列，每个队列有自己的调度算法。</p><p>队列之间也需要优先级，可以是固定优先级或划分时间片</p><h4 id="3-6-多级反馈队列调度"><a href="#3-6-多级反馈队列调度" class="headerlink" title="3.6 多级反馈队列调度"></a>3.6 多级反馈队列调度</h4><p>根据不同CPU区间特点以区分进程，允许进程在队列之间移动。</p><p>如果进程使用过多的CPU时间，那么它会被移到更低优先级队列，这一方案会将I/O为主和交互式进程留在较高优先级队列。</p><p>在较低优先级队列中等待过长的进程会被转移到较高优先级队列，这种形式的老化能够阻止饥饿的发生。</p><h3 id="4-调度算法计算题"><a href="#4-调度算法计算题" class="headerlink" title="4. 调度算法计算题"></a>4. 调度算法计算题</h3><div class="table-container"><table><thead><tr><th style="text-align:center">进程</th><th style="text-align:center">到达时间</th><th style="text-align:center">执行时间</th><th style="text-align:center">优先级</th></tr></thead><tbody><tr><td style="text-align:center">P1</td><td style="text-align:center">0</td><td style="text-align:center">10</td><td style="text-align:center">2</td></tr><tr><td style="text-align:center">P2</td><td style="text-align:center">1</td><td style="text-align:center">4</td><td style="text-align:center">5</td></tr><tr><td style="text-align:center">P3</td><td style="text-align:center">2</td><td style="text-align:center">9</td><td style="text-align:center">3</td></tr><tr><td style="text-align:center">P4</td><td style="text-align:center">3</td><td style="text-align:center">5</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">P5</td><td style="text-align:center">4</td><td style="text-align:center">2</td><td style="text-align:center">4</td></tr></tbody></table></div><h4 id="4-1-FCFS调度"><a href="#4-1-FCFS调度" class="headerlink" title="4.1 FCFS调度"></a>4.1 FCFS调度</h4><p>甘特图：</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">| <span class="type">P1</span> | <span class="type">P2</span> | <span class="type">P3</span> | <span class="type">P4</span> | <span class="type">P5</span> |</span><br><span class="line"><span class="type">0</span>    <span class="number">10</span>   <span class="number">14</span>   <span class="number">23</span>   <span class="number">28</span>   <span class="number">30</span> </span><br></pre></td></tr></table></figure><ul><li>平均等待时间：$(0+(10-1)+(14-2)+(23-3)+(28-4))\div 5 = 13$</li><li>平均周转时间：$(10+(14-1)+(23-2)+(28-3)+(30-4))\div 5 = 19$</li><li>平均响应时间=平均等待时间</li></ul><h4 id="4-2-SJF调度"><a href="#4-2-SJF调度" class="headerlink" title="4.2 SJF调度"></a>4.2 SJF调度</h4><p>由于P1先到，所以P1先执行，非抢占式</p><p>甘特图：</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">| <span class="type">P1</span> | <span class="type">P5</span> | <span class="type">P2</span> | <span class="type">P4</span> | <span class="type">P3</span> |</span><br><span class="line"><span class="type">0</span>    <span class="number">10</span>   <span class="number">12</span>   <span class="number">16</span>   <span class="number">21</span>   <span class="number">30</span></span><br></pre></td></tr></table></figure><ul><li>平均等待时间：$(0+(12-1)+(21-2)+(16-3)+(10-4))\div 5 = 9.8$</li><li>平均周转时间：$(10+(16-1)+(30-2)+(21-3)+(12-4))\div 5 = 15.8$</li><li>平均响应时间=平均等待时间</li></ul><h4 id="4-3-SRTF调度"><a href="#4-3-SRTF调度" class="headerlink" title="4.3 SRTF调度"></a>4.3 SRTF调度</h4><p>甘特图：</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">| <span class="type">P1</span> | <span class="type">P2</span> | <span class="type">P5</span> | <span class="type">P4</span> | <span class="type">P1</span> | <span class="type">P3</span> |</span><br><span class="line"><span class="type">0</span>    <span class="number">1</span>    <span class="number">5</span>    <span class="number">7</span>    <span class="number">12</span>   <span class="number">21</span>   <span class="number">30</span></span><br></pre></td></tr></table></figure><ul><li>平均等待时间：$((0+(12-1))+(1-1)+(21-2)+(7-3)+(5-4))\div 5 = 7$</li><li>平均周转时间：$(21+(5-1)+(30-2)+(12-3)+(7-4))\div 5 = 13$</li><li>平均响应时间：$(0+(1-1)+(21-2)+(7-3)+(5-4))\div 5 = 4.8$</li></ul><h4 id="4-4-优先级调度（非抢占式）"><a href="#4-4-优先级调度（非抢占式）" class="headerlink" title="4.4 优先级调度（非抢占式）"></a>4.4 优先级调度（非抢占式）</h4><p>由于P1先到，所以P1先执行，非抢占式</p><p>甘特图：</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">| <span class="type">P1</span> | <span class="type">P4</span> | <span class="type">P3</span> | <span class="type">P5</span> | <span class="type">P2</span> |</span><br><span class="line"><span class="type">0</span>    <span class="number">10</span>   <span class="number">15</span>   <span class="number">24</span>   <span class="number">26</span>   <span class="number">30</span></span><br></pre></td></tr></table></figure><ul><li>平均等待时间：$(0+(24-1)+(15-2)+(10-3)+(26-4))\div 5 = 13$</li><li>平均周转时间：$(10+(30-1)+(26-2)+(15-3)+(24-4))\div 5 = 19$</li><li>平均响应时间=平均等待时间</li></ul><h4 id="4-5-优先级调度（抢占式）"><a href="#4-5-优先级调度（抢占式）" class="headerlink" title="4.5 优先级调度（抢占式）"></a>4.5 优先级调度（抢占式）</h4><p>甘特图：</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">| <span class="type">P1</span> | <span class="type">P4</span> | <span class="type">P1</span> | <span class="type">P3</span> | <span class="type">P5</span> | <span class="type">P2</span> |</span><br><span class="line"><span class="type">0</span>    <span class="number">3</span>    <span class="number">8</span>    <span class="number">15</span>   <span class="number">24</span>   <span class="number">26</span>   <span class="number">30</span></span><br></pre></td></tr></table></figure><ul><li>平均等待时间：$((0+(8-3))+(26-1)+(15-2)+(4-3)+(24-4))\div 5 = 12.6$</li><li>平均周转时间：$(15+(30-1)+(24-2)+(8-3)+(26-4))\div 5 = 18.6$</li><li>平均响应时间：$(0+(26-1)+(15-2)+(4-3)+(24-4))\div 5 = 11.6$</li></ul><h4 id="4-6-轮转调度（RR）"><a href="#4-6-轮转调度（RR）" class="headerlink" title="4.6 轮转调度（RR）"></a>4.6 轮转调度（RR）</h4><p>假设时间片为2s，进程到达入队 优先于 时间片到入队</p><p>运行流程</p><div class="table-container"><table><thead><tr><th style="text-align:center">时间</th><th style="text-align:center">CPU执行</th><th style="text-align:center">就绪队列</th><th style="text-align:center">备注</th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center">P1(0/10)</td><td style="text-align:center">[]</td><td style="text-align:center">P1到达，P1执行</td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">P1(1/10)</td><td style="text-align:center">[P2(0/4) ]</td><td style="text-align:center">P2到达，P1继续执行</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">P2(0/4)</td><td style="text-align:center">[P3(0/9), P1(2/10)]</td><td style="text-align:center">P3到达，P1时间片到，P2执行</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">P2(1/4)</td><td style="text-align:center">[P3(0/9), P1(2/10), P4(0/5)]</td><td style="text-align:center">P4到达，P2继续执行</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">P3(0/9)</td><td style="text-align:center">[P1(2/10), P4(0/5), P5(0/2), P2(2/4)]</td><td style="text-align:center">P5到达，P2时间片到，P3执行</td></tr><tr><td style="text-align:center">6</td><td style="text-align:center">P1(2/10)</td><td style="text-align:center">[P4(0/5), P5(0/2), P2(2/4), P3(2/9)]</td><td style="text-align:center">P3时间片到，P1执行</td></tr><tr><td style="text-align:center">8</td><td style="text-align:center">P4(0/5)</td><td style="text-align:center">[P5(0/2), P2(2/4), P3(2/9), P1(4/10)]</td><td style="text-align:center">P1时间片到，P4执行</td></tr><tr><td style="text-align:center">10</td><td style="text-align:center">P5(0/2)</td><td style="text-align:center">[P2(2/4), P3(2/9), P1(4/10), P4(2/5)]</td><td style="text-align:center">P4时间片到，P5执行</td></tr><tr><td style="text-align:center">12</td><td style="text-align:center">P2(2/4)</td><td style="text-align:center">[P3(2/9), P1(4/10), P4(2/5)]</td><td style="text-align:center">P5完成，P2执行</td></tr><tr><td style="text-align:center">14</td><td style="text-align:center">P3(2/9)</td><td style="text-align:center">[P1(4/10), P4(2/5)]</td><td style="text-align:center">P2完成，P3执行</td></tr><tr><td style="text-align:center">16</td><td style="text-align:center">P1(4/10)</td><td style="text-align:center">[P4(2/5), P3(4/9)]</td><td style="text-align:center">P3时间片到，P1执行</td></tr><tr><td style="text-align:center">18</td><td style="text-align:center">P4(2/5)</td><td style="text-align:center">[P3(4/9), P1(6/10)]</td><td style="text-align:center">P1时间片到，P4执行</td></tr><tr><td style="text-align:center">20</td><td style="text-align:center">P3(4/9)</td><td style="text-align:center">[P1(6/10), P4(4/5)]</td><td style="text-align:center">P4时间片到，P3执行</td></tr><tr><td style="text-align:center">22</td><td style="text-align:center">P1(6/10)</td><td style="text-align:center">[P4(4/5), P3(6/9)]</td><td style="text-align:center">P3时间片到，P1执行</td></tr><tr><td style="text-align:center">24</td><td style="text-align:center">P4(4/5)</td><td style="text-align:center">[P3(6/9), P1(8/10)]</td><td style="text-align:center">P1时间片到，P4执行</td></tr><tr><td style="text-align:center">25</td><td style="text-align:center">P3(6/9)</td><td style="text-align:center">[P1(8/10) ]</td><td style="text-align:center">P4完成，P3执行</td></tr><tr><td style="text-align:center">27</td><td style="text-align:center">P1(8/10)</td><td style="text-align:center">[P3(8/9) ]</td><td style="text-align:center">P3时间片到，P1执行</td></tr><tr><td style="text-align:center">29</td><td style="text-align:center">P3(8/9)</td><td style="text-align:center">[]</td><td style="text-align:center">P1完成，P3执行</td></tr><tr><td style="text-align:center">30</td><td style="text-align:center">P3(9/9)</td><td style="text-align:center">[]</td><td style="text-align:center">P3完成，所有进程执行完毕</td></tr></tbody></table></div><p>甘特图：</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">| <span class="type">P1</span> | <span class="type">P2</span> | <span class="type">P3</span> | <span class="type">P1</span> | <span class="type">P4</span> | <span class="type">P5</span> | <span class="type">P2</span> | <span class="type">P3</span> | <span class="type">P1</span> | <span class="type">P4</span> | <span class="type">P3</span> | <span class="type">P1</span> | <span class="type">P4</span> | <span class="type">P3</span> | <span class="type">P1</span> | <span class="type">P3</span> |</span><br><span class="line"><span class="type">0</span>    <span class="number">2</span>    <span class="number">4</span>    <span class="number">6</span>    <span class="number">8</span>    <span class="number">10</span>   <span class="number">12</span>   <span class="number">14</span>   <span class="number">16</span>   <span class="number">18</span>   <span class="number">20</span>   <span class="number">22</span>   <span class="number">24</span>   <span class="number">25</span>   <span class="number">27</span>   <span class="number">29</span>   <span class="number">30</span></span><br></pre></td></tr></table></figure><ul><li>平均等待时间=周转时间-执行时间=$((29-0-10)+(14-1-4)+(30-2-9)+(23-3-5)+(25-4-2))/5=14$</li><li>平均周转时间=$(29+(14-1)+(30-2)+(23-3)+(25-4))/5=20$</li><li>平均响应时间=$(0+(2-1)+(4-2)+(8-3)+(10-4))/5=2.8$</li></ul><h2 id="六、进程同步"><a href="#六、进程同步" class="headerlink" title="六、进程同步"></a>六、进程同步</h2><h3 id="1-竞争条件"><a href="#1-竞争条件" class="headerlink" title="1. 竞争条件"></a>1. 竞争条件</h3><p>多个进程并发访问和操作同一数据时，执行结果和访问发生的特定顺序有关，这种情况称为竞争条件。</p><p>例如：赋值语句和自增语句</p><h3 id="2-临界区问题"><a href="#2-临界区问题" class="headerlink" title="2. 临界区问题"></a>2. 临界区问题</h3><p>临界区(Critical Section)：并发过程中可能访问/修改共享数据的代码段。</p><p>临界区问题：确保在任何时刻，只有一个进程可以进入临界区。</p><p>解决临界区问题必须满足的3个条件：</p><ol><li>互斥：进程在临界区，其他进程不能进入临界区</li><li>前进：没有进程在临界区，允许其他进程进入临界区，不能无限等待</li><li>有限等待：从一个进程作出进入临界区的请求到该进程进入临界区之间，其他进程进入临界区的请求个数有限</li></ol><p>忙则等待；空则让进；等则有限；等则让权</p><h3 id="3-Peterson算法"><a href="#3-Peterson算法" class="headerlink" title="3. Peterson算法"></a>3. Peterson算法</h3><p>适用于两个进程的临界区问题。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> flag[<span class="number">2</span>] = &#123;<span class="number">0</span>, <span class="number">0</span>&#125;; <span class="comment">// 表示哪个进程想要进入临界区,默认为false</span></span><br><span class="line"><span class="type">int</span> turn; <span class="comment">// 表示当前轮到哪个进程进入临界区</span></span><br><span class="line"><span class="comment">// P0</span></span><br><span class="line"><span class="keyword">while</span>(<span class="number">1</span>)&#123;</span><br><span class="line">    flag[<span class="number">0</span>] = <span class="number">1</span>; <span class="comment">// 表示进程0想进入临界区</span></span><br><span class="line">    turn = <span class="number">1</span>; <span class="comment">// 让进程1先进入临界区（等则让权）</span></span><br><span class="line">    <span class="keyword">while</span>(flag[<span class="number">1</span>] &amp;&amp; turn == <span class="number">1</span>); <span class="comment">// 等待进程1退出临界区</span></span><br><span class="line">    <span class="comment">// 临界区代码</span></span><br><span class="line">    flag[<span class="number">0</span>] = <span class="number">0</span>; <span class="comment">// 退出临界区</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// P1</span></span><br><span class="line"><span class="keyword">while</span>(<span class="number">1</span>)&#123;</span><br><span class="line">    flag[<span class="number">1</span>] = <span class="number">1</span>; <span class="comment">// 表示进程1想进入临界区</span></span><br><span class="line">    turn = <span class="number">0</span>; <span class="comment">// 让进程0先进入临界区</span></span><br><span class="line">    <span class="keyword">while</span>(flag[<span class="number">0</span>] &amp;&amp; turn == <span class="number">0</span>); <span class="comment">// 等待进程0退出临界区</span></span><br><span class="line">    <span class="comment">// 临界区代码</span></span><br><span class="line">    flag[<span class="number">1</span>] = <span class="number">0</span>; <span class="comment">// 退出临界区</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="4-硬件同步"><a href="#4-硬件同步" class="headerlink" title="4. 硬件同步"></a>4. 硬件同步</h3><p>许多系统为解决临界区问题提供了硬件支持</p><ol><li>修改共享变量禁止中断<ul><li>正在运行的指令不被其他指令抢占CPU</li><li>适用于单处理器环境，非抢占内核（不允许内核模式进程被抢占，同时刻只有一个内核模式进程） </li></ul></li><li>使用原子操作：不能被中断的原子指令</li></ol><h3 id="5-信号量-Semaphore"><a href="#5-信号量-Semaphore" class="headerlink" title="5. 信号量(Semaphore)"></a>5. 信号量(Semaphore)</h3><p>信号量是一种不需要忙等的进程同步机制（空则让进），本质是一个整数变量。</p><p>除初始化外，只能通过两个原子操作来修改：P（wait）和V（signal）。</p><ul><li>P操作：如果信号量值大于0，则将其减1并继续执行；如果信号量值为0，则阻塞进程，直到信号量值大于0。</li><li>V操作：将信号量值加1，如果有进程在等待，则唤醒一个等待的进程。</li></ul><p>信号量分为两种类型：</p><ol><li>二进制信号量（Binary Semaphore）：值只能为0或1，通常用于互斥访问临界区，又被称为互斥锁（Mutex）。</li><li>计数信号量（Counting Semaphore）：值可以为任意非负整数，通常用于控制对有限资源的访问。</li></ol><p>实现方案：忙等实现（S&gt;=0）和阻塞实现（S可以为负数，绝对值表示等待的进程数）。</p><p>忙等实现-自旋锁(Spinlock)：</p><ul><li>当一个进程位于其临界区时，其它任何试图进入临界区的进程都必须在其进入区的代码中连续循环</li><li>不用阻塞进程、不必上下文切换</li><li>临界区代码短时效率高</li><li>适合多处理器环境（单处理器可以通过简单的禁止中断实现wait和signal的原子执行）</li><li>单处理器系统忙等时不会释放CPU，也没有其他进程能够运行以获得CPU控制权</li></ul><h3 id="6-死锁和饥饿"><a href="#6-死锁和饥饿" class="headerlink" title="6. 死锁和饥饿"></a>6. 死锁和饥饿</h3><p>死锁（Deadlock）：两个或多个进程互相等待对方释放资源，导致所有进程都无法继续执行。</p><p>饥饿（Starvation）：进程无限等待信号量。对信号量有关的链表LIFO顺序增删进程可能导致。</p><h3 id="7-经典同步问题"><a href="#7-经典同步问题" class="headerlink" title="7. 经典同步问题"></a>7. 经典同步问题</h3><h4 id="7-1-存在先后关系的简单同步问题"><a href="#7-1-存在先后关系的简单同步问题" class="headerlink" title="7.1 存在先后关系的简单同步问题"></a>7.1 存在先后关系的简单同步问题</h4><p>将不同进程间的代码块的执行顺序视为DAG，进行拓扑排序：</p><p><img src="https://source.cclmsy.cc/posts/notes/course/operating_system/image-2.png" alt="alt text"></p><p>记信号量<code>Sij</code>表示进程<code>j</code>等待进程<code>i</code>的信号量（进程<code>i</code>执行完后才能执行进程<code>j</code>）</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// P1</span></span><br><span class="line"><span class="keyword">while</span>(<span class="number">1</span>)&#123;</span><br><span class="line">    wait(S21);</span><br><span class="line">    <span class="comment">// 临界区1代码</span></span><br><span class="line">    signal(S15);</span><br><span class="line"></span><br><span class="line">    wait(S54);</span><br><span class="line">    <span class="comment">// 临界区4代码</span></span><br><span class="line">    signal(S47);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// P2</span></span><br><span class="line"><span class="keyword">while</span>(<span class="number">1</span>)&#123;</span><br><span class="line">    <span class="comment">// 代码块2</span></span><br><span class="line">    signal(S21);</span><br><span class="line">    </span><br><span class="line">    wait(S15);</span><br><span class="line">    wait(S35);</span><br><span class="line">    <span class="comment">// 临界区5代码</span></span><br><span class="line">    signal(S54);</span><br><span class="line">    signal(S56);</span><br><span class="line"></span><br><span class="line">    wait(S47);</span><br><span class="line">    wait(S67);</span><br><span class="line">    <span class="comment">// 代码块7</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// P3略</span></span><br></pre></td></tr></table></figure><h4 id="7-2-生产者-消费者问题"><a href="#7-2-生产者-消费者问题" class="headerlink" title="7.2 生产者-消费者问题"></a>7.2 生产者-消费者问题</h4><p>生产者-消费者问题是经典的进程同步问题，涉及到两个进程：生产者和消费者。</p><p>生产者进程生成数据并将其放入缓冲区，消费者进程从缓冲区中取出数据进行处理。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 生产者</span></span><br><span class="line"><span class="keyword">while</span>(<span class="number">1</span>)&#123;</span><br><span class="line">    wait(empty); <span class="comment">// 等待缓冲区有空位</span></span><br><span class="line"></span><br><span class="line">    wait(mutex); <span class="comment">// 进入临界区</span></span><br><span class="line">    buffer[in] = produce_item(); <span class="comment">// 生产一个项目</span></span><br><span class="line">    in = (in + <span class="number">1</span>) % N; <span class="comment">// 更新输入指针</span></span><br><span class="line">    signal(mutex); <span class="comment">// 离开临界区</span></span><br><span class="line"></span><br><span class="line">    signal(full); <span class="comment">// 增加缓冲区满的计数</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 消费者</span></span><br><span class="line"><span class="keyword">while</span>(<span class="number">1</span>)&#123;</span><br><span class="line">    wait(full); <span class="comment">// 等待缓冲区有项目</span></span><br><span class="line"></span><br><span class="line">    wait(mutex); <span class="comment">// 进入临界区</span></span><br><span class="line">    consume_item(buffer[out]); <span class="comment">// 消费一个项目</span></span><br><span class="line">    out = (out + <span class="number">1</span>) % N; <span class="comment">// 更新输出指针</span></span><br><span class="line">    signal(mutex); <span class="comment">// 离开临界区</span></span><br><span class="line"></span><br><span class="line">    signal(empty); <span class="comment">// 增加缓冲区空的计数</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="7-3-读者-写者问题"><a href="#7-3-读者-写者问题" class="headerlink" title="7.3 读者-写者问题"></a>7.3 读者-写者问题</h4><p>读者-写者问题是经典的进程同步问题，涉及到多个读者和一个写者。</p><ul><li>读者：并发读取数据，不修改数据</li><li>写者：独占访问数据，修改数据</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 读者</span></span><br><span class="line"><span class="keyword">while</span>(<span class="number">1</span>)&#123;</span><br><span class="line">    wait(read_mutex); <span class="comment">// 进入读者临界区</span></span><br><span class="line">    read_count++; <span class="comment">// 增加读者计数</span></span><br><span class="line">    <span class="keyword">if</span> (read_count == <span class="number">1</span>) wait(write_mutex); <span class="comment">// 第一个读者阻塞写者</span></span><br><span class="line">    signal(read_mutex); <span class="comment">// 离开读者临界区</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 读取数据</span></span><br><span class="line">    read_data();</span><br><span class="line"></span><br><span class="line">    wait(read_mutex); <span class="comment">// 进入读者临界区</span></span><br><span class="line">    read_count--; <span class="comment">// 减少读者计数</span></span><br><span class="line">    <span class="keyword">if</span> (read_count == <span class="number">0</span>) signal(write_mutex); <span class="comment">// 最后一个读者释放写者</span></span><br><span class="line">    signal(read_mutex); <span class="comment">// 离开读者临界区</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 写者</span></span><br><span class="line"><span class="keyword">while</span>(<span class="number">1</span>)&#123;</span><br><span class="line">    wait(write_mutex); <span class="comment">// 进入写者临界区</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 写入数据</span></span><br><span class="line">    write_data();</span><br><span class="line"></span><br><span class="line">    signal(write_mutex); <span class="comment">// 离开写者临界区</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>进一步的：</p><ul><li>读者优先：直到无读者等待，写者才能进入临界区</li><li>写者优先：有写者等待时，读者不能进入临界区</li></ul><h4 id="7-4-哲学家就餐问题"><a href="#7-4-哲学家就餐问题" class="headerlink" title="7.4 哲学家就餐问题"></a>7.4 哲学家就餐问题</h4><p>哲学家就餐问题是经典的进程同步问题，涉及到5个哲学家和5个叉子。</p><p>如果所有哲学家都拿起左边的叉子，那么就会发生死锁。</p><p>解决思路：</p><ol><li>当4个叉子被拿起时，没有叉子的哲学家不能拿起叉子</li><li>任一哲学家拿起两个叉子前时，其他哲学家不能拿起叉子</li><li>…</li></ol><h2 id="七、死锁-Deadlock"><a href="#七、死锁-Deadlock" class="headerlink" title="七、死锁(Deadlock)"></a>七、死锁(Deadlock)</h2><h3 id="1-死锁的4个必要条件"><a href="#1-死锁的4个必要条件" class="headerlink" title="1. 死锁的4个必要条件"></a>1. 死锁的4个必要条件</h3><ol><li>互斥：至少有一个资源不能共享</li><li>占有并等待：一个进程至少持有一个资源，并等待其他资源（被其他进程持有）</li><li>非抢占：资源不能被抢占，只能由持有该资源的进程释放</li><li>循环等待：存在一个进程等待环，其中每个进程都在等待下一个进程持有的资源</li></ol><p>必须同时满足这四个条件才能发生死锁。</p><h4 id="例题"><a href="#例题" class="headerlink" title="例题"></a>例题</h4><p>假设有4个相同类型的资源被3个进程共享，每个进程最多需要2个资源，试证明这个系统不会死锁。</p><p>在任何情况下，即使所有进程都持有最大“不完全”资源（每个进程1个资源），系统中也总会剩下至少1个资源。这个剩余的资源足以让其中一个进程获得并完成任务，然后释放其占有的资源。</p><p>随着资源的释放，其他被阻塞的进程也能依次获得资源并完成任务。</p><p>因此，系统永远不会进入所有进程都无法继续执行的死锁状态。</p><h3 id="2-资源分配图"><a href="#2-资源分配图" class="headerlink" title="2. 资源分配图"></a>2. 资源分配图</h3><p>方形R表示资源，内部点个数表示资源数量；圆形P表示进程。</p><ul><li>P-&gt;R：表示进程P请求资源R</li><li>R-&gt;P：表示资源R被进程P占用</li></ul><p><img src="https://source.cclmsy.cc/posts/notes/course/operating_system/image-3.png" alt="alt text"></p><p>死锁判断：</p><ol><li>根据资源R的出边，划掉已被分配的资源</li><li>找到一个进程P，其所有请求（出边）都可被满足</li><li>释放进程P占用的资源R，并将其边从图中删除</li><li>重复步骤2和3，直到没有进程满足条件或所有进程都被释放</li></ol><h3 id="3-死锁的预防"><a href="#3-死锁的预防" class="headerlink" title="3. 死锁的预防"></a>3. 死锁的预防</h3><p>否定死锁的四个必要条件之一：</p><ol><li>互斥：非共享资源必须要有互斥条件，不能否定</li><li>占有并等待：降低资源利用率，并且可能导致饥饿<ol><li>执行前必须申请到所有资源</li><li>申请新资源前必须释放所有已占有的资源</li></ol></li><li>非抢占：使用范围有限，只能用于可保存和恢复的资源（寄存器、内存等）<ol><li>如果一个进程申请的资源不能立刻分配，已分配资源可被抢占</li></ol></li><li>循环等待：对所有资源的类型进行完全排序，要求每个进程按递增顺序申请资源</li></ol><h3 id="4-死锁的避免"><a href="#4-死锁的避免" class="headerlink" title="4. 死锁的避免"></a>4. 死锁的避免</h3><p>安全状态：存在一种顺序为所有进程分配资源，能够避免死锁</p><h4 id="4-1-资源分配图算法"><a href="#4-1-资源分配图算法" class="headerlink" title="4.1 资源分配图算法"></a>4.1 资源分配图算法</h4><p>[资源分配图]算法(#2-资源分配图)适用于每种资源类型只有一个实例的情况，核心思想是检测图中是否存在环路。</p><p>算法机制：</p><ol><li>除申请边和分配边外，引入一种新类型的边，称为需求边。<ul><li>需求边Pi-&gt;Rj 表示进程Pi可能在将来某个时候申请资源Rj。</li><li>需求边类似于申请边，但用虚线表示。</li></ul></li><li>当进程申请资源时，需求边变成申请边。</li><li>当资源分配给进程时，申请边变成分配边。</li><li>当进程释放资源时，分配边变成需求边。</li><li>系统必须事先要求资源，即当进程Pi开始执行时，所有需求边必须处于资源分配图。</li></ol><p>假设进程Pi申请资源Rj，只有在将申请边Pi-&gt;Rj变成分配边Rj-&gt;Pi，且不会导致资源分配图形成环时才允许申请。</p><h4 id="4-2-银行家算法"><a href="#4-2-银行家算法" class="headerlink" title="4.2 银行家算法"></a>4.2 银行家算法</h4><p>适用于每种资源类型有多个实例的情况。</p><p>当进程申请一组资源时，系统必须确定分配这些资源后系统是否仍处于安全状态。<br>如果是，就分配资源，否则，进程必须等待直到其他进程释放足够的资源。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 银行家算法</span></span><br><span class="line"><span class="type">int</span> n,m; <span class="comment">// n为进程数，m为资源种类数</span></span><br><span class="line"><span class="type">int</span> available[m]; <span class="comment">// 可用资源向量</span></span><br><span class="line"><span class="type">int</span> max[n][m]; <span class="comment">// 最大需求矩阵</span></span><br><span class="line"><span class="type">int</span> allocation[n][m]; <span class="comment">// 当前分配矩阵</span></span><br><span class="line"><span class="type">int</span> need[n][m]; <span class="comment">// 需求矩阵，need[i][j] = max[i][j] - allocation[i][j]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 安全性检查 </span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">is_safe</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">auto</span> work = available; <span class="comment">// 可用资源向量</span></span><br><span class="line">    <span class="keyword">auto</span> finish = <span class="built_in">vector</span>&lt;<span class="type">bool</span>&gt;(n, <span class="literal">false</span>); <span class="comment">// 进程完成标志</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; ++i)</span><br><span class="line">        <span class="comment">// 进程i未完成且需求小于等于可用资源</span></span><br><span class="line">        <span class="keyword">if</span>(finish[i]==<span class="literal">false</span> &amp;&amp; need[i] &lt;= work) &#123;</span><br><span class="line">            work += allocation[i]; <span class="comment">// 完成，释放资源</span></span><br><span class="line">            finish[i] = <span class="literal">true</span>; <span class="comment">// 标记进程i完成</span></span><br><span class="line">            i = <span class="number">-1</span>; <span class="comment">// 重置i，重新检查所有进程</span></span><br><span class="line">        &#125;</span><br><span class="line">    <span class="comment">// 检查是否所有进程都完成</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; ++i) &#123;</span><br><span class="line">        <span class="keyword">if</span>(finish[i] == <span class="literal">false</span>) <span class="keyword">return</span> <span class="literal">false</span>; <span class="comment">// 存在未完成进程，系统不安全</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>; <span class="comment">// 所有进程都完成，系统安全</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 资源请求算法</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">request_resources</span><span class="params">(<span class="type">int</span> i, vector&lt;<span class="type">int</span>&gt; request)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!(request&lt;= need[i])) <span class="keyword">return</span> <span class="literal">false</span>; <span class="comment">// 请求超过需求</span></span><br><span class="line">    <span class="keyword">if</span> (!(request &lt;= available)) <span class="keyword">return</span> <span class="literal">false</span>; <span class="comment">// 请求超过可用资源</span></span><br><span class="line">    <span class="comment">// 假设分配资源</span></span><br><span class="line">    available -= request; <span class="comment">// 更新可用资源</span></span><br><span class="line">    allocation[i] += request; <span class="comment">// 更新分配矩阵</span></span><br><span class="line">    need[i] -= request; <span class="comment">// 更新需求矩阵</span></span><br><span class="line">    <span class="keyword">if</span> (!<span class="built_in">is_safe</span>()) &#123; <span class="comment">// 检查是否安全</span></span><br><span class="line">        <span class="comment">// 如果不安全，回滚分配</span></span><br><span class="line">        available += request; <span class="comment">// 恢复可用资源</span></span><br><span class="line">        allocation[i] -= request; <span class="comment">// 恢复分配矩阵</span></span><br><span class="line">        need[i] += request; <span class="comment">// 恢复需求矩阵</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>; <span class="comment">// 请求失败</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="5-死锁的检测和恢复"><a href="#5-死锁的检测和恢复" class="headerlink" title="5. 死锁的检测和恢复"></a>5. 死锁的检测和恢复</h3><p>死锁检测算法：检测系统状态，确定系统是否出现了死锁。（原理类似于死锁避免）</p><p>恢复机制：终止（代价大）、资源抢占</p><h2 id="八、主存管理"><a href="#八、主存管理" class="headerlink" title="八、主存管理"></a>八、主存管理</h2><h3 id="1-内存管理单元MMU"><a href="#1-内存管理单元MMU" class="headerlink" title="1. 内存管理单元MMU"></a>1. 内存管理单元MMU</h3><p>在运行时完成逻辑地址到物理地址的转换的硬件被称为内存管理单元（Memory Management Unit, MMU）。</p><p>三种实现方法：连续内存分配、分页和分段</p><h3 id="2-连续内存分配"><a href="#2-连续内存分配" class="headerlink" title="2. 连续内存分配"></a>2. 连续内存分配</h3><p>内存保护：通过基址寄存器和界限寄存器来实现。</p><ul><li>基址寄存器：存储逻辑地址空间的起始地址</li><li>界限寄存器：存储逻辑地址空间的大小</li></ul><p>多分区方法：固定分区、<strong>可变分区</strong></p><p>孔：可用的内存块。<br>一开始整个内存是一个孔，随着进程的进入和中止，整个内存将遍布着许多大小不同的孔。</p><p>动态存储分配问题：根据一组空闲的孔和一个请求的大小，选择一个孔来满足请求。</p><p>三种分配策略：</p><ol><li>首次适应（First Fit）：从头开始搜索，找到第一个足够大的孔分配给进程。</li><li>最佳适应（Best Fit）：搜索所有孔，找到最小的足够大的孔分配给进程。</li><li>最差适应（Worst Fit）：搜索所有孔，找到最大的孔分配给进程。</li></ol><ul><li>首次适应和最佳适应在执行时间和利用空间方面都好于最差适应。</li><li>首次适应比最佳适应要快</li></ul><p>碎片：因太小而无法分配给任何进程的孔。</p><ul><li>外部碎片：由于分配和释放内存块后，剩余的内存块太小而无法满足新的请求，三种分配策略都可能导致外部碎片。</li><li>内部碎片：固定分区（分页）方法的问题，进程分配到的内存块比实际需要的要大，导致未使用的内存空间。</li></ul><p>解决外部碎片的方法：</p><ol><li>紧缩：移动内存内容，将所有空闲空间合并成一整块<ul><li>缺点：有条件限制（要求重定位是动态的）、开销大</li></ul></li><li>允许物理地址空间为非连续的（分页和分段）</li></ol><h3 id="3-分页（Paging）"><a href="#3-分页（Paging）" class="headerlink" title="3. 分页（Paging）"></a>3. 分页（Paging）</h3><h4 id="3-1-基本方法"><a href="#3-1-基本方法" class="headerlink" title="3.1 基本方法"></a>3.1 基本方法</h4><p>物理地址分为固定大小的块，称为<strong>帧</strong>(Frame)，逻辑地址分为同样大小的块，称为<strong>页</strong>(Page)。</p><p>内存的分配信息保存在称为<strong>帧表</strong>(frame table)的数据结构中</p><p>如果一个进程需要x页，则在内存在寻找x个空闲帧，如果有，则分配。</p><p>为进程分配内存时建立一个<strong>页表</strong>，用于将逻辑地址转换成物理地址，页表的指针与其他信息一起存入进程控制块。</p><p>页表基寄存器(PTBR)指向页表，切换页表只需改变PTBR的值即可。</p><p>页表长度寄存器(PTLB)表示页表的长度。</p><p>采用分页技术不会产生外部碎片，但是会有<strong>内部碎片</strong>。</p><p>分页的优点之一是可以共享共同代码：多个进程之间可以共享同一只读代码（重入代码）段的拷贝；私有独占代码和数据</p><p>记块大小$2^n$，物理内存大小为$2^k$，进程逻辑地址大小为$2^m$。</p><p>帧数：$2^{k-n}$，页数：$2^{m-n}$</p><p>逻辑地址高m-n位为(p)页表索引，低n位(d)为页偏移</p><p>假设每页4B：</p><p><img src="https://source.cclmsy.cc/posts/notes/course/operating_system/image-5.png" alt="alt text"></p><p><img src="https://source.cclmsy.cc/posts/notes/course/operating_system/image-4.png" alt="alt text"></p><h4 id="3-2-转换表缓冲TLB"><a href="#3-2-转换表缓冲TLB" class="headerlink" title="3.2 转换表缓冲TLB"></a>3.2 转换表缓冲TLB</h4><p>页表存储在内存中，每访问一个字节，需要两次访问内存（查找页表、找到需要的信息），针对这一问题的标准解决方案是关联内存(TLB)。</p><p>当关联内存根据给定值（页号）查找时，它会同时与所有键进行比较，如果找到条目，就得到相应的值域（帧号）</p><p>相当于页表的一个缓存，TLB的大小通常很小（几十个条目），因此需要使用替换算法</p><p>有效内存访问时间(Effective Memory Access Time, EMAT)：</p><script type="math/tex; mode=display">EMAT = (T+\epsilon)\alpha + (2T+\epsilon)(1-\alpha)</script><ul><li>T：访问一次内存的时间</li><li>ε：访问一次TLB的时间</li><li>α：TLB命中率</li><li>第一项：TLB命中，访问一次内存</li><li>第二项：TLB未命中，访问两次内存</li></ul><h4 id="3-3-页表的结构"><a href="#3-3-页表的结构" class="headerlink" title="3.3 页表的结构"></a>3.3 页表的结构</h4><ol><li>层次化页表：将页表分为多个层次，每个层次的页表只包含一部分页表项，减少内存占用。</li><li>哈希页表：使用哈希函数将页号映射到页表项，减少内存占用</li><li>反向页表：每个物理帧对应一个页表项，记录哪个进程的哪个页映射到该帧</li></ol><p><img src="https://source.cclmsy.cc/posts/notes/course/operating_system/image-6.png" alt="alt text"></p><h4 id="3-4-例题1"><a href="#3-4-例题1" class="headerlink" title="3.4 例题1"></a>3.4 例题1</h4><p>页面大小为4KB，逻辑地址24KB，页表的内容为：[2,5,6,8,3,11]。<br>则逻辑地址12293转换成物理地址为多少？给出计算过程。</p><p>12293D=011|0000,0000,0101B</p><p>页号p=011=3 =&gt; 帧号8</p><p>页内偏移d=101=5</p><p>物理地址=帧号<em>页大小+页内偏移=8</em>4KB+5=32768+5=32773</p><h4 id="3-5-例题2"><a href="#3-5-例题2" class="headerlink" title="3.5 例题2"></a>3.5 例题2</h4><p>如果访问一次内存要1.5ns，快表的命中率为85%，查找快表的时间为0.5ns。计算该系统的有效访问时间。</p><p>EMAT = (T + ε)α + (2T + ε)(1 - α) = (1.5 + 0.5) <em> 0.85 + (2 </em> 1.5 + 0.5) * (1 - 0.85)</p><h3 id="4-分段（Segmentation）"><a href="#4-分段（Segmentation）" class="headerlink" title="4. 分段（Segmentation）"></a>4. 分段（Segmentation）</h3><p>分段是指将逻辑地址空间划分成一组段，每个段都有名称和长度。<br>地址指定了段名和段内偏移。<br>因此用户可通过两个量来指定地址段名和偏移，编译器会自动根据用户程序构造段。</p><p>逻辑地址由两个元素组成：&lt;段号s，段内偏移d&gt;</p><p>段表：将二维的用户定义地址映射为一维物理地址。段表的每个条目都包含：</p><ul><li>基地址：包含段的起始地址</li><li>界限：指定段的长度</li></ul><p>段表基地址寄存器（STBR）指向内存中的段表所在的物理地址</p><p>段表界限寄存器（STLR）指示程序所用的段的个数，段号S小于STLR的时候才是有效的</p><h3 id="5-比较"><a href="#5-比较" class="headerlink" title="5. 比较"></a>5. 比较</h3><div class="table-container"><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">连续内存分配</th><th style="text-align:center">分页</th><th style="text-align:center">分段</th></tr></thead><tbody><tr><td style="text-align:center">外部碎片</td><td style="text-align:center">有</td><td style="text-align:center">无</td><td style="text-align:center">有</td></tr><tr><td style="text-align:center">内部碎片</td><td style="text-align:center">无</td><td style="text-align:center">有</td><td style="text-align:center">无</td></tr><tr><td style="text-align:center">代码共享</td><td style="text-align:center">不可以</td><td style="text-align:center">可以</td><td style="text-align:center">可以</td></tr></tbody></table></div><h3 id="6-其他"><a href="#6-其他" class="headerlink" title="6. 其他"></a>6. 其他</h3><p>地址映射是指将程序中的<strong>逻辑</strong>地址转换为内存中的<strong>物理</strong>地址。</p><p>在分页管理系统中，为实现地址转换设置了控制寄存器，其中存放的是<strong>页表</strong>在内存中的起始地址。</p><p>存储管理应具有的功能包括：<strong>内存分配与回收</strong>，<strong>地址映射</strong>，<strong>内存保护</strong>和<strong>内存扩充</strong>。</p><p>在分页式虚拟内存中，当发现某页不在<strong>页表</strong>中，将产生缺页中断。若内存没有空闲帧，则需要进行<strong>页面置换</strong>。如果算法选择不合理，可能会出现频繁的页面调度，系统产生<strong>抖动</strong>现象。</p><h2 id="九、虚拟内存"><a href="#九、虚拟内存" class="headerlink" title="九、虚拟内存"></a>九、虚拟内存</h2><h3 id="1-有效访问时间"><a href="#1-有效访问时间" class="headerlink" title="1. 有效访问时间"></a>1. 有效访问时间</h3><p>有效访问时间（Effective Access Time, EAT）是指在虚拟内存系统中，平均每次访问内存所需的时间。</p><p>EAT的计算公式为：</p><script type="math/tex; mode=display">EAT = (1 - p) \times T + p \times S</script><ul><li>p：缺页率（Page Fault Rate），表示访问内存时发生缺页的概率</li><li>T：平均内存访问时间</li><li>S：平均页错误处理时间</li></ul><p>实现按需页面调度要解决的两个问题：</p><ol><li>帧分配：内存中存在多个进程，需要决定每个进程分配多少帧</li><li>页面置换：当内存满时，需要决定将哪个页面换出，原则：最小页错误率</li></ol><h3 id="2-页面置换算法"><a href="#2-页面置换算法" class="headerlink" title="2. 页面置换算法"></a>2. 页面置换算法</h3><p>页面置换的基本方法：</p><ol><li>查找所需页在磁盘上的位置。</li><li>查找空闲帧<ul><li>如果有空闲帧，那么就使用它；</li><li>如果没有空闲帧，就使用页面置换算法选择一个“牺牲”帧。</li><li>将“牺牲”帧的内容写到磁盘上，修改页表和帧表。</li></ul></li><li>将所需的页读入空闲帧，修改页表和帧表。</li><li>重启进程。</li></ol><h3 id="3-FIFO页面置换算法"><a href="#3-FIFO页面置换算法" class="headerlink" title="3. FIFO页面置换算法"></a>3. FIFO页面置换算法</h3><p>FIFO（First In First Out）页面置换算法是最简单的页面置换算法。</p><figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">  1 , 2 , 3 , 4 , 1 , 2 , 5 , 1 , 2 , 3 , 4 , 5</span><br><span class="line"></span><br><span class="line">|<span class="string"> 1*</span>|<span class="string"> 1 </span>|<span class="string"> 1 </span>|<span class="string"> 4*</span>|<span class="string"> 4 </span>|<span class="string"> 4 </span>|<span class="string"> 5*</span>|<span class="string">   </span>|<span class="string">   </span>|<span class="string"> 5 </span>|<span class="string"> 5 </span>|<span class="string"> H </span>|</span><br><span class="line">|<span class="string">   </span>|<span class="string"> 2*</span>|<span class="string"> 2 </span>|<span class="string"> 2 </span>|<span class="string"> 1*</span>|<span class="string"> 1 </span>|<span class="string"> 1 </span>|<span class="string"> H </span>|<span class="string">   </span>|<span class="string"> 3*</span>|<span class="string"> 3 </span>|<span class="string">   </span>|</span><br><span class="line">|<span class="string">   </span>|<span class="string">   </span>|<span class="string"> 3*</span>|<span class="string"> 3 </span>|<span class="string"> 3 </span>|<span class="string"> 2*</span>|<span class="string"> 2 </span>|<span class="string">   </span>|<span class="string"> H </span>|<span class="string"> 2 </span>|<span class="string"> 4*</span>|<span class="string">   </span>|</span><br></pre></td></tr></table></figure><p>页错误次数：9</p><p>规律：不计命中，自某帧进入内存开始会出现n次，n为内存帧数</p><p>Belady异常：页错误率可能会随着所分配的帧数的增加而增加，如上例增加为4帧时：</p><figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">  1 , 2 , 3 , 4 , 1 , 2 , 5 , 1 , 2 , 3 , 4 , 5</span><br><span class="line"></span><br><span class="line">|<span class="string"> 1*</span>|<span class="string"> 1 </span>|<span class="string"> 1 </span>|<span class="string"> 1 </span>|<span class="string"> H </span>|<span class="string">   </span>|<span class="string"> 5*</span>|<span class="string"> 5 </span>|<span class="string"> 5 </span>|<span class="string"> 5 </span>|<span class="string"> 4*</span>|<span class="string"> 4 </span>|</span><br><span class="line">|<span class="string">   </span>|<span class="string"> 2*</span>|<span class="string"> 2 </span>|<span class="string"> 2 </span>|<span class="string">   </span>|<span class="string"> H </span>|<span class="string"> 2 </span>|<span class="string"> 1*</span>|<span class="string"> 1 </span>|<span class="string"> 1 </span>|<span class="string"> 1 </span>|<span class="string"> 5*</span>|</span><br><span class="line">|<span class="string">   </span>|<span class="string">   </span>|<span class="string"> 3*</span>|<span class="string"> 3 </span>|<span class="string">   </span>|<span class="string">   </span>|<span class="string"> 3 </span>|<span class="string"> 3 </span>|<span class="string"> 2*</span>|<span class="string"> 2 </span>|<span class="string"> 2 </span>|<span class="string"> 2 </span>|</span><br><span class="line">|<span class="string">   </span>|<span class="string">   </span>|<span class="string">   </span>|<span class="string"> 4*</span>|<span class="string">   </span>|<span class="string">   </span>|<span class="string"> 4 </span>|<span class="string"> 4 </span>|<span class="string"> 4 </span>|<span class="string"> 3*</span>|<span class="string"> 3 </span>|<span class="string"> 3 </span>|</span><br></pre></td></tr></table></figure><h3 id="4-最优页面置换OPT"><a href="#4-最优页面置换OPT" class="headerlink" title="4. 最优页面置换OPT"></a>4. 最优页面置换OPT</h3><p>最优页面置换算法（Optimal Page Replacement）是理论上最好的页面置换算法。</p><p>选择将来最长时间不被访问的页面进行置换。</p><figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">  1 , 2 , 3 , 4 , 1 , 2 , 5 , 1 , 2 , 3 , 4 , 5</span><br><span class="line"></span><br><span class="line">|<span class="string"> 1*</span>|<span class="string"> 1 </span>|<span class="string"> 1 </span>|<span class="string"> 1 </span>|<span class="string"> H </span>|<span class="string">   </span>|<span class="string"> 1 </span>|<span class="string"> H </span>|<span class="string">   </span>|<span class="string"> 3*</span>|<span class="string"> 3 </span>|<span class="string">   </span>|</span><br><span class="line">|<span class="string">   </span>|<span class="string"> 2*</span>|<span class="string"> 2 </span>|<span class="string"> 2 </span>|<span class="string">   </span>|<span class="string"> H </span>|<span class="string"> 2 </span>|<span class="string">   </span>|<span class="string"> H </span>|<span class="string"> 2 </span>|<span class="string"> 4*</span>|<span class="string">   </span>|</span><br><span class="line">|<span class="string">   </span>|<span class="string">   </span>|<span class="string"> 3*</span>|<span class="string"> 4*</span>|<span class="string">   </span>|<span class="string">   </span>|<span class="string"> 5*</span>|<span class="string">   </span>|<span class="string">   </span>|<span class="string"> 5 </span>|<span class="string"> 5 </span>|<span class="string"> H </span>|</span><br></pre></td></tr></table></figure><p>页错误次数：7</p><h3 id="5-LRU页面置换算法"><a href="#5-LRU页面置换算法" class="headerlink" title="5. LRU页面置换算法"></a>5. LRU页面置换算法</h3><p>LRU（Least Recently Used）页面置换算法是基于最近最少使用原则的页面置换算法。</p><p>LRU算法选择最久未被访问的页面进行置换。</p><figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">  1 , 2 , 3 , 4 , 1 , 2 , 5 , 1 , 2 , 3 , 4 , 5</span><br><span class="line"></span><br><span class="line">|<span class="string"> 1*</span>|<span class="string"> 1 </span>|<span class="string"> 1 </span>|<span class="string"> 4*</span>|<span class="string"> 4 </span>|<span class="string"> 4 </span>|<span class="string"> 5*</span>|<span class="string">   </span>|<span class="string">   </span>|<span class="string"> 3*</span>|<span class="string"> 5 </span>|<span class="string"> H </span>|</span><br><span class="line">|<span class="string">   </span>|<span class="string"> 2*</span>|<span class="string"> 2 </span>|<span class="string"> 2 </span>|<span class="string"> 1*</span>|<span class="string"> 1 </span>|<span class="string"> 1 </span>|<span class="string"> H </span>|<span class="string">   </span>|<span class="string"> 1 </span>|<span class="string"> 4*</span>|<span class="string">   </span>|</span><br><span class="line">|<span class="string">   </span>|<span class="string">   </span>|<span class="string"> 3*</span>|<span class="string"> 3 </span>|<span class="string"> 3 </span>|<span class="string"> 2*</span>|<span class="string"> 2 </span>|<span class="string">   </span>|<span class="string"> H </span>|<span class="string"> 2 </span>|<span class="string"> 2 </span>|<span class="string">   </span>|</span><br></pre></td></tr></table></figure><p>页错误次数：9</p><p>OPT和LRU没有Belady异常。</p><h2 id="十、文件系统"><a href="#十、文件系统" class="headerlink" title="十、文件系统"></a>十、文件系统</h2><h3 id="1-概念"><a href="#1-概念" class="headerlink" title="1. 概念"></a>1. 概念</h3><ul><li>文件属性：名称、类型、位置、大小、时间戳、权限等</li><li>文件操作：创建、删除、读、写、重定位等</li><li>文件类型：扩展名</li></ul><h3 id="2-访问方法"><a href="#2-访问方法" class="headerlink" title="2. 访问方法"></a>2. 访问方法</h3><ol><li>顺序访问：从头到尾依次访问文件内容<ul><li>read_next(), write_next(), reset()等</li></ul></li><li>直接访问（随机访问、相对访问）：可以直接跳转到文件的任意位置进行读写操作<ul><li>read(n), write(n), position_to(n)等</li></ul></li><li>索引访问：使用索引表来快速定位文件中的数据块</li></ol><h3 id="3-文件的路径名"><a href="#3-文件的路径名" class="headerlink" title="3. 文件的路径名"></a>3. 文件的路径名</h3><p><code>盘符:\目录1\目录2\...\文件名.扩展名</code></p><p>相对路径、绝对路径</p><h3 id="4-目录与磁盘结构"><a href="#4-目录与磁盘结构" class="headerlink" title="4. 目录与磁盘结构"></a>4. 目录与磁盘结构</h3><ol><li>单层目录：所有文件都在同一目录下，命名冲突、分组问题</li><li>双层目录：每个用户有自己的目录，用户目录下有文件</li><li>树形目录：典型，相对路径、绝对路径都唯一</li><li>无环图目录：有多条路径访问同一文件<ul><li>命名：一个文件可有多个绝对路径名，不同文件名可能表示同一文件</li><li>删除：删除文件导致悬挂指针（指向不存在的文件或者执行了其他文件）</li></ul></li><li>通用图目录：有多条路径访问同一文件或目录</li></ol><h2 id="十一、文件系统实现（磁盘分配方法）"><a href="#十一、文件系统实现（磁盘分配方法）" class="headerlink" title="十一、文件系统实现（磁盘分配方法）"></a>十一、文件系统实现（磁盘分配方法）</h2><h3 id="1-连续分配"><a href="#1-连续分配" class="headerlink" title="1. 连续分配"></a>1. 连续分配</h3><p>每个文件在磁盘上占用一组连续的块。</p><p>优点：</p><ol><li>简单：只需要块起始地址和块长度（占用几个块）就能访问文件 </li><li>访问连续分配的文件所需的寻道时间最小 </li><li>支持随机访问</li></ol><p>缺点：</p><ol><li>外部碎片：随着文件的创建和删除，磁盘上会产生外部碎片，导致无法分配连续空间</li><li>有时创建文件时不能确定文件的大小</li><li>文件不能动态扩展</li></ol><h3 id="2-链接分配"><a href="#2-链接分配" class="headerlink" title="2. 链接分配"></a>2. 链接分配</h3><p>每个文件是磁盘块的链表，每个块包含下一个块的地址。</p><p>优点：</p><ol><li>简单：只需要起始地址；</li><li>利用率高：没有外部碎片，只要有空闲块，文件就能增大</li></ol><p>缺点：</p><ol><li>只能用于文件的顺序访问，不支持文件的直接访问。</li><li>指针需要空间，磁盘空间有一部分用于存储指针。</li><li>可靠性低：如果指针丢失或损坏可能牵连到空闲空间列表。</li></ol><h3 id="3-索引分配（散列分配）"><a href="#3-索引分配（散列分配）" class="headerlink" title="3. 索引分配（散列分配）"></a>3. 索引分配（散列分配）</h3><p>将所有指针放在一起，形成一个索引块，索引块包含文件的所有块的地址。</p><p>索引块方案：链接索引、多级索引、组合方案</p><h2 id="十二、大容量存储结构（磁盘）"><a href="#十二、大容量存储结构（磁盘）" class="headerlink" title="十二、大容量存储结构（磁盘）"></a>十二、大容量存储结构（磁盘）</h2><h3 id="1-磁盘速度"><a href="#1-磁盘速度" class="headerlink" title="1. 磁盘速度"></a>1. 磁盘速度</h3><p>磁盘的访问时间：</p><ul><li>数据传输时间：驱动器与计算机之间的数据传输速率</li><li>定位时间/随机访问时间<ul><li>寻道时间：磁头移动到柱面所需的时间  </li><li>旋转延时：等待扇区旋转到磁头下所需的时间</li></ul></li></ul><h3 id="2-磁盘调度"><a href="#2-磁盘调度" class="headerlink" title="2. 磁盘调度"></a>2. 磁盘调度</h3><p>假设有一个磁盘队列，其I/O对各个柱面上块的请求顺序：98, 183, 37, 122, 14, 124, 65, 67，磁头位于53号柱面</p><p>寻道距离：寻道顺序下，相邻项序号之差的绝对值之和</p><p>调度时间=寻道距离×平均寻道时间+旋转延时×旋转次数</p><h4 id="2-1-FCFS"><a href="#2-1-FCFS" class="headerlink" title="2.1 FCFS"></a>2.1 FCFS</h4><p>寻道顺序：53-&gt;98-&gt;183-&gt;37-&gt;122-&gt;14-&gt;124-&gt;65-&gt;67</p><p>寻道距离：640</p><p><img src="https://source.cclmsy.cc/posts/notes/course/operating_system/image-7.png" alt="alt text"></p><h4 id="2-2-SSTF-最短寻道时间优先"><a href="#2-2-SSTF-最短寻道时间优先" class="headerlink" title="2.2 SSTF 最短寻道时间优先"></a>2.2 SSTF 最短寻道时间优先</h4><p>优先前往距离当前磁头位置最近的请求。</p><p>寻道顺序：53-&gt;65-&gt;67-&gt;37-&gt;14-&gt;98-&gt;122-&gt;124-&gt;183</p><p>寻道距离：236</p><p><img src="https://source.cclmsy.cc/posts/notes/course/operating_system/image-8.png" alt="alt text"></p><h4 id="2-3-SCAN-扫描算法"><a href="#2-3-SCAN-扫描算法" class="headerlink" title="2.3 SCAN 扫描算法"></a>2.3 SCAN 扫描算法</h4><p>磁臂丛磁盘的一端移动到另一端，当磁头移过每个柱面时，处理该柱面上的请求；到达另一端时返回并依次处理柱面上的请求。</p><p>寻道顺序：53-&gt;37-&gt;14-&gt;(0)-&gt;65-&gt;67-&gt;98-&gt;122-&gt;124-&gt;183</p><p>寻道距离：208+28(到达0造成的多余寻道距离)=236</p><p><img src="https://source.cclmsy.cc/posts/notes/course/operating_system/image-9.png" alt="alt text"></p><h4 id="2-4-C-SCAN-循环扫描算法"><a href="#2-4-C-SCAN-循环扫描算法" class="headerlink" title="2.4 C-SCAN 循环扫描算法"></a>2.4 C-SCAN 循环扫描算法</h4><p>提供更加均匀的等待时间，磁头移动到另一端后立即返回磁盘开始，返回时不处理请求。 </p><p>寻道顺序：53-&gt;65-&gt;67-&gt;98-&gt;122-&gt;124-&gt;183-&gt;(199)-&gt;(0)-&gt;14-&gt;37</p><p>寻道距离：382</p><p><img src="https://source.cclmsy.cc/posts/notes/course/operating_system/image-10.png" alt="alt text"></p><h4 id="2-5-LOOK-C-LOOK-调度算法"><a href="#2-5-LOOK-C-LOOK-调度算法" class="headerlink" title="2.5 LOOK/C-LOOK 调度算法"></a>2.5 LOOK/C-LOOK 调度算法</h4><p>和SCAN/C-SCAN对应，LOOK调度算法只扫描到最后一个请求的柱面，然后返回。</p><p>C-LOOK寻道顺序：53-&gt;65-&gt;67-&gt;98-&gt;122-&gt;124-&gt;183-&gt;14-&gt;37</p><p>寻道距离：322</p><p><img src="https://source.cclmsy.cc/posts/notes/course/operating_system/image-11.png" alt="alt text"></p><h2 id="十三、I-O系统"><a href="#十三、I-O系统" class="headerlink" title="十三、I/O系统"></a>十三、I/O系统</h2><h3 id="1-I-O硬件"><a href="#1-I-O硬件" class="headerlink" title="1. I/O硬件"></a>1. I/O硬件</h3><ol><li>轮询（Polling）：I/O设备传输数据时CPU处于忙等状态，CPU不断检查设备状态，直到设备准备好数据。<ul><li>并发性差、I/O效率低。</li></ul></li><li>中断（Interrupt）：I/O设备传输数据时，CPU可以为其它进程服务，每传输完一个字节，由I/O设备向CPU发送中断请求信号。<ul><li>并发性好，传送大批数据时I/O效率低。</li><li>适用于低速外设，如键盘、鼠标等</li></ul></li><li>内存直接访问(DMA)：CPU提供源地址、目标地址以及字节数，完成整块数据传输后产生一次中断<ul><li>并发性好，可一次性传送大批数据，效率高</li><li>适用于高速外设，如磁盘、网络等</li></ul></li></ol><h3 id="2-中断和陷阱"><a href="#2-中断和陷阱" class="headerlink" title="2. 中断和陷阱"></a>2. 中断和陷阱</h3><p>中断：操作系统中发生某一事件时，硬件将触发一个中断，中断信号通过中断向量将控制程序转移到合适的终端服务程序，以改变CPU的执行过程</p><p>陷阱：陷阱是由软件产生的，一般由用户请求或者错误引起，主要用于调用操作系统服务或者捕捉算法错误。</p>]]></content>
    
    
    <summary type="html">操作操作系统操作计算机完成操作（乐</summary>
    
    
    
    <category term="课程笔记" scheme="https://www.cclmsy.cc/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="课程笔记" scheme="https://www.cclmsy.cc/tags/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>论文笔记|MLLM-as-a-Judge for Image Safety without Human Labeling</title>
    <link href="https://www.cclmsy.cc/posts/2501.00192.html"/>
    <id>https://www.cclmsy.cc/posts/2501.00192.html</id>
    <published>2025-06-13T16:00:00.000Z</published>
    <updated>2025-07-21T05:57:26.023Z</updated>
    
    <content type="html"><![CDATA[<p>论文：<a href="https://arxiv.org/abs/2501.00192">MLLM-as-a-Judge for Image Safety without Human Labeling</a></p><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>方向：Image Safety Judgment（图像安全性判断）</p><p>现有方案（Traditional Classifer、MLLM）极度依赖人工标注数据，有效但耗费时间和资源</p><p>一种“<strong>利用预训练MLLM的能力，根据一套安全规则，以0-Shot方式判断图像安全性</strong>”的方案受到关注。</p><p>对MLLM进行安全性规则查询不足以实现可靠的安全性检测，原因有以下三点：</p><ol><li><strong>安全性规则描述模糊或具有主观性</strong>。样例询问“不适合公众观看的内容”描述笼统，不同人对“不适合”的理解可能不同</li><li><strong>当前的MLLM难以推理复杂冗长的安全性规则</strong>。样例询问包含2个分句25个英文单词，MLLM可能无法完全理解</li><li><strong>MLLM存在固有偏差</strong>。样例询问“是否有喉部伤口“，即使图片中只有地面和毛发上有血迹，MLLM也可能会错误地认为有喉部伤口</li></ol><p><img src="https://source.cclmsy.cc/posts/notes/papers/2501.00192/image.png" alt="alt text"></p><p>为了解决这些问题，本文提出了<strong>CLUE</strong>（<strong>C</strong>ontrastive M<strong>L</strong>LM J<strong>u</strong>dg<strong>e</strong>），显著提高了MLLM 0-Shot Image Safety Judge的有效性</p><ol><li>将安全性规则<strong>客观化</strong>，转化为MLLM可以有效处理的客观、可行的规则</li><li>一次检查一个规则<ul><li>为了处理复杂或冗长的规则，每条规则转化为一组逻辑上完整的<strong>前提条件链</strong></li><li>为了加快所有规则的迭代过程，采用<strong>多模态对比模型</strong>（如CLIP）衡量规则和图像的相关性</li></ul></li><li>进行<strong>去偏标记概率分析（debiased token probability analysis）</strong>，使用去偏概率预测结果<ul><li>减少由语言先验和非图像中心区域造成的偏差</li></ul></li></ol><p>当标记概率分析置信度低时，CLUE会使用思维链进行深入推理。</p><h2 id="2-BG"><a href="#2-BG" class="headerlink" title="2. BG"></a>2. BG</h2><ol><li>Image Content Safety 图像内容安全</li><li>Safety Judge Model 安全性判断模型<ul><li>最初的传统分类器（Traditional Classifier）、最近的微调LLM<ul><li>局限：人工标注耗时且昂贵</li></ul></li><li>近期：0-shot MLLM（Multimodal Large Language Model）<ul><li>性能不令人满意</li></ul></li></ul></li></ol><h2 id="3-Method"><a href="#3-Method" class="headerlink" title="3. Method"></a>3. Method</h2><h3 id="问题模型"><a href="#问题模型" class="headerlink" title="问题模型"></a>问题模型</h3><p>给定一张图像$x$和一组安全性规则$G$，有以下2个目标：</p><ol><li>确定图像$x$是否违反了$G$中的任何规则</li><li>提供识别出的违反规则的列表</li></ol><p>表示为：$A(x,G)\rightarrow(s,R)$</p><ul><li>$s$：识别结果（安全/不安全）</li><li>$R$：违反的具体安全规则</li></ul><h3 id="3-1-Rules-Objectification-规则客观化"><a href="#3-1-Rules-Objectification-规则客观化" class="headerlink" title="3.1 Rules Objectification 规则客观化"></a>3.1 Rules Objectification 规则客观化</h3><p>将LLM作为优化器（LLM-as-an-Optimizer）对规则进行客观化。</p><p>让LLM对每条规则进行1~10分的打分，修改分数低于阈值（9）的规则，直到达到9分。</p><p>LLM客观性评估Prompt：</p><p><img src="https://source.cclmsy.cc/posts/notes/papers/2501.00192/image-1.png" alt="alt text"></p><p>原始规则集：</p><p><img src="https://source.cclmsy.cc/posts/notes/papers/2501.00192/image-2.png" alt="alt text"></p><p>客观化后的规则集：</p><p><img src="https://source.cclmsy.cc/posts/notes/papers/2501.00192/image-3.png" alt="alt text"></p><p>以第4条为例，“挨着另一个人躺在床上的人”的7分描述修改为“两个互相接触的人躺在床上”的9分描述”</p><h3 id="3-2-Relevance-Scanning-相关性扫描"><a href="#3-2-Relevance-Scanning-相关性扫描" class="headerlink" title="3.2 Relevance Scanning 相关性扫描"></a>3.2 Relevance Scanning 相关性扫描</h3><p>MLLM处理复杂结构时推理能力有限，不能把所有规则一次性输入。<br>尝试枚举规则输入，但是效率不高，而且很多规则可能和图片无关。<br>因此，需要过滤掉与图像无关的规则，减少MLLM的工作量以提高效率。</p><p>CLUE使用了预训练的文本图像编码器CLIP，通过计算余弦相似度来衡量规则和图像的相关性。</p><p>满足<script type="math/tex">cos(I(x),T(r))>t</script>的规则$r$被认为与图像$x$相关</p><ul><li>$I(x)$：图像$x$的CLIP编码</li><li>$T(r)$：规则$r$的CLIP编码</li><li>$t$：阈值</li></ul><p>使用编码器的好处：速度（比MLLM）明显快，因为和MLLM数十亿的参数数量相比，Encoder的大小要小得多</p><p>实验证明，t设置为0.22时，能够过滤掉67%的不相关规则，同时保留96.6%的实际违规规则</p><h3 id="3-3-Precondition-Extraction-前提条件提取"><a href="#3-3-Precondition-Extraction-前提条件提取" class="headerlink" title="3.3 Precondition Extraction 前提条件提取"></a>3.3 Precondition Extraction 前提条件提取</h3><p>自动将每条规则转化为一组逻辑上完整的前提条件链，便于MLLM更好地理解处理。</p><p>例如“不应描绘人物或动物身体上带有清晰可见、血腥且可能会导致其立即死亡的伤害”被转化为：</p><ol><li>图中有可见的人 OR 图中有可见的动物</li><li>身体带有清晰可见的血腥伤害</li><li>伤害可能会导致其立即死亡</li></ol><p><img src="https://source.cclmsy.cc/posts/notes/papers/2501.00192/image-4.png" alt="alt text"></p><p>LLM前提条件提取Prompt：</p><p><img src="https://source.cclmsy.cc/posts/notes/papers/2501.00192/image-5.png" alt="alt text"></p><h3 id="3-4-Debiased-Token-Probability-Analysis-去偏标记概率分析"><a href="#3-4-Debiased-Token-Probability-Analysis-去偏标记概率分析" class="headerlink" title="3.4 Debiased Token Probability Analysis 去偏标记概率分析"></a>3.4 Debiased Token Probability Analysis 去偏标记概率分析</h3><p>给定MLLM $\mathcal{M}$、图像$x$和前提条件$c$，我们将前提条件得分记为：</p><p><img src="https://source.cclmsy.cc/posts/notes/papers/2501.00192/image-6.png" alt="alt text"></p><p>也就是面对图像$x$，MLLM对前提条件$c$标记为“Yes”的概率。</p><p>如果高于一定值，则认为图像$x$满足了前提条件$c$。</p><p>一个直观的想法是把阈值设为0.5，但这个方法存在问题。</p><p>MLLM具有token probability bias（标记概率偏差），即材料本身的含义或属性会对模型的输出产生误导。</p><h4 id="3-4-1-Bias-from-Language-Prior-语言先验偏差"><a href="#3-4-1-Bias-from-Language-Prior-语言先验偏差" class="headerlink" title="3.4.1 Bias from Language Prior 语言先验偏差"></a>3.4.1 Bias from Language Prior 语言先验偏差</h4><p>研究表明，MLLM的标记概率会受到模型语言先验的影响。</p><p>在InternVL2-76B上，大部分图像对于“血腥伤害可能会导致其立即死亡”的“Yes”标记概率都很低，因为根据训练数据，这种内容通常不会出现在图像中。</p><p>解决策略：衡量有无图像token查询之间的得分差异。</p><script type="math/tex; mode=display">\mathcal{M}(x, c) - \mathcal{M}(None, c)</script><ul><li>低于0，则图像$x$很可能不满足前提条件$c$；</li><li>明显高于0，图像$x$极有可能满足前提条件$c$</li></ul><h4 id="3-4-2-Bias-from-Image-来自图像的偏差"><a href="#3-4-2-Bias-from-Image-来自图像的偏差" class="headerlink" title="3.4.2 Bias from Image 来自图像的偏差"></a>3.4.2 Bias from Image 来自图像的偏差</h4><p>图像的非核心部分也会带来强烈的偏差。</p><p>比如图像中的人上半身裸体，MLLM对提问“这个人裸露臀部”的“Yes”标记概率会很高，因为根据训练数据，上半身裸露和臀部裸露具有较强的相关性。</p><p>解决策略：衡量整幅图像和删除图像核心区域$i$后图像之间的得分差异</p><script type="math/tex; mode=display">\mathcal{M}(x, c) - \mathcal{M}(x \ominus i, c)</script><p><img src="https://source.cclmsy.cc/posts/notes/papers/2501.00192/image-7.png" alt="alt text"></p><ul><li>使用最先进的开放词汇对象检测器OWLv2</li><li>明显高于0，且对象检测边界框置信度较高（0.05），图像$x$极有可能满足前提条件$c$</li></ul><h3 id="3-5-Reasoning-based-Judgment"><a href="#3-5-Reasoning-based-Judgment" class="headerlink" title="3.5 Reasoning-based Judgment"></a>3.5 Reasoning-based Judgment</h3><p>如果基于去偏标记概率分析的置信度不够，CLUE会采用基于推理的判断。</p><p>分为2步：</p><ol><li><strong>思维链生成</strong><ul><li>使用LLM生成思维链，推理图像是否满足前提条件</li><li>对格式不做要求</li></ul></li><li><strong>格式化</strong>：以Json格式输出预测结果和理由</li></ol><p>响应速度慢，但在之前步骤置信度不足的情况下，可以提供更可靠的结果。</p><h3 id="3-6-Algorithm"><a href="#3-6-Algorithm" class="headerlink" title="3.6 Algorithm"></a>3.6 Algorithm</h3><p><img src="https://source.cclmsy.cc/posts/notes/papers/2501.00192/image-8.png" alt="alt text"></p><h2 id="4-个人思考"><a href="#4-个人思考" class="headerlink" title="4. 个人思考"></a>4. 个人思考</h2><h3 id="4-1-论文亮点"><a href="#4-1-论文亮点" class="headerlink" title="4.1 论文亮点"></a>4.1 论文亮点</h3><h4 id="4-1-1-摆脱对人工标注的依赖"><a href="#4-1-1-摆脱对人工标注的依赖" class="headerlink" title="4.1.1 摆脱对人工标注的依赖"></a>4.1.1 摆脱对人工标注的依赖</h4><ol><li>采用0-Shot方式，不需要人工标注数据</li><li>扩展性、适应性强，如果安全规则发生变化，只需要更新规则集，无需重新标注数据、微调模型</li><li>表现优异：结果远高于baseline（不论是0-Shot还是基于fine-tuning的方法）</li></ol><h3 id="4-1-2-洞察与解决MLLM的偏差问题"><a href="#4-1-2-洞察与解决MLLM的偏差问题" class="headerlink" title="4.1.2 洞察与解决MLLM的偏差问题"></a>4.1.2 洞察与解决MLLM的偏差问题</h3><ol><li>作者洞察到Pre-trained MLLM在处理图像安全性判断时存在偏差问题</li><li>提出了去偏标记概率分析（debiased token probability analysis）的方法，针对语言先验和图像非核心区域分别进行去偏处理</li></ol><h3 id="4-1-3-规则客观化与前提条件提取"><a href="#4-1-3-规则客观化与前提条件提取" class="headerlink" title="4.1.3 规则客观化与前提条件提取"></a>4.1.3 规则客观化与前提条件提取</h3><ol><li>考虑了安全规则描述可能具有模糊性和主观性的问题</li><li>通过LLM对规则进行客观化处理，确保规则描述清晰、可操作</li><li>对规则进行前提条件提取，将复杂规则转化为逻辑上完整的前提条件链，便于MLLM处理</li></ol><h3 id="4-1-4-多阶段推理流程"><a href="#4-1-4-多阶段推理流程" class="headerlink" title="4.1.4 多阶段推理流程"></a>4.1.4 多阶段推理流程</h3><ol><li>通过相关性扫描过滤不相关规则，减少MLLM的工作量</li><li>在去偏标记概率分析置信度不足时，采用思维链进行深入推理，结合了两者的优势</li></ol><h2 id="4-2-论文存在的问题"><a href="#4-2-论文存在的问题" class="headerlink" title="4.2 论文存在的问题"></a>4.2 论文存在的问题</h2><h3 id="4-2-1-规则客观化的局限性"><a href="#4-2-1-规则客观化的局限性" class="headerlink" title="4.2.1 规则客观化的局限性"></a>4.2.1 规则客观化的局限性</h3><ol><li>仅使用简短的Prompt提示LLM进行1~10分的评分，但并没有具体的评分标准或示例，可能导致评分结果不一致</li><li>不能保证LLM的评分就是客观准确的。<ul><li>LLM本身就因训练数据等原因存在偏差，甚至可能产生幻觉</li><li>每一次调用LLM的结果可能会有所不同，缺乏一致性</li></ul></li><li>LLM可能根据自己的理解将规则修改为子规则，而遗漏部分情况，影响判断结果</li></ol><h3 id="4-2-2-未考虑MLLM受对抗攻击的影响"><a href="#4-2-2-未考虑MLLM受对抗攻击的影响" class="headerlink" title="4.2.2 未考虑MLLM受对抗攻击的影响"></a>4.2.2 未考虑MLLM受对抗攻击的影响</h3><p>MLLM已被证明易受对抗性攻击：小幅度修改输入图像，导致模型输出错误的结果。</p><p>一篇研究<a href="https://arxiv.org/abs/2505.21494">《Adversarial Attacks against Closed-Source MLLMs via Feature Optimal Alignment》</a>甚至可以对闭源的MLLM进行对抗攻击。</p><p>CLUE中就存在多个可能被对抗攻击的环节：</p><ol><li>CLIP编码器的相关性扫描：设计一个不安全的图像，其对抗性扰动专门针对CLIP模型 ，使其对相关安全规则产生低相关性分数，从而导致大部分相关规则被过滤掉，进而减少图像被判断为不安全的可能性</li><li>由于前提条件提取，复杂规则被分解为多个前提条件，攻击者可以针对个别条件进行对抗性扰动，使得某些前提条件的标记概率低于阈值</li></ol><h2 id="4-3-改进思路和建议"><a href="#4-3-改进思路和建议" class="headerlink" title="4.3 改进思路和建议"></a>4.3 改进思路和建议</h2><h3 id="4-3-1-规则客观化的改进"><a href="#4-3-1-规则客观化的改进" class="headerlink" title="4.3.1 规则客观化的改进"></a>4.3.1 规则客观化的改进</h3><ol><li>引入评分标准：为LLM评分提供明确的标准和示例，确保评分的一致性和客观性</li><li>多模型并行取平均：根据同一规则，调用多个不同的LLM进行评分，取平均值，减少单一模型偏差的影响</li></ol><h3 id="4-3-2-增强对抗攻击的防御"><a href="#4-3-2-增强对抗攻击的防御" class="headerlink" title="4.3.2 增强对抗攻击的防御"></a>4.3.2 增强对抗攻击的防御</h3><p>一个实用、免训练的方法是采用模型集成。<br>2020年9月的一篇论文<a href="https://arxiv.org/abs/2009.09612">《Improving Ensemble Robustness by Collaboratively Promoting and Demoting Adversarial Robustness》</a>提出基于集合的对抗训练是实现对抗攻击鲁棒性的一种方法。</p><p>例如，让多款不同的MLLM（如InternVL、LLaVA、GPT-4V）对同一张图片进行判断，并要求达成共识，这可以提高鲁棒性，因为针对某一模型的攻击可能无法迁移到其他模型上。</p>]]></content>
    
    
    <summary type="html">阅读论文《MLLM-as-a-Judge for Image Safety without Human Labeling》</summary>
    
    
    
    <category term="论文笔记" scheme="https://www.cclmsy.cc/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="论文笔记" scheme="https://www.cclmsy.cc/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    <category term="MLLLM" scheme="https://www.cclmsy.cc/tags/MLLLM/"/>
    
    <category term="CV" scheme="https://www.cclmsy.cc/tags/CV/"/>
    
  </entry>
  
  <entry>
    <title>论文笔记&amp;实现|PlugIR：基于对话的图像检索系统</title>
    <link href="https://www.cclmsy.cc/posts/2406.03411.html"/>
    <id>https://www.cclmsy.cc/posts/2406.03411.html</id>
    <published>2025-04-09T16:00:00.000Z</published>
    <updated>2025-07-21T05:38:29.270Z</updated>
    
    <content type="html"><![CDATA[<p>论文：<a href="https://arxiv.org/abs/2406.03411">Interactive Text-to-ImageRetrieval with Large Language Models: A Plug-and-Play Approach</a></p><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>ChatIR是一种基于聊天的文本到图像的方法，提出了利用LLM进行多轮对话以提高检索效率。（我的阅读笔记见<a href="https://www.cclmsy.cc/posts/2305.20062.html">Link</a>）</p><p>这个方法具有以下不足：</p><ol><li>需要进行微调文本编码器，来适应多轮对话数据<ul><li>微调耗费资源、可扩展性差。</li><li>解决方法：将对话重构为可以直接输入到预训练的视觉语言模型的格式，不需要对模型进行微调</li></ul></li><li>LLM提问者G只知道对话历史，无法查看候选图像<ul><li>可能生成图像中不存在的属性的询问</li><li>LLM提问者基于候选集提问，确保问题与图像属性相关</li></ul></li></ol><p>本文提出的PlugIR系统包含2个部分：上下文重构（Context Reformulation）和上下文感知对话生成（Context-aware Dialogue Generation）</p><p><img src="https://source.cclmsy.cc/posts/notes/papers/2406.03411/PlugIR.png" alt="PlugIR"></p><p>本文贡献：</p><ol><li>实证0样本或微调的大模型难以理解对话数据</li><li>提出了一种LLM提问者，解决了因冗余问题和噪声问题带来的性能瓶颈</li><li>提出新指标BRI（最佳对数排名积分，Best log Rank Integral）<ul><li>比Recall@K和Hit@K更接近人的评价，更全面地评估交互式检索系统</li></ul></li><li>PlugIR具有即插即用的特性，且具有实用性</li></ol><h2 id="2-Related-Work"><a href="#2-Related-Work" class="headerlink" title="2. Related Work"></a>2. Related Work</h2><ul><li>文本到图像检索</li><li>视觉语言模型：BLIP、CLIP</li><li>大语言模型LLM</li></ul><h2 id="3-Method"><a href="#3-Method" class="headerlink" title="3. Method"></a>3. Method</h2><h3 id="3-1-Preliminaries-InteractiveText-to-Image-Retrieval-交互式文本到图像检索"><a href="#3-1-Preliminaries-InteractiveText-to-Image-Retrieval-交互式文本到图像检索" class="headerlink" title="3.1 Preliminaries:InteractiveText-to-Image Retrieval 交互式文本到图像检索"></a>3.1 Preliminaries:InteractiveText-to-Image Retrieval 交互式文本到图像检索</h3><p>对话记录表示：$D_i = (C, Q_1, A_1, …, Q_i)$</p><ul><li>$C$：目标图像的初始文本描述（标题）</li><li>$Q_i$：第i个问题</li><li>$A_i$：第i个回答</li></ul><p>检索系统将数据库中的所有图片与文本进行匹配，根据相似度进行排序，根据目标排名评估系统性能。</p><ul><li>Recall@K：本轮交互检索到的前K张图片包含目标的概率</li><li>Hit@K：本轮以及任意一轮的交互检索到的前K张图片包含目标的概率</li></ul><h3 id="3-2-Context-Reformulation-上下文重构"><a href="#3-2-Context-Reformulation-上下文重构" class="headerlink" title="3.2 Context Reformulation 上下文重构"></a>3.2 Context Reformulation 上下文重构</h3><p>作者测试了0样本的CLIP、BLIP、BLIP-2和一个黑箱模型ATM</p><ul><li>Hit@K逐步提升，但这是由其定义决定的</li><li>Recall@K在仅包含最初的文本描述时最高，随着对话轮次增加而下降<ul><li>对话在0样本模型上可能没有贡献、产生了噪声</li><li>0样本模型无法理解对话数据</li></ul></li></ul><p>为了解决这个问题，一种方法是像ChatIR一样对模型进行微调，但这样做有以下限制：</p><ol><li>不能使用黑箱模型，比如ATM</li><li>需要大量的训练数据</li></ol><p>本文不直接使用对话作为输入进行查询，而是将对话重构为可以直接输入到预训练的视觉语言模型的格式，不需要对模型进行微调（即所谓的Plug-and-Play）。</p><h3 id="3-3-Context-aware-Dialogue-Generation-上下文感知对话生成"><a href="#3-3-Context-aware-Dialogue-Generation-上下文感知对话生成" class="headerlink" title="3.3 Context-aware Dialogue Generation 上下文感知对话生成"></a>3.3 Context-aware Dialogue Generation 上下文感知对话生成</h3><p>仅靠对话历史生成问题具有以下问题：</p><ol><li>生成的问题可能与图像属性无关</li><li>可能询问历史对话中已有信息</li></ol><p>提问过程（用于解决问题1）：</p><ol><li>使用重构后的查询语句进行检索，找出高相似度的“检索候选”图像集</li><li>对候选图像Embeddings进行K-means聚类，得到每个候选图像与其他图像的相似度得分分布</li><li>对于每个聚类，选择<code>相似度分布熵</code>最小的图像作为代表<ul><li>熵越小，属性越真实、越容易区分</li><li>例如，同一组图像对“一张配有2台电脑显示器和一副键盘的桌子”的描述熵更低，对“办公室”的描述熵更高</li></ul></li><li>将这K副图像通过image2text模型生成caption，作为附加信息提供给LLM提问者</li></ol><p>提问（算法1）伪代码：</p><ol><li>输入：对话上下文$c$、图像库$I$、“检索候选”图像数$n$、聚类数$m$、相似度函数$sim$、$KMeans$、i2t模型$Captioning$</li><li>从$I$中选出前$n$个和$c$最相似的图像，作为$S_R$<ol><li>初始化$S_R \leftarrow {}$</li><li>$while S_R.size() &lt; n do$<ol><li>将和$c$最相似的图像$x$加入$S_R$</li><li>将$x$从$I$中移除</li></ol></li></ol></li><li>对$S_R$进行$KMeans$聚类，得到$m$个聚类$S_R^{(1)}, S_R^{(2)}, …, S_R^{(m)}$</li><li>计算每个图像相对$S<em>R$的概率，使用Softmax得到$P_c(x)=\frac{exp(sim(c, x))}{\sum</em>{x’ \in S_R} exp(sim(c, x’))}$</li><li>从每个簇$S_R^{(i)}$中选择最优的图像，并对这$m$个图像进行$Captioning$，得到$T$<ol><li>$for i in range(1,m+1) do$<ol><li>计算当前簇$S_R^{(i)}$中所有图像的熵，并找出最小熵的图像$\hat x^{(i)}$</li><li>对$\hat x^{(i)}$进行$Captioning$，并加入$T$</li></ol></li></ol></li><li>返回：$T$</li></ol><p>采用思维链（Chain of Thought）的方法，提示词位于原文18~19页，获取与图像相关的问题。<br>这样生成的问题仍然可能冗余（已经知道答案），还需要经过过滤。</p><p>过滤过程（用于解决问题2）：</p><ol><li>通过上下文回答函数，判断问题是否“确定”，选取“不确定”的问题</li><li>选择“不确定”的问题中KL散度最小的问题<ol><li>KL散度：$KL(P<em>c||P</em>{c,q})=\sum<em>{x \in T} P_c(x)log\frac{P_c(x)}{P</em>{c,q}(x)}$</li><li>用于防止不合适的问题导致相似度骤变</li></ol></li></ol><p>过滤（算法2）伪代码：</p><ol><li>输入：对话上下文$c$、问题集合$Q$、检索候选集$T$、相似度函数$sim$、上下文回答函数$Answer$</li><li>定义计算上下文概率分布的函数<ol><li>图像$x$在上下文$c$下的分布：$P<em>c(x)=\frac{exp(sim(c, x))}{\sum</em>{x’ \in T} exp(sim(c, x’))}$</li><li>加入问题$q$后图像$x$在上下文$c$下的分布：$P<em>{c,q}(x)=\frac{exp(sim(concat(c, q), x))}{\sum</em>{x’ \in T} exp(sim(concat(c, q), x’))}$</li></ol></li><li>筛选出答案“不确定”的问题，作为 $Q’$<ol><li>初始化 $Q’ \leftarrow {}$</li><li>$for q in Q do$<ol><li>如果 $Answer(c, q)$ 为“不确定”，则加入 $Q’$</li></ol></li></ol></li><li>选择KL散度最小的问题 $\hat q$</li><li>返回：$\hat q$</li></ol><h3 id="3-4-The-Best-Log-Rank-Integral-BRI-Metric-最佳对数排名积分"><a href="#3-4-The-Best-Log-Rank-Integral-BRI-Metric-最佳对数排名积分" class="headerlink" title="3.4 The Best Log Rank Integral (BRI) Metric 最佳对数排名积分"></a>3.4 The Best Log Rank Integral (BRI) Metric 最佳对数排名积分</h3><p>作者指出，在评估交互式检索系统时，有3个关键点：</p><ol><li>用户满意度：在多少次交互中至少找到了一次目标图像算满意</li><li>效率：成功检索所需轮次越少越好</li><li>排名提升意义：排名靠前时提升排名的意义更大，如从2到1比从100到99更有意义</li></ol><p>Recall@K用于非交互式检索；Hit@K只考虑了用户满意度</p><p>作者提出了BRI指标，综合了用户满意度、效率和排名提升意义</p><p>记：$Q$问题集合、$T$最大轮次</p><p>$\pi(q_t)$：表示具有$t$轮对话的查询$q_t$，在这$t$轮查询中，目标图像的历史最佳排名，用于衡量用户满意度</p><p>BRI：$\mathbb E<em>{q \in Q}\left[ \dfrac{1}{2T}\log\pi(q_0)\pi(q_T)+\dfrac{1}{T}\sum\limits</em>{t=1}^{T-1}\log\pi(q_t)\right]$</p><ul><li>边界项：$\dfrac{1}{2T}\log\pi(q_0)\pi(q_T)$<ul><li>权重较小，反映初始查询$q_0$到最终查询$q_T$的排名改善情况</li></ul></li><li>平均查询排名项：$\dfrac{1}{T}\sum\limits_{t=1}^{T-1}\log\pi(q_t)$<ul><li>计算了查询$q$的所有$t$轮中，目标的历史最佳排名的对数的均值</li><li>对数函数使得低排名的进一步降低对BRI变化的影响更大</li></ul></li><li>BRI越小，性能越好</li><li>BRI不依赖于具体的K值，更全面、统一</li><li>实验表明，BRI与人类评价更接近</li></ul><h2 id="4-Experiments"><a href="#4-Experiments" class="headerlink" title="4. Experiments"></a>4. Experiments</h2><ul><li>数据集：Visdail、COCO、Flickr30k</li><li>文本到图像检索模型：默认BLIP，也有BLIP-2、ATM</li><li>LLM提问者：ChatGPT</li><li>测试集回答者：BLIP-2</li><li>聚类数m：10</li></ul><p>Baseline：0-shot、ChatIR</p><p>同时进行了Ablation Study，测试了不同组件的加入对结果的影响</p><h2 id="总结和实现"><a href="#总结和实现" class="headerlink" title="总结和实现"></a>总结和实现</h2><ul><li>PlugIR系统也是一个基于对话的图像检索系统，在ChatIR的基础上进行了改进</li><li>主要优化了提问过程，使得提问的有效性提升</li><li>使用了新的评估指标BRI，能够更全面地评估交互式检索系统</li></ul><p>由于系统代码量较大，在实现时划分到多个文件</p><h3 id="config-py"><a href="#config-py" class="headerlink" title="config.py"></a>config.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">config = &#123;</span><br><span class="line">    <span class="string">&quot;hitk&quot;</span> : <span class="number">10</span>, <span class="comment"># hit@k</span></span><br><span class="line">    <span class="string">&quot;q_num&quot;</span> : <span class="number">5</span>, <span class="comment"># 待select的问题数量</span></span><br><span class="line">    <span class="string">&quot;threshold_low&quot;</span> : <span class="number">500</span>, <span class="comment"># 低阈值，用于计算Kmeans聚类时的样本数</span></span><br><span class="line">    <span class="string">&quot;gpt_model&quot;</span> : <span class="string">&#x27;gpt-4o-mini&#x27;</span>, <span class="comment"># OpenAI模型名称</span></span><br><span class="line">    <span class="string">&quot;api_key&quot;</span> : <span class="string">&quot;&quot;</span>, <span class="comment"># OpenAI API密钥</span></span><br><span class="line">    <span class="string">&quot;vqa_model&quot;</span> : <span class="string">&#x27;Salesforce/blip2-flan-t5-xl&#x27;</span>, <span class="comment"># VQA模型名称</span></span><br><span class="line">    <span class="string">&quot;retriever&quot;</span> : <span class="string">&quot;blip&quot;</span>, <span class="comment"># 检索器名称，blip或clip</span></span><br><span class="line">    <span class="string">&quot;device&quot;</span> : torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>),</span><br><span class="line">    <span class="string">&quot;sep_token&quot;</span> : <span class="string">&quot;, &quot;</span>, <span class="comment"># ChatIR分隔符</span></span><br><span class="line">    <span class="string">&quot;eval_caption&quot;</span> : <span class="literal">True</span>, <span class="comment"># eval时是否为PlugIR总结的Caption，True：PlugIR，False：ChatIR</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 算法配置</span></span><br><span class="line">    <span class="string">&quot;referring&quot;</span> : <span class="literal">True</span>, <span class="comment"># 是否参考候选集Caption提问（算法1）</span></span><br><span class="line">    <span class="string">&quot;filtering&quot;</span> : <span class="literal">True</span>, <span class="comment"># 是否AI过滤问题（算法2）</span></span><br><span class="line">    <span class="string">&quot;select&quot;</span> : <span class="literal">True</span>, <span class="comment"># 是否使用KL散度选择问题（算法2）</span></span><br><span class="line">    <span class="string">&quot;reconstruct&quot;</span> : <span class="literal">True</span>, <span class="comment"># 是否重构对话</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 路径配置</span></span><br><span class="line">    <span class="comment"># 图片路径前缀，路径=dir_prefix+&lt;img_path&gt;(&quot;unlabeled2017/xxx.jpg&quot;)</span></span><br><span class="line">    <span class="string">&quot;dir_prefix&quot;</span> : <span class="string">&quot;./&quot;</span>, </span><br><span class="line">    <span class="comment"># Visdial数据，[&#123;&quot;img&quot;:&quot;&lt;img_path&gt;&quot;, &quot;dialog&quot;:[&quot;&lt;caption&gt;&quot;, &quot;Q? A&quot;, &quot;Q? A&quot;, ...]&#125;, ...]，2064</span></span><br><span class="line">    <span class="string">&quot;visdial_path&quot;</span> : <span class="string">&quot;./dialogues/VisDial_v1.0_queries_val.json&quot;</span>, </span><br><span class="line">    <span class="comment"># 搜索空间，[&quot;&lt;img_path&gt;&quot;, &quot;&lt;img_path&gt;&quot;, ...]，50000</span></span><br><span class="line">    <span class="string">&quot;search_space&quot;</span> : <span class="string">&quot;./Protocol/Search_Space_val_50k.json&quot;</span>, </span><br><span class="line"><span class="comment"># Visdial数据，仅保留caption，[&#123;&quot;id&quot;: &quot;&lt;img_path&gt;&quot;, &quot;caption&quot;: [&quot;&lt;caption&gt;&quot;]&#125;,...]，50000</span></span><br><span class="line">    <span class="string">&quot;captions_path&quot;</span> : <span class="string">&quot;./ChatIR/ChatIR_Protocol/visdial_captions.json&quot;</span>,</span><br><span class="line">    <span class="comment"># blip预处理的embeddings</span></span><br><span class="line">    <span class="string">&quot;img_emb_path&quot;</span> : <span class="string">&quot;./ChatIR/temp/corpus_finetuned_blip.pth&quot;</span>, </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="OpenAI-py"><a href="#OpenAI-py" class="headerlink" title="OpenAI.py"></a>OpenAI.py</h3><p>所有函数统一返回response对象，包含了所有信息。</p><p>messages.py中定义了消息格式，包含prompt信息，具体文本见论文附录。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> openai</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> API.messages <span class="keyword">as</span> messages</span><br><span class="line"><span class="keyword">from</span> config <span class="keyword">import</span> config</span><br><span class="line"></span><br><span class="line">client = openai.OpenAI(api_key=config[<span class="string">&quot;api_key&quot;</span>])</span><br><span class="line"></span><br><span class="line">SEED = <span class="number">1021</span> <span class="comment"># 随机种子 <span class="doctag">TODO:</span>不设置的效果</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">reconstruct_dialog</span>(<span class="params">dialog:<span class="built_in">list</span>[<span class="built_in">str</span>], temperature:<span class="built_in">float</span>=<span class="number">.0</span>, model:<span class="built_in">str</span>=<span class="string">&#x27;gpt-4o-mini&#x27;</span></span>)-&gt;<span class="built_in">str</span>:</span><br><span class="line"><span class="string">&quot;&quot;&quot;重构对话框</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">将对话中的有效信息总结为一段描述。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Args:</span></span><br><span class="line"><span class="string">dialog : 对话列表</span></span><br><span class="line"><span class="string">temperature : 采样温度，越小越保守 [0.0,2.0]</span></span><br><span class="line"><span class="string">model : 模型名称</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">retry_count = <span class="number">0</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">response = client.chat.completions.create(</span><br><span class="line">model=model,</span><br><span class="line">messages=messages.reconstruct_dialog_message(dialog),</span><br><span class="line">n=<span class="number">1</span>,</span><br><span class="line">temperature=temperature,</span><br><span class="line">seed=SEED,</span><br><span class="line">max_tokens=<span class="number">512</span>)</span><br><span class="line"><span class="keyword">break</span></span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">retry_count += <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Error: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">time.sleep(<span class="number">3</span>)</span><br><span class="line"><span class="keyword">if</span> retry_count &gt; <span class="number">5</span>:</span><br><span class="line"><span class="keyword">raise</span> Exception(<span class="string">&quot;Retry limit exceeded!&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Retry <span class="subst">&#123;retry_count&#125;</span> times...&quot;</span>)</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line"><span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_questions</span>(<span class="params">dialog:<span class="built_in">list</span>[<span class="built_in">str</span>], n:<span class="built_in">int</span>=<span class="number">1</span>, model:<span class="built_in">str</span>=<span class="string">&#x27;gpt-4o-mini&#x27;</span></span>)-&gt;<span class="built_in">list</span>[<span class="built_in">str</span>]:</span><br><span class="line"><span class="string">&quot;&quot;&quot;Baseline: 1-shot生成问题 ChatIR</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">仅参考历史对话生成新的问题。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Args:</span></span><br><span class="line"><span class="string">dialog : 对话列表</span></span><br><span class="line"><span class="string">n : 生成问题数量</span></span><br><span class="line"><span class="string">model : 模型名称</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">response :</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">retry_count = <span class="number">0</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">response = client.chat.completions.create(</span><br><span class="line">model=model,</span><br><span class="line">messages=messages.generate_questions_message(dialog),</span><br><span class="line">n=n,</span><br><span class="line">temperature=<span class="number">0.5</span>,</span><br><span class="line">max_tokens=<span class="number">32</span>)</span><br><span class="line"><span class="keyword">break</span></span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">retry_count += <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Error: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">time.sleep(<span class="number">3</span>)</span><br><span class="line"><span class="keyword">if</span> retry_count &gt; <span class="number">5</span>:</span><br><span class="line"><span class="keyword">raise</span> Exception(<span class="string">&quot;Retry limit exceeded!&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Retry <span class="subst">&#123;retry_count&#125;</span> times...&quot;</span>)</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_questions_referring</span>(<span class="params">dialog:<span class="built_in">list</span>[<span class="built_in">str</span>], prompt_related_captions:<span class="built_in">str</span>=<span class="string">&quot;&quot;</span>, questions:<span class="built_in">list</span>=[], n:<span class="built_in">int</span>=<span class="number">1</span>, model=<span class="string">&#x27;gpt-4o-mini&#x27;</span></span>):</span><br><span class="line"><span class="string">&quot;&quot;&quot;利用思维链CoT和候选集Captions生成新问题</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Args:</span></span><br><span class="line"><span class="string">dailog : 对话列表</span></span><br><span class="line"><span class="string">prompt_related_captions : 预处理的候选集Caption</span></span><br><span class="line"><span class="string">questions : 历史问答对</span></span><br><span class="line"><span class="string">n : 生成问题数量</span></span><br><span class="line"><span class="string">model : 模型名称</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">retry_count = <span class="number">0</span></span><br><span class="line">message = messages.generate_questions_referring_message(dialog, prompt_related_captions, questions)</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">response = client.chat.completions.create(</span><br><span class="line">model=model,</span><br><span class="line">messages=message,</span><br><span class="line">n=<span class="number">1</span>,</span><br><span class="line">temperature=<span class="number">0.5</span>,</span><br><span class="line">max_tokens=<span class="number">32</span>)</span><br><span class="line"><span class="keyword">break</span></span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">retry_count += <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Error: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">time.sleep(<span class="number">3</span>)</span><br><span class="line"><span class="keyword">if</span> retry_count &gt; <span class="number">5</span>:</span><br><span class="line"><span class="keyword">raise</span> Exception(<span class="string">&quot;Retry limit exceeded!&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Retry <span class="subst">&#123;retry_count&#125;</span> times...&quot;</span>)</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">filter_questions</span>(<span class="params">context:<span class="built_in">str</span>, question:<span class="built_in">str</span>, model=<span class="string">&#x27;gpt-4o-mini&#x27;</span></span>):</span><br><span class="line"><span class="string">&quot;&quot;&quot;过滤问题</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">判断问题是否“Uncertain”</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Args:</span></span><br><span class="line"><span class="string">context : 上下文</span></span><br><span class="line"><span class="string">question : 问题</span></span><br><span class="line"><span class="string">model : 模型名称</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">retry_count = <span class="number">0</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">response = client.chat.completions.create(</span><br><span class="line">model=model,</span><br><span class="line">messages=messages.filter_questions_message(context, question),</span><br><span class="line">n=<span class="number">1</span>,</span><br><span class="line">temperature=<span class="number">.0</span>,</span><br><span class="line">max_tokens=<span class="number">32</span>)</span><br><span class="line"><span class="keyword">break</span></span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">retry_count += <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Error: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">time.sleep(<span class="number">3</span>)</span><br><span class="line"><span class="keyword">if</span> retry_count &gt; <span class="number">5</span>:</span><br><span class="line"><span class="keyword">raise</span> Exception(<span class="string">&quot;Retry limit exceeded!&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Retry <span class="subst">&#123;retry_count&#125;</span> times...&quot;</span>)</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">paraphrase</span>(<span class="params">text:<span class="built_in">str</span>=<span class="string">&quot;&quot;</span>, model=<span class="string">&#x27;gpt-4o-mini&#x27;</span></span>):</span><br><span class="line"><span class="string">&quot;&quot;&quot;重述</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">重述给定的文本。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Args:</span></span><br><span class="line"><span class="string">text : 待重述文本</span></span><br><span class="line"><span class="string">model : 模型名称</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">retry_count = <span class="number">0</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">response = client.chat.completions.create(</span><br><span class="line">model=model,</span><br><span class="line">messages=messages.paraphrase(text),</span><br><span class="line">n=<span class="number">1</span>,</span><br><span class="line">temperature=<span class="number">0.7</span>,</span><br><span class="line">top_p=<span class="number">0.8</span>,</span><br><span class="line">max_tokens=<span class="number">512</span>)</span><br><span class="line"><span class="keyword">break</span></span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">retry_count += <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Error: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">time.sleep(<span class="number">3</span>)</span><br><span class="line"><span class="keyword">if</span> retry_count &gt; <span class="number">5</span>:</span><br><span class="line"><span class="keyword">raise</span> Exception(<span class="string">&quot;Retry limit exceeded!&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Retry <span class="subst">&#123;retry_count&#125;</span> times...&quot;</span>)</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> response</span><br></pre></td></tr></table></figure><h3 id="utils-py"><a href="#utils-py" class="headerlink" title="utils.py"></a>utils.py</h3><p>实现了特征提取、K-means聚类、KL散度计算、获取簇中心caption、熵计算等函数功能，使主程序代码简洁易读。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.nn.functional <span class="keyword">import</span> normalize</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> BlipForImageTextRetrieval,AutoProcessor</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> InterpolationMode</span><br><span class="line"><span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> config <span class="keyword">import</span> config</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./Protocol/visdial_captions.json&#x27;</span>, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> ss_cap_json:</span><br><span class="line">captions = json.load(ss_cap_json) <span class="comment"># length:50000</span></span><br><span class="line"><span class="comment"># &#123;&quot;id&quot;: &quot;&lt;img_path&gt;&quot;, &quot;caption&quot;: [&quot;&lt;caption&gt;&quot;]&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BlipForRetrieval</span>(<span class="title class_ inherited__">BlipForImageTextRetrieval</span>):</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_text_features</span>(<span class="params"></span></span><br><span class="line"><span class="params">self,</span></span><br><span class="line"><span class="params">input_ids: torch.LongTensor, <span class="comment"># Tokenized input IDs</span></span></span><br><span class="line"><span class="params">attention_mask: torch.LongTensor | <span class="literal">None</span> = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">return_dict: <span class="built_in">bool</span>|<span class="literal">None</span> = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params"></span>) -&gt; torch.FloatTensor:</span><br><span class="line"><span class="string">&quot;&quot;&quot;获取文本特征</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Args:</span></span><br><span class="line"><span class="string">input_ids : 文本的token ID（即经过分词后的输入）</span></span><br><span class="line"><span class="string">attention_mask : 注意力掩码</span></span><br><span class="line"><span class="string">return_dict : 是否返回字典</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">return_dict=return_dict <span class="keyword">if</span> return_dict <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> self.config.use_return_dict</span><br><span class="line"></span><br><span class="line">text_embeddings = self.text_encoder(</span><br><span class="line">input_ids=input_ids,</span><br><span class="line">attention_mask=attention_mask,</span><br><span class="line">return_dict=return_dict,</span><br><span class="line">)</span><br><span class="line">text_embeddings = text_embeddings[<span class="number">0</span>] <span class="keyword">if</span> <span class="keyword">not</span> return_dict <span class="keyword">else</span> text_embeddings.last_hidden_state</span><br><span class="line"><span class="keyword">return</span> normalize(self.text_proj(text_embeddings[:, <span class="number">0</span>, :]), dim=-<span class="number">1</span>) <span class="comment"># [:,0,:]取的是[CLS]标记的隐藏状态，它通常被用作整个句子的特征表示</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_image_features</span>(<span class="params"></span></span><br><span class="line"><span class="params">self,</span></span><br><span class="line"><span class="params">pixel_values: torch.FloatTensor,</span></span><br><span class="line"><span class="params">output_attentions: <span class="built_in">bool</span> | <span class="literal">None</span> = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">output_hidden_states: <span class="built_in">bool</span> | <span class="literal">None</span> = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">return_dict: <span class="built_in">bool</span> | <span class="literal">None</span> = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params"></span>) -&gt; torch.FloatTensor:</span><br><span class="line"><span class="string">&quot;&quot;&quot;获取图片特征</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Args:</span></span><br><span class="line"><span class="string">pixel_values : 图片像素值</span></span><br><span class="line"><span class="string">output_attentions : 是否输出注意力</span></span><br><span class="line"><span class="string">output_hidden_states : 是否输出隐藏状态</span></span><br><span class="line"><span class="string">return_dict : 是否返回字典</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">return_dict = return_dict <span class="keyword">if</span> return_dict <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> self.config.use_return_dict</span><br><span class="line"></span><br><span class="line">output_attentions = output_attentions <span class="keyword">if</span> output_attentions <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> self.config.output_attentions</span><br><span class="line">output_hidden_states = output_hidden_states <span class="keyword">if</span> output_hidden_states <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> self.config.output_hidden_states</span><br><span class="line"></span><br><span class="line">vision_outputs = self.vision_encoder(</span><br><span class="line">pixel_values=pixel_values,</span><br><span class="line">output_attentions=output_attentions,</span><br><span class="line">output_hidden_states=output_hidden_states,</span><br><span class="line">return_dict=return_dict,</span><br><span class="line">)</span><br><span class="line">image_embeddings = vision_outputs[<span class="number">0</span>]</span><br><span class="line"><span class="keyword">return</span> normalize(self.vision_proj(image_embeddings[:, <span class="number">0</span>, :]), dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">processor = AutoProcessor.from_pretrained(<span class="string">&quot;Salesforce/blip-itm-large-coco&quot;</span>)</span><br><span class="line">model = BlipForRetrieval.from_pretrained(<span class="string">&quot;Salesforce/blip-itm-large-coco&quot;</span>).to(config[<span class="string">&quot;device&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_text_features</span>(<span class="params">text: <span class="built_in">str</span>, model=model, processor=processor</span>) -&gt; torch.FloatTensor:</span><br><span class="line"><span class="string">&quot;&quot;&quot;获取文本特征</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Args:</span></span><br><span class="line"><span class="string">text : 文本</span></span><br><span class="line"><span class="string">model : Pretrained Model，用于获取文本特征</span></span><br><span class="line"><span class="string">processor : 文本处理器，用于将文本转换为模型输入</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">text_encodings = processor(text=text, padding=<span class="literal">True</span>, return_tensors=<span class="string">&quot;pt&quot;</span>).to(config[<span class="string">&quot;device&quot;</span>])</span><br><span class="line"><span class="keyword">return</span> model.get_text_features(**text_encodings)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------------------------------------------------------------------------------------------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">search_imgs</span>(<span class="params">query=<span class="string">&quot;&quot;</span>, img_embs=<span class="literal">None</span>, search_space=<span class="literal">None</span>, k=<span class="number">10</span></span>):</span><br><span class="line"><span class="string">&quot;&quot;&quot;搜索前k个相关图片</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Args:</span></span><br><span class="line"><span class="string">query : 查询文本</span></span><br><span class="line"><span class="string">img_embs : 图片特征</span></span><br><span class="line"><span class="string">search_space : 搜索空间，图片路径列表</span></span><br><span class="line"><span class="string">k : 返回的图片数量</span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">related_imgs : 前k个相关图片</span></span><br><span class="line"><span class="string">related_indices : 前k个相关图片的索引</span></span><br><span class="line"><span class="string">cos_sim : 余弦相似度</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">query_emb = get_text_features(query)</span><br><span class="line">query_emb_norm = normalize(query_emb, dim=-<span class="number">1</span>) <span class="comment"># 归一化查询特征</span></span><br><span class="line">cos_sim = torch.matmul(query_emb_norm, img_embs.T).squeeze() <span class="comment"># 计算余弦相似度</span></span><br><span class="line">related_indices = cos_sim.sort()[<span class="number">1</span>][-k:]</span><br><span class="line"><span class="comment"># related_indices = cos_sim.topk(k).indices</span></span><br><span class="line">related_imgs = []</span><br><span class="line"><span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">related_imgs.append(search_space[related_indices[idx].item()])</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> related_imgs, related_indices, cos_sim</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> fast_pytorch_kmeans <span class="keyword">import</span> KMeans</span><br><span class="line">kmeans = KMeans(n_clusters=<span class="number">10</span>, mode=<span class="string">&#x27;cosine&#x27;</span>, verbose=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_related_captions</span>(<span class="params">caption_recon, <span class="built_in">round</span>=<span class="number">1</span>, threshold_low=<span class="number">500</span>, img_embs=<span class="literal">None</span>, captions=<span class="literal">None</span></span>):</span><br><span class="line"><span class="string">&quot;&quot;&quot;获取簇中心的相关图片描述</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">将low-(round-1)*(low/10.0)个最相关的图片作为候选集S_R，进行k-means聚类，</span></span><br><span class="line"><span class="string">得到10个簇中，信息熵最小的图片描述作为当前轮次的相关图片描述。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Args:</span></span><br><span class="line"><span class="string">caption_recon : 对话上下文（重构的）</span></span><br><span class="line"><span class="string">round : 当前轮次</span></span><br><span class="line"><span class="string">threshold_low : 根据轮次计算相关图片的数量 low-(round-1)*(low/10.0)</span></span><br><span class="line"><span class="string">img_embs : 图片特征</span></span><br><span class="line"><span class="string">captions : 图片描述</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">caps = []</span><br><span class="line"><span class="comment"># related_size = 100 - (round-1)*10</span></span><br><span class="line">related_size = <span class="built_in">int</span>(threshold_low - (<span class="built_in">round</span>-<span class="number">1</span>) * (threshold_low / <span class="number">10.0</span>)) <span class="comment"># 候选集大小 500-(round-1)*50</span></span><br><span class="line">emb = normalize(get_text_features(caption_recon), dim=-<span class="number">1</span>) </span><br><span class="line">sim = torch.matmul(emb, img_embs.T).squeeze() <span class="comment"># 计算余弦相似度</span></span><br><span class="line">topk = sim.argsort()[-related_size:] <span class="comment"># 获取前related_size个相关图片的索引</span></span><br><span class="line">img_embs_topk = img_embs[topk] <span class="comment"># 获取前related_size个相关图片的特征</span></span><br><span class="line"></span><br><span class="line">entropies = torch.zeros([related_size]) </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(related_size):</span><br><span class="line">cap = captions[topk[i].item()][<span class="string">&#x27;caption&#x27;</span>]</span><br><span class="line">emb = normalize(get_text_features(cap), dim=-<span class="number">1</span>)</span><br><span class="line">sim = torch.matmul(emb, img_embs_topk.T).squeeze()</span><br><span class="line">p = torch.nn.functional.softmax(sim, dim=<span class="number">0</span>)</span><br><span class="line">entropy = (-p * p.log()).<span class="built_in">sum</span>().detach().cpu() <span class="comment"># 信息熵</span></span><br><span class="line">entropies[i] += entropy</span><br><span class="line">idx_entropies_sorted = entropies.argsort()</span><br><span class="line"></span><br><span class="line">cluster_label = kmeans.fit_predict(img_embs_topk)</span><br><span class="line">cluster_label_sorted = cluster_label[idx_entropies_sorted]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line"><span class="keyword">if</span> (cluster_label_sorted == i).<span class="built_in">any</span>():</span><br><span class="line">idx_c = (cluster_label_sorted == i).nonzero().squeeze().<span class="built_in">min</span>() </span><br><span class="line">caps.append(captions[topk[idx_entropies_sorted[idx_c]].item()][<span class="string">&#x27;caption&#x27;</span>][<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># for i in range(10):</span></span><br><span class="line"><span class="comment">#     caps.append(captions[topk[entropies.argsort()[i]].item()][&#x27;caption&#x27;][0])</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> caps</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_referring_prompt</span>(<span class="params">caption=<span class="string">&quot;&quot;</span>, img_embs=<span class="literal">None</span>, k=<span class="number">10</span>, <span class="built_in">round</span>=<span class="number">1</span>, search_space=<span class="literal">None</span></span>):</span><br><span class="line"><span class="string">&quot;&quot;&quot; 进行k-means聚类，获取相关图片描述；获取前k个相关图片的索引和余弦相似度。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Args:</span></span><br><span class="line"><span class="string">caption : 图片描述</span></span><br><span class="line"><span class="string">img_embs : 图片特征</span></span><br><span class="line"><span class="string">k : 返回的图片数量</span></span><br><span class="line"><span class="string">round : 当前轮次</span></span><br><span class="line"><span class="string">search_space : 搜索空间，图片路径列表</span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">prompt_sys : 系统prompt</span></span><br><span class="line"><span class="string">prompt_related_captions : 相关图片描述</span></span><br><span class="line"><span class="string">top_k : 前k个相关图片的索引</span></span><br><span class="line"><span class="string">cos_sims : 余弦相似度</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">img_paths, top_k, cos_sims = search_imgs(caption, img_embs, search_space, k=k)</span><br><span class="line">related_captions = get_related_captions(caption, <span class="built_in">round</span>, img_embs=img_embs, captions=captions)</span><br><span class="line"></span><br><span class="line">prompt_sys = <span class="string">&quot;&quot;</span></span><br><span class="line">prompt_sys += <span class="string">&quot;You should leverage the &#x27;related_captions Information&#x27; that is related to the target image &quot;</span></span><br><span class="line">prompt_sys += <span class="string">&quot;corresponding to the caption but does not match the target image.&quot;</span></span><br><span class="line"><span class="comment"># 你需要利用与目标图像相关的“虚假信息”，该信息与目标图像标题相关，但与目标图像不匹配。</span></span><br><span class="line"></span><br><span class="line">prompt_related_captions = <span class="string">&quot;&quot;</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(related_captions)):</span><br><span class="line">prompt_related_captions += <span class="built_in">str</span>(i) + <span class="string">&#x27;. &#x27;</span> + related_captions[i] + <span class="string">&#x27;\n&#x27;</span></span><br><span class="line"><span class="comment"># 1. caption1</span></span><br><span class="line"><span class="comment"># 2. caption2</span></span><br><span class="line"><span class="comment"># ...</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> prompt_sys, prompt_related_captions, top_k, cos_sims</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">select_question</span>(<span class="params">caption_recon=<span class="string">&quot;&quot;</span>, questions=[], cossim_prev=<span class="literal">None</span>, k=<span class="number">10</span>, img_embs=<span class="literal">None</span>, threshold=<span class="number">500</span>, <span class="built_in">round</span>=<span class="number">1</span></span>):</span><br><span class="line"><span class="string">&quot;&quot;&quot;选择KL散度最小的问题</span></span><br><span class="line"><span class="string">根据上一次的相似度，选择KL散度最小的问题。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Args:</span></span><br><span class="line"><span class="string">caption_recon : 对话上下文（重构的）</span></span><br><span class="line"><span class="string">questions : 问题列表</span></span><br><span class="line"><span class="string">cossim_prev : 上一轮的相似度</span></span><br><span class="line"><span class="string">k : 返回的图片数量</span></span><br><span class="line"><span class="string">img_embs : 图片特征</span></span><br><span class="line"><span class="string">threshold : 相关图片的数量 low-(round-1)*(low/10.0)</span></span><br><span class="line"><span class="string">round : 当前轮次</span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">str : 选择的问题</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">threshold = <span class="built_in">int</span>(threshold - (<span class="built_in">round</span>-<span class="number">1</span>) * (threshold / <span class="number">10.0</span>))</span><br><span class="line">idx_related = cossim_prev.argsort()[-threshold:-k]</span><br><span class="line">p_prev = torch.nn.functional.softmax(cossim_prev[idx_related], dim=<span class="number">0</span>)</span><br><span class="line">kl_divs = torch.zeros([<span class="built_in">len</span>(questions)])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, ques <span class="keyword">in</span> <span class="built_in">enumerate</span>(questions):</span><br><span class="line">caption_tmp = caption_recon + <span class="string">&quot;, &quot;</span> + ques</span><br><span class="line"></span><br><span class="line">query_emb_tmp = normalize(get_text_features(caption_tmp), dim=-<span class="number">1</span>)</span><br><span class="line">cossim_tmp = torch.matmul(query_emb_tmp, img_embs.T).squeeze()</span><br><span class="line">p_tmp = torch.nn.functional.softmax(cossim_tmp[idx_related], dim=<span class="number">0</span>)</span><br><span class="line">kl_div = (p_prev*(p_prev.log() - p_tmp.log())).<span class="built_in">sum</span>().detach().cpu()</span><br><span class="line">kl_divs[i] += kl_div</span><br><span class="line"></span><br><span class="line">idx_final = kl_divs.argsort()[<span class="number">0</span>].item()</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> questions[idx_final]</span><br></pre></td></tr></table></figure><h3 id="系统实现：PlugIR-exec-py"><a href="#系统实现：PlugIR-exec-py" class="headerlink" title="系统实现：PlugIR_exec.py"></a>系统实现：PlugIR_exec.py</h3><p>PlugIR的运行版，实现利用多轮对话进行图像检索的功能，描述以及每次问答后显示当前最相关的图片。</p><p>改写为<code>PlugIR_func.py</code>，实现了函数化，便于后续批量生成对话数据用于evaluation。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> API <span class="keyword">import</span> OpenAI</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> utils</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> config <span class="keyword">import</span> config</span><br><span class="line"></span><br><span class="line">img_embs = torch.load(config[<span class="string">&quot;img_emb_path&quot;</span>], map_location=config[<span class="string">&quot;device&quot;</span>])[<span class="number">1</span>] <span class="comment"># blip预处理的embeddings</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> config[<span class="string">&quot;filtering&quot;</span>]:</span><br><span class="line">    config[<span class="string">&quot;q_num&quot;</span>] = <span class="number">1</span> <span class="comment"># 不过滤问题，生成1个问题</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(config[<span class="string">&quot;search_space&quot;</span>], <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> ss_json:</span><br><span class="line">    search_space = json.load(ss_json) <span class="comment"># length:50000</span></span><br><span class="line">    search_space = [config[<span class="string">&quot;dir_prefix&quot;</span>] + path <span class="keyword">for</span> path <span class="keyword">in</span> search_space]</span><br><span class="line">    <span class="comment"># [&quot;&lt;img_path&gt;&quot;, &quot;&lt;img_path&gt;&quot;, ...]</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(config[<span class="string">&quot;visdial_path&quot;</span>], <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> diag_json:</span><br><span class="line">visdial = json.load(diag_json) <span class="comment"># length:2064</span></span><br><span class="line"><span class="comment"># [&#123;&quot;img&quot;:&quot;&lt;img_path&gt;&quot;, &quot;dialog&quot;:[&quot;&lt;caption&gt;&quot;, &quot;Q? A&quot;, &quot;Q? A&quot;, ...]&#125;, ...]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(config[<span class="string">&quot;captions_path&quot;</span>], <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> ss_cap_json:</span><br><span class="line">captions = json.load(ss_cap_json) <span class="comment"># length:50000</span></span><br><span class="line">    <span class="comment"># [&#123;&quot;id&quot;: &quot;&lt;img_path&gt;&quot;, &quot;caption&quot;: [&quot;&lt;caption&gt;&quot;]&#125;,...]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ask_for_caption</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;询问用户描述&quot;&quot;&quot;</span></span><br><span class="line">    caption = <span class="built_in">input</span>(<span class="string">&quot;Caption: &quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> caption.strip()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ask_question</span>(<span class="params">question</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;询问用户问题&quot;&quot;&quot;</span></span><br><span class="line">    ans = <span class="built_in">input</span>(<span class="string">f&quot;<span class="subst">&#123;question&#125;</span> &quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> ans.strip()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">display_image</span>(<span class="params">img_path</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;显示图片&quot;&quot;&quot;</span></span><br><span class="line">    img = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line">    img.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    caption = ask_for_caption() <span class="comment"># 询问用户描述</span></span><br><span class="line">    dialogue = [caption] <span class="comment"># 对话框</span></span><br><span class="line">    caption_recon = caption <span class="comment"># 重构后的描述，用于匹配图片</span></span><br><span class="line">    caption_recons = [caption] <span class="comment"># 重构描述列表</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">round</span> <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>): <span class="comment"># 10轮对话</span></span><br><span class="line">        questions = [] <span class="comment"># 合法问题列表</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> config[<span class="string">&quot;referring&quot;</span>]: <span class="comment"># 参考候选集的Caption提问</span></span><br><span class="line">            ques_prior = [] <span class="comment"># 非法问题列表</span></span><br><span class="line">            _, prompt_related_captions, top_k, cos_sims = utils.get_referring_prompt(</span><br><span class="line">                caption_recon,</span><br><span class="line">                img_embs=img_embs,</span><br><span class="line">                k=config[<span class="string">&quot;hitk&quot;</span>],</span><br><span class="line">                <span class="built_in">round</span>=<span class="built_in">round</span>+<span class="number">1</span>,</span><br><span class="line">                search_space=search_space)</span><br><span class="line">            display_image(search_space[top_k[-<span class="number">1</span>]]) <span class="comment"># 显示第一张图片</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(config[<span class="string">&quot;q_num&quot;</span>]): <span class="comment"># 生成config[&quot;q_num&quot;]个问题</span></span><br><span class="line">                <span class="keyword">if</span> config[<span class="string">&quot;filtering&quot;</span>]: <span class="comment"># AI过滤问题</span></span><br><span class="line">                    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>): <span class="comment"># 尝试3次根据候选集Caption生成问题</span></span><br><span class="line">                        resp = OpenAI.generate_questions_referring(</span><br><span class="line">                            dialog=dialogue,</span><br><span class="line">                            prompt_related_captions=prompt_related_captions,</span><br><span class="line">                            questions=ques_prior,</span><br><span class="line">                            model=config[<span class="string">&quot;gpt_model&quot;</span>]</span><br><span class="line">                        ).choices[<span class="number">0</span>].message.content</span><br><span class="line">                        question = resp.split(<span class="string">&#x27;?&#x27;</span>)[<span class="number">0</span>]+<span class="string">&#x27;?&#x27;</span></span><br><span class="line">                        fq = OpenAI.filter_questions(caption_recon, question).choices[<span class="number">0</span>].message.content</span><br><span class="line">                        <span class="keyword">if</span> <span class="string">&quot;uncertain&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> fq.lower(): <span class="comment"># 如果不uncertain，问题非法</span></span><br><span class="line">                            ques_prior.append(question)</span><br><span class="line">                        <span class="keyword">else</span> : <span class="comment"># 如果uncertain，问题合法</span></span><br><span class="line">                            <span class="keyword">break</span></span><br><span class="line">                    <span class="keyword">if</span> <span class="built_in">len</span>(ques_prior) == <span class="number">3</span>: <span class="comment"># 三次非法问题，尝试直接询问一次，再不行，就固定询问其他对象</span></span><br><span class="line">                        response = OpenAI.generate_questions(dialog=dialogue, n=<span class="number">1</span>).choices[<span class="number">0</span>].message.content</span><br><span class="line">                        question = response.split(<span class="string">&#x27;?&#x27;</span>)[<span class="number">0</span>]+<span class="string">&#x27;?&#x27;</span></span><br><span class="line">                        fq = OpenAI.filter_questions(caption_recon, question).choices[<span class="number">0</span>].message.content</span><br><span class="line">                        <span class="keyword">if</span> <span class="string">&quot;uncertain&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> fq.lower():</span><br><span class="line">                            question = <span class="string">&quot;what is the other object in the image?&quot;</span></span><br><span class="line">                <span class="keyword">else</span>: <span class="comment"># 不过滤问题</span></span><br><span class="line">                    response = OpenAI.generate_questions_referring(</span><br><span class="line">                        dialog=dialogue, prompt_related_captions=prompt_related_captions, questions=ques_prior, n=<span class="number">1</span>, model=config[<span class="string">&quot;gpt_model&quot;</span>]</span><br><span class="line">                    ).choices[<span class="number">0</span>].message.content</span><br><span class="line">                    question = response.split(<span class="string">&#x27;?&#x27;</span>)[<span class="number">0</span>]+<span class="string">&#x27;?&#x27;</span></span><br><span class="line">            questions.append(question)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>: <span class="comment"># ChatIR：直接提问</span></span><br><span class="line">            _, top_k, cos_sims = utils.search_imgs(</span><br><span class="line">                query=caption_recon,</span><br><span class="line">                img_embs=img_embs, </span><br><span class="line">                search_space=search_space,</span><br><span class="line">                k=config[<span class="string">&quot;hitk&quot;</span>]</span><br><span class="line">            )</span><br><span class="line">            display_image(search_space[top_k[-<span class="number">1</span>]]) <span class="comment"># 显示第一张图片</span></span><br><span class="line">            <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(config[<span class="string">&quot;q_num&quot;</span>]): <span class="comment"># 生成config[&quot;q_num&quot;]个问题</span></span><br><span class="line">                question = OpenAI.generate_questions(</span><br><span class="line">                    dialog=dialogue, n=<span class="number">1</span>, model=config[<span class="string">&quot;gpt_model&quot;</span>]</span><br><span class="line">                ).choices[<span class="number">0</span>].message.content</span><br><span class="line">                questions.append(question)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> config[<span class="string">&quot;select&quot;</span>]: <span class="comment"># 选择KL散度最小的问题</span></span><br><span class="line">            question_final = utils.select_question( </span><br><span class="line">                caption_recon=caption_recon,</span><br><span class="line">                questions=questions,</span><br><span class="line">                cossim_prev=cos_sims,</span><br><span class="line">                k=config[<span class="string">&quot;hitk&quot;</span>],</span><br><span class="line">                img_embs=img_embs,</span><br><span class="line">                threshold=config[<span class="string">&quot;threshold_low&quot;</span>],</span><br><span class="line">                <span class="built_in">round</span>=<span class="built_in">round</span>+<span class="number">1</span></span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            question_final = questions[<span class="number">0</span>] </span><br><span class="line"></span><br><span class="line">        answer = ask_question(question_final)</span><br><span class="line">        qa = question_final + <span class="string">&#x27; &#x27;</span> + answer</span><br><span class="line">        dialogue.append(qa)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> config[<span class="string">&quot;reconstruct&quot;</span>]: <span class="comment"># 重构对话上下文</span></span><br><span class="line">            caption_recon = OpenAI.reconstruct_dialog(</span><br><span class="line">                dialog=dialogue,</span><br><span class="line">                model=config[<span class="string">&quot;gpt_model&quot;</span>]</span><br><span class="line">            ).choices[<span class="number">0</span>].message.content</span><br><span class="line">            <span class="keyword">if</span> caption_recon == caption_recons[-<span class="number">1</span>]:</span><br><span class="line">                caption_recon = OpenAI.paraphrase(caption_recon, model=config[<span class="string">&quot;gpt_model&quot;</span>]).choices[<span class="number">0</span>].message.content</span><br><span class="line">        <span class="keyword">else</span>: <span class="comment"># ChatIR：&quot;, &quot;连接&quot;</span></span><br><span class="line">            caption_recon = <span class="string">&#x27;, &#x27;</span>.join(dialogue)</span><br><span class="line">        caption_recons.append(caption_recon)</span><br></pre></td></tr></table></figure><p>运行效果：</p><p><img src="https://source.cclmsy.cc/posts/notes/papers/2406.03411/PlugIR_exec.png" alt="PlugIR_exec"></p><h3 id="对话数据生成：test-gen-py"><a href="#对话数据生成：test-gen-py" class="headerlink" title="对话数据生成：test_gen.py"></a>对话数据生成：test_gen.py</h3><p>为了自动获取测试数据，免除人工回答，使用了BLIP2模型回答问题。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> lavis.models <span class="keyword">import</span> load_model_and_preprocess</span><br><span class="line"><span class="keyword">from</span> config <span class="keyword">import</span> config</span><br><span class="line"><span class="keyword">from</span> PlugIR_func <span class="keyword">import</span> generate_question</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> API <span class="keyword">import</span> OpenAI</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(config[<span class="string">&quot;visdial_path&quot;</span>], <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> diag_json:</span><br><span class="line">visdial = json.load(diag_json) <span class="comment"># length:2064</span></span><br><span class="line"><span class="comment"># [&#123;&quot;img&quot;:&quot;&lt;img_path&gt;&quot;, &quot;dialog&quot;:[&quot;&lt;caption&gt;&quot;, &quot;Q? A&quot;, &quot;Q? A&quot;, ...]&#125;, ...]</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="comment"># st,ed = 5,100 # 目标范围[0,2064]</span></span><br><span class="line">st,ed = <span class="built_in">int</span>(sys.argv[<span class="number">1</span>]), <span class="built_in">int</span>(sys.argv[<span class="number">2</span>]) <span class="comment"># 目标范围[0,2064]</span></span><br><span class="line">images = [visdial[i][<span class="string">&quot;img&quot;</span>] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(st,ed)] <span class="comment"># 目标图片列表</span></span><br><span class="line">target_captions = [visdial[i][<span class="string">&quot;dialog&quot;</span>][<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(st,ed)] <span class="comment"># 目标图片对应的caption作为用户描述</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> Blip2Processor, Blip2ForConditionalGeneration</span><br><span class="line">processor2 = Blip2Processor.from_pretrained(config[<span class="string">&quot;vqa_model&quot;</span>])</span><br><span class="line">blip2 = Blip2ForConditionalGeneration.from_pretrained(config[<span class="string">&quot;vqa_model&quot;</span>], device_map=&#123;<span class="string">&quot;&quot;</span>: <span class="number">0</span>&#125;, torch_dtype=torch.float16)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">reconstruct_caption</span>(<span class="params">dialogue, caption_recons</span>):</span><br><span class="line">caption_recon=<span class="string">&quot;&quot;</span></span><br><span class="line"><span class="keyword">if</span> config[<span class="string">&quot;reconstruct&quot;</span>]: <span class="comment"># 重构对话上下文</span></span><br><span class="line">caption_recon = OpenAI.reconstruct_dialog(</span><br><span class="line">dialog=dialogue,</span><br><span class="line">model=config[<span class="string">&quot;gpt_model&quot;</span>]</span><br><span class="line">).choices[<span class="number">0</span>].message.content</span><br><span class="line"><span class="keyword">if</span> caption_recon == caption_recons[-<span class="number">1</span>]:</span><br><span class="line">caption_recon = OpenAI.paraphrase(caption_recon, model=config[<span class="string">&quot;gpt_model&quot;</span>]).choices[<span class="number">0</span>].message.content</span><br><span class="line"><span class="keyword">else</span>: <span class="comment"># ChatIR：&quot;, &quot;连接</span></span><br><span class="line">caption_recon = config[<span class="string">&quot;sep_token&quot;</span>].join(dialogue)</span><br><span class="line"><span class="keyword">return</span> caption_recon</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_dialog</span>(<span class="params">idx</span>):</span><br><span class="line"><span class="string">&quot;&quot;&quot;生成对话数据</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Args:</span></span><br><span class="line"><span class="string">idx : 图片索引(st-&gt;0)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">image = Image.<span class="built_in">open</span>(images[idx])</span><br><span class="line">caption = target_captions[idx] <span class="comment"># 目标图片对应的caption作为用户描述</span></span><br><span class="line">tqdm.write(<span class="string">f&quot;\nCaption <span class="subst">&#123;idx&#125;</span>: <span class="subst">&#123;caption&#125;</span>&quot;</span>)</span><br><span class="line">dialogue = [caption] <span class="comment"># 对话框</span></span><br><span class="line">caption_recon = caption <span class="comment"># 重构后的描述，用于匹配图片</span></span><br><span class="line">caption_recons = [caption] <span class="comment"># 重构描述列表</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>): <span class="comment"># 10轮对话</span></span><br><span class="line">question = generate_question(dialogue, caption_recon)</span><br><span class="line">prompt = <span class="string">f&quot;Question: <span class="subst">&#123;question&#125;</span> Answer: &quot;</span></span><br><span class="line">_inputs = processor2(images=image, text=prompt, return_tensors=<span class="string">&#x27;pt&#x27;</span>).to(config[<span class="string">&quot;device&quot;</span>])</span><br><span class="line">_outputs = blip2.generate(**_inputs, do_sample=<span class="literal">False</span>)</span><br><span class="line">answer = processor2.decode(_outputs[<span class="number">0</span>], skip_special_tokens=<span class="literal">True</span>).strip()</span><br><span class="line">qa = question.strip()+ <span class="string">&#x27; &#x27;</span> + answer</span><br><span class="line">dialogue.append(qa)</span><br><span class="line">caption_recon = reconstruct_caption(dialogue, caption_recons)</span><br><span class="line">caption_recons.append(caption_recon)</span><br><span class="line">tqdm.write(<span class="string">f&quot;Round <span class="subst">&#123;i+<span class="number">1</span>&#125;</span>: <span class="subst">&#123;caption_recon&#125;</span>&quot;</span>)</span><br><span class="line">ret = &#123;</span><br><span class="line"><span class="string">&quot;img&quot;</span>: images[idx],</span><br><span class="line"><span class="string">&quot;dialog&quot;</span>: caption_recons</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> ret</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">filename = <span class="string">&quot;dialogues/&quot;</span>+<span class="string">&quot;mine_&quot;</span> + config[<span class="string">&quot;gpt_model&quot;</span>]+<span class="string">&quot;_&quot;</span>+<span class="string">&quot;BLIP2&quot;</span>+<span class="string">&quot;.txt&quot;</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(filename, <span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line"><span class="keyword">for</span> idx <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(<span class="built_in">len</span>(images)), desc=<span class="string">&quot;对话生成进度&quot;</span>, position=<span class="number">0</span>):</span><br><span class="line">dialog = generate_dialog(idx)</span><br><span class="line">f.write(json.dumps(dialog, ensure_ascii=<span class="literal">False</span>)+<span class="string">&quot;\n&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id="Debug日志"><a href="#Debug日志" class="headerlink" title="Debug日志"></a>Debug日志</h3><p>测试使用了项目仓库的<code>eval.py</code>源代码。</p><p>可能是我使用Windows系统的缘故，<code>eval.py</code>代码中有一些报错，具体问题和调整如下：</p><ol><li><code>AttributeError: Can&#39;t pickle local object &#39;BLIP_ZERO_SHOT_BASELINE.&lt;locals&gt;.&lt;lambda&gt;&#39;</code><ul><li>原因：在Windows上使用多进程（<code>num_workers&gt;0</code>）时，需要pickle对象，但是其中的lambda函数或局部函数不能被pickle</li><li>解决：将lambda函数改为全局函数，再使用<code>functools.partial</code>进行参数绑定</li></ul></li><li><code>RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!</code> <ul><li>原因：函数<code>text_encode_fn</code>中的<code>processor</code>没有<code>to(device)</code></li><li>解决：多做一步，将<code>processor</code>的输出<code>`to(device)</code></li></ul></li></ol><p>尝试跑通<code>generate_dialog.py</code>的过程中也遇到了上述问题，解决方法同。</p><h3 id="测试结果"><a href="#测试结果" class="headerlink" title="测试结果"></a>测试结果</h3><p>正常情况下3~5分钟可以生成1条数据（大约80次请求）。<br>但由于我生成数据短时间内大量调用OpenAI API，导致被限流，20~30分钟才能产生1条数据，故本次实现在eval阶段仅有253条数据。</p><p>在使用ChatGPT-4o-mini作为提问模型G，BLIP2作为回答模型A，使用同一测试代码的情况下，测试结果和仓库的对话数据Hit@K对比如下：</p><div class="table-container"><table><thead><tr><th style="text-align:center">length</th><th style="text-align:center">仓库数据Hit@10(2064 testcases)</th><th style="text-align:center">实现数据Hit@10（253 testcases）</th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center">71.12%</td><td style="text-align:center">72.33%</td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">79.02%</td><td style="text-align:center">81.42%</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">83.09%</td><td style="text-align:center">83.40%</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">85.85%</td><td style="text-align:center">85.38%</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">87.55%</td><td style="text-align:center">86.56%</td></tr><tr><td style="text-align:center">5</td><td style="text-align:center">88.71%</td><td style="text-align:center">87.75%</td></tr><tr><td style="text-align:center">6</td><td style="text-align:center">89.39%</td><td style="text-align:center">88.14%</td></tr><tr><td style="text-align:center">7</td><td style="text-align:center">90.12%</td><td style="text-align:center">88.54%</td></tr><tr><td style="text-align:center">8</td><td style="text-align:center">90.70%</td><td style="text-align:center">88.93%</td></tr><tr><td style="text-align:center">9</td><td style="text-align:center">91.09%</td><td style="text-align:center">89.33%</td></tr><tr><td style="text-align:center">10</td><td style="text-align:center">91.47%</td><td style="text-align:center">90.12%</td></tr></tbody></table></div><p>BRI对比（越低越好）：</p><ul><li>仓库对话的BRI：10.195615768432617</li><li>实现对话的BRI：10.252569198608398</li></ul>]]></content>
    
    
    <summary type="html">实现论文《Interactive Text-to-ImageRetrieval with Large Language Models：A Plug-and-Play Approach》</summary>
    
    
    
    <category term="论文笔记" scheme="https://www.cclmsy.cc/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="论文实现" scheme="https://www.cclmsy.cc/tags/%E8%AE%BA%E6%96%87%E5%AE%9E%E7%8E%B0/"/>
    
    <category term="图像检索" scheme="https://www.cclmsy.cc/tags/%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2/"/>
    
    <category term="MLLM" scheme="https://www.cclmsy.cc/tags/MLLM/"/>
    
  </entry>
  
  <entry>
    <title>Bag of Features 图像检索算法</title>
    <link href="https://www.cclmsy.cc/posts/bag_of_features.html"/>
    <id>https://www.cclmsy.cc/posts/bag_of_features.html</id>
    <published>2025-03-15T16:00:00.000Z</published>
    <updated>2025-07-18T12:42:11.031Z</updated>
    
    <content type="html"><![CDATA[<h2 id="算法原理"><a href="#算法原理" class="headerlink" title="算法原理"></a>算法原理</h2><h3 id="引入：词袋模型（Bag-of-Words）"><a href="#引入：词袋模型（Bag-of-Words）" class="headerlink" title="引入：词袋模型（Bag of Words）"></a>引入：词袋模型（Bag of Words）</h3><p>Bag of Words是文本分类中一种通俗易懂的策略。<br>一般来讲，如果我们要了解一段文本的主要内容，最行之有效的策略是抓取文本中的关键词，根据关键词出现的频率确定这段文本的中心思想。</p><p>Bag of Words中的Words是区分度较高的单词。<br>根据这些Words ，我们就可以快速识别出文章内容，并对文章进行分类。</p><p>Bag of Features是对图像的一种类似的处理方法，抽出图像中的关键特征，根据这些特征来识别图像。</p><h3 id="Bag-of-Features-算法流程"><a href="#Bag-of-Features-算法流程" class="headerlink" title="Bag of Features 算法流程"></a>Bag of Features 算法流程</h3><ol><li>提取出关键特征，通常会使用SIFT特征。</li><li>将这些特征进行K-Means聚类，得到包含K个视觉词汇的词典。</li><li>对图像中的特征点进行量化，将特征点映射到视觉词汇上。</li><li>统计每个视觉词汇的出现频率，得到频率直方图。</li><li>构造特征到图像的倒排表，用于图像检索。</li><li>根据索引结果，进行直方图匹配</li></ol><h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><p><code>image</code>文件夹下存放图像，<code>query</code>文件夹下存放查询图像。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">from</span> scipy.spatial <span class="keyword">import</span> distance</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&quot;LOKY_MAX_CPU_COUNT&quot;</span>] = <span class="string">&quot;4&quot;</span> <span class="comment"># KMenas 多线程设置</span></span><br><span class="line"></span><br><span class="line">image_paths = [] <span class="comment"># 图片路径列表</span></span><br><span class="line">sift_res = &#123;&#125; <span class="comment"># sift_res[img_path] = (keypoints, descriptors) # SIFT特征字典</span></span><br><span class="line">k_means = <span class="literal">None</span> <span class="comment"># K-Means模型</span></span><br><span class="line">k = <span class="number">50</span> <span class="comment"># 视觉词典大小</span></span><br><span class="line">histograms = &#123;&#125; <span class="comment"># 直方图字典</span></span><br><span class="line">sift = cv2.SIFT_create() <span class="comment"># 创建SIFT对象</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取文件夹下所有图片路径</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_images</span>(<span class="params">image_folder</span>):</span><br><span class="line">    <span class="keyword">global</span> image_paths</span><br><span class="line">    <span class="keyword">for</span> root, _, files <span class="keyword">in</span> os.walk(image_folder): </span><br><span class="line">        <span class="keyword">for</span> filename <span class="keyword">in</span> files:</span><br><span class="line">            <span class="keyword">if</span> filename.lower().endswith(<span class="string">&quot;.jpg&quot;</span>):</span><br><span class="line">                image_paths.append(os.path.join(root, filename))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 提取SIFT特征</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_sift_features</span>(<span class="params">cache=<span class="string">&quot;cache/BOF_SIFT_desc.pkl&quot;</span></span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;1.提取SIFT特征&quot;</span>)</span><br><span class="line">    <span class="keyword">global</span> sift_res, image_paths</span><br><span class="line">    <span class="keyword">if</span> os.path.exists(cache):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(cache, <span class="string">&quot;rb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;从缓存中加载SIFT特征: <span class="subst">&#123;cache&#125;</span>&quot;</span>)</span><br><span class="line">            sift_res = pickle.load(f)</span><br><span class="line">            <span class="keyword">return</span> </span><br><span class="line">        </span><br><span class="line">    <span class="keyword">for</span> img_path <span class="keyword">in</span> tqdm(image_paths):</span><br><span class="line">        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE) </span><br><span class="line">        _, desc = sift.detectAndCompute(img, <span class="literal">None</span>) <span class="comment"># 提取特征点和描述符</span></span><br><span class="line">        sift_res[img_path] = desc</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(cache, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;保存SIFT特征到缓存: <span class="subst">&#123;cache&#125;</span>&quot;</span>)</span><br><span class="line">        pickle.dump(sift_res, f)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. K-Means聚类，创建视觉词典</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_vocabulary</span>(<span class="params">cache=<span class="string">&quot;cache/BOF_kmeans.pkl&quot;</span></span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;2.创建视觉词典&quot;</span>)</span><br><span class="line">    <span class="keyword">global</span> k_means, k</span><br><span class="line">    <span class="keyword">if</span> os.path.exists(cache):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(cache, <span class="string">&quot;rb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;从缓存中加载K-Means模型: <span class="subst">&#123;cache&#125;</span>&quot;</span>)</span><br><span class="line">            k_means=pickle.load(f)</span><br><span class="line">            <span class="keyword">return</span> </span><br><span class="line"></span><br><span class="line">    st = time()</span><br><span class="line">    descriptors_list = <span class="built_in">list</span>(sift_res.values())</span><br><span class="line">    all_descriptors = np.vstack(descriptors_list)  <span class="comment"># 汇总所有特征点</span></span><br><span class="line">    k_means = KMeans(n_clusters=k, random_state=<span class="number">0</span>, n_init=<span class="number">10</span>)</span><br><span class="line">    k_means.fit(all_descriptors)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;K-Means聚类耗时: <span class="subst">&#123;time()-st:<span class="number">.2</span>f&#125;</span>s&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(cache, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;保存K-Means模型到缓存: <span class="subst">&#123;cache&#125;</span>&quot;</span>)</span><br><span class="line">        pickle.dump(k_means, f)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 计算BoF直方图</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_histogram</span>(<span class="params">img_path</span>):</span><br><span class="line">    <span class="keyword">if</span> img_path <span class="keyword">in</span> sift_res:</span><br><span class="line">        descriptors = sift_res[img_path] <span class="comment"># 获取描述符</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE) </span><br><span class="line">        _, descriptors = sift.detectAndCompute(img, <span class="literal">None</span>)</span><br><span class="line">    words = k_means.predict(descriptors) <span class="comment"># 预测每个描述符的词汇索引</span></span><br><span class="line">    hist, _ = np.histogram(words, bins=np.arange(k+<span class="number">1</span>)) <span class="comment"># 计算直方图</span></span><br><span class="line">    hist = hist / np.linalg.norm(hist)  <span class="comment"># 归一化</span></span><br><span class="line">    <span class="keyword">return</span> hist</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_histograms</span>(<span class="params">cache=<span class="string">&quot;cache/BOF_histogram.pkl&quot;</span></span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;3.计算数据库的BoF直方图&quot;</span>)</span><br><span class="line">    <span class="keyword">global</span> image_paths, histograms, k_means</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(cache):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(cache, <span class="string">&quot;rb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;从缓存中加载数据库直方图: <span class="subst">&#123;cache&#125;</span>&quot;</span>)</span><br><span class="line">            histograms=pickle.load(f)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> img_path <span class="keyword">in</span> tqdm(image_paths):</span><br><span class="line">        histograms[img_path] = compute_histogram(img_path)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(cache, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;保存数据库直方图到缓存: <span class="subst">&#123;cache&#125;</span>&quot;</span>)</span><br><span class="line">        pickle.dump(histograms, f)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 直方图匹配</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cos_sim</span>(<span class="params">a, b</span>):</span><br><span class="line">    <span class="keyword">return</span> np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_topk</span>(<span class="params">query_hist, topk=<span class="number">10</span></span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;4.直方图匹配&quot;</span>)</span><br><span class="line">    <span class="keyword">global</span> histograms</span><br><span class="line">    similarities = []</span><br><span class="line">    <span class="keyword">for</span> img_path, hist <span class="keyword">in</span> tqdm(histograms.items()):</span><br><span class="line">        <span class="comment"># dist = distance.euclidean(query_hist, hist)</span></span><br><span class="line">        dist = cos_sim(query_hist, hist)</span><br><span class="line">        similarities.append((img_path, dist))</span><br><span class="line">    similarities.sort(key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>) <span class="comment"># 降序排序</span></span><br><span class="line">    <span class="keyword">return</span> similarities[:topk]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行BoF流程</span></span><br><span class="line">image_folder = <span class="string">&quot;image&quot;</span></span><br><span class="line">get_images(image_folder)</span><br><span class="line">extract_sift_features()</span><br><span class="line">create_vocabulary()</span><br><span class="line">compute_histograms()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 匹配图像</span></span><br><span class="line">test_img = <span class="string">&quot;query/A0C573_20151103073308_3029240562.jpg&quot;</span></span><br><span class="line">test_hist = compute_histogram(test_img)</span><br><span class="line">topk=get_topk(test_hist, topk=<span class="number">10</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Top 10 相似图片:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> i, (filepath, sim) <span class="keyword">in</span> <span class="built_in">enumerate</span>(topk):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;i+<span class="number">1</span>&#125;</span>. <span class="subst">&#123;filepath&#125;</span> - 相似度: <span class="subst">&#123;sim:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>测试结果：</p><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">(DL) PS <span class="attr">D:</span>\Repos\Course\CVLab&gt; &amp; <span class="attr">C:</span><span class="regexp">/Users/</span>CCLMSY<span class="regexp">/.conda/</span>envs<span class="regexp">/DL/</span>python.exe <span class="attr">d:</span><span class="regexp">/Repos/</span>Course<span class="regexp">/CVLab/</span>BOF.py</span><br><span class="line"><span class="number">1.</span>提取SIFT特征</span><br><span class="line">从缓存中加载SIFT特征: cache/BOF_SIFT_desc.pkl</span><br><span class="line"><span class="number">2.</span>创建视觉词典</span><br><span class="line">从缓存中加载K-Means模型: cache/BOF_kmeans.pkl</span><br><span class="line"><span class="number">3.</span>计算数据库的BoF直方图</span><br><span class="line">从缓存中加载数据库直方图: cache/BOF_histogram.pkl</span><br><span class="line"><span class="number">4.</span>构造倒排索引</span><br><span class="line"><span class="number">100</span>%|██████████████████████████████████████████████████| <span class="number">945</span><span class="regexp">/945 [00:00&lt;00:00, 23779.80it/</span>s] </span><br><span class="line"><span class="number">5.</span>直方图匹配</span><br><span class="line"><span class="number">100</span>%|██████████████████████████████████████████████████| <span class="number">946</span><span class="regexp">/946 [00:00&lt;00:00, 157646.77it/</span>s] </span><br><span class="line">query/A0C573_20151029074136_6562078379.jpg 匹配到的最相似图片是 image\A0C573\A0C573_20151029074136_6562078379.jpg</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">一种是用于图像和视频检索的算法</summary>
    
    
    
    <category term="DL笔记" scheme="https://www.cclmsy.cc/categories/DL%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="图像检索" scheme="https://www.cclmsy.cc/tags/%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2/"/>
    
    <category term="CV" scheme="https://www.cclmsy.cc/tags/CV/"/>
    
  </entry>
  
  <entry>
    <title>SIFT 图像特征匹配算法</title>
    <link href="https://www.cclmsy.cc/posts/sift.html"/>
    <id>https://www.cclmsy.cc/posts/sift.html</id>
    <published>2025-03-15T16:00:00.000Z</published>
    <updated>2025-07-21T05:29:25.279Z</updated>
    
    <content type="html"><![CDATA[<h2 id="SIFT简介"><a href="#SIFT简介" class="headerlink" title="SIFT简介"></a>SIFT简介</h2><p>SIFT（Scale-Invariant Feature Transform，尺度不变特征变换匹配算法）是一种高效区域检测算法。</p><p>SIFT算法可以解决的问题：</p><ol><li>RST（Rotation Scale Translation）：图像的旋转、缩放、平移等变换</li><li>图像的仿射变换（Affine Transformation）：图像的拉伸、压缩、扭曲等变换</li><li>图像的光照变化</li><li>目标部分遮挡</li><li>杂物和噪声干扰</li></ol><h2 id="SIFT算法原理"><a href="#SIFT算法原理" class="headerlink" title="SIFT算法原理"></a>SIFT算法原理</h2><h3 id="1-高斯滤波"><a href="#1-高斯滤波" class="headerlink" title="1. 高斯滤波"></a>1. 高斯滤波</h3><p>一个图像的尺度空间$L$是高斯函数$G(x,y,\sigma)$与图像$I(x,y)$的卷积：</p><script type="math/tex; mode=display">\begin{aligned}L(x,y,\sigma) &= G(x,y,\sigma) * I(x,y) \\\\G(x,y,\sigma) &= \dfrac{1}{2\pi\sigma^2}e^{-\frac{(x-x_0)^2+(y-y_0)^2}{2\sigma^2}}\end{aligned}</script><p>其中，$G(x,y,\sigma)$是高斯函数，$\sigma$是尺度因子，$*$是卷积运算，$x_0,y_0$是高斯函数的中心（卷积核的中心）。</p><p>$\sigma$越小，图像被平滑的越少，图像的细节越多。<br>小尺度对应于图像的细节，大尺度对应于图像的整体特征。</p><p><img src="https://source.cclmsy.cc/posts/notes/others/Gaussian_Blur.png" alt="Gaussian Blur"></p><h3 id="2-高斯金字塔"><a href="#2-高斯金字塔" class="headerlink" title="2. 高斯金字塔"></a>2. 高斯金字塔</h3><p><img src="https://source.cclmsy.cc/posts/notes/others/高斯金字塔.png" alt="高斯金字塔"></p><p>高斯金字塔包含多组（Octave）图像，每组图像由多层（Interval）不同尺度的高斯模糊图像组成。</p><p>构建过程：</p><ol><li>将原图像扩大到两倍，作为第0组的第0层</li><li>对第0组的第0层进行$\sigma_0$的高斯模糊，得到第0组的第1层</li><li>选定一个比例系数$k$，对第0组的第1层进行$k\sigma_0$的高斯模糊，得到第0组的第2层</li><li>对第0组的第2层进行$k^2\sigma_0$的高斯模糊，得到第0组的第3层，以此类推…</li><li>将<strong>上一组倒数第3层图像</strong>做比例因子为2的降采样，得到下一组的第0层，重复步骤2-4</li></ol><p>组数计算公式：$O=\lfloor\log_2(\min(M,N))\rfloor-3$</p><ul><li>$M,N$：原图像的长宽</li></ul><p>层数公式：$S=n+3$</p><ul><li>$S$是每组的层数（自设）</li><li>$n$是最终想在差分金字塔中提取极值点的层数（见差分金字塔）</li></ul><p>平滑因子公式：$\sigma(o,r)=\sigma_0 2^{o+\frac{r}{n}}$，其中$o$是组数，$r$是层数</p><ul><li>SIFT算法中，$\sigma_0=1.6$。但由于相机具有初始模糊$\sigma_0=0.5$，实际$\sigma_0=\sqrt{1.6^2-0.5^2}=1.52$</li><li>第o层的初始平滑因子$\sigma(o,0)=2^o\sigma_0$</li><li>$k=2^{1/n}$</li></ul><p><img src="https://source.cclmsy.cc/posts/notes/others/高斯金字塔2.png" alt="高斯金字塔2"></p><p>金字塔内各图片的关系：</p><ul><li>在同一组内，不同层图像的尺寸是一样的，后一层图像的高斯平滑因子σ是前一层图像平滑因子的k倍</li><li>在不同组内，后一组第一个图像是前一组倒数第三个图像的二分之一采样，图像大小是前一组的一半</li></ul><h3 id="3-高斯差分金字塔与极值点检测"><a href="#3-高斯差分金字塔与极值点检测" class="headerlink" title="3. 高斯差分金字塔与极值点检测"></a>3. 高斯差分金字塔与极值点检测</h3><h4 id="3-1-高斯差分金字塔"><a href="#3-1-高斯差分金字塔" class="headerlink" title="3.1 高斯差分金字塔"></a>3.1 高斯差分金字塔</h4><p>对高斯金字塔的每一组图像，计算相邻两层图像的差分，得到高斯差分金字塔(DoG, Difference of Gaussian)。</p><script type="math/tex; mode=display">D(x,y,\sigma) = (G(x,y,k\sigma)-G(x,y,\sigma)) * I(x,y)</script><h4 id="3-2-估计极值点"><a href="#3-2-估计极值点" class="headerlink" title="3.2 估计极值点"></a>3.2 估计极值点</h4><p>将每个像素点和它在3×3×3的邻域内的26个像素点进行比较。<br>如果这个点是这27个点中的最大值或最小值，则认为这个点是一个极值点。</p><p>DoG金字塔是离散的(因为尺度空间和像素点都是离散的)，所以找到的极值点不太准确的，很大可能在真正极值点附近，因此需要对每个极值点进行插值。</p><h4 id="3-3-泰勒展开求精确极值点"><a href="#3-3-泰勒展开求精确极值点" class="headerlink" title="3.3 泰勒展开求精确极值点"></a>3.3 泰勒展开求精确极值点</h4><p>对每个极值点$X_0(x_0,y_0,\sigma_0)^T$，进行三元二次泰勒展开：</p><script type="math/tex; mode=display">\begin{aligned}f(X) &= f(x_0)+\dfrac{\partial f}{\partial X}^T\hat{X}+\dfrac{1}{2}\hat{X}^T\dfrac{\partial^2 f}{\partial X^2}\hat{X} \\\\\hat{X} &= X-X_0 \\\\X &= (x,y,\sigma)^T\end{aligned}</script><p>将$f(X)$对$X$求导：</p><script type="math/tex; mode=display">\dfrac{\partial f(X)}{\partial X} = \dfrac{\partial f}{\partial X}^T+\dfrac{1}{2}\left( \dfrac{\partial^2 f}{\partial X^2} + \dfrac{\partial^2 f}{\partial X^2}^T \right)\hat{X} = \dfrac{\partial f}{\partial X}^T+\dfrac{\partial^2 f}{\partial X^2}\hat{X}</script><p>导数为0时，解得极值点：</p><script type="math/tex; mode=display">\hat{X} = -\dfrac{\partial^2 f}{\partial X^2}^{-1}\dfrac{\partial f}{\partial X}</script><p>代入$f(X)$得到极值：</p><script type="math/tex; mode=display">f(X) = f(x_0)+\dfrac{1}{2}\dfrac{\partial f}{\partial X}^T\hat{X}</script><h4 id="3-4-去除低对比度点"><a href="#3-4-去除低对比度点" class="headerlink" title="3.4 去除低对比度点"></a>3.4 去除低对比度点</h4><p>舍去$|f(X_0)|&lt;\dfrac{T}{n}, T=0.04$的极值点，因为这些点对应的差分值太小，对比度低，不具有代表性。</p><h4 id="3-5-去除边缘响应"><a href="#3-5-去除边缘响应" class="headerlink" title="3.5 去除边缘响应"></a>3.5 去除边缘响应</h4><p>DoG在边缘会有比较大的值（边缘响应强），但边缘不一定能够提供稳定的特征，因此需要去除边缘响应强的点。</p><p>对于每个极值点，计算Hessian矩阵的迹和行列式：</p><script type="math/tex; mode=display">\begin{aligned}H &= \begin{bmatrix} D_{xx} & D_{xy} \\ D_{xy} & D_{yy} \end{bmatrix} \\\\Tr(H) &= D_{xx} + D_{yy} = \alpha + \beta \\\\Det(H) &= D_{xx} D_{yy} - (D_{xy})^2 = \alpha \beta\end{aligned}</script><p>其中：</p><ul><li>$\alpha$为较大的特征值，$\beta$为较小的特征值</li><li>$\alpha = r \beta$，$r$是一个大于1的实数</li></ul><p>过滤：</p><ol><li>$Det(H)&lt;0$</li><li>$\dfrac{(Tr(H))^2}{Det(H)}\ge (r+1)^2/r$，论文推荐值$r=10$</li></ol><h3 id="4-关键点方向分配"><a href="#4-关键点方向分配" class="headerlink" title="4. 关键点方向分配"></a>4. 关键点方向分配</h3><ol><li>0~360度划分为36 bins，每个bin为10度</li><li>在<strong>高斯金字塔</strong>找到关键点对应位置，以它为圆心，半径为$1.5\sigma$画圆</li><li>统计圆中所有像素的梯度方向、梯度幅值（模），直方图平滑处理，用$1.5\sigma$进行高斯加权<ul><li>平滑处理：防止某个梯度方向角度受噪声干扰等因素突变 </li><li>高斯加权：使特征点附件的梯度幅值具有更大的权重，弥补因没有仿射不变性而导致的特征不稳定</li></ul></li><li>统计出数值最高的梯度方向，作为主方向；保留大于主方向80%的方向作为辅方向</li></ol><p>梯度方向和梯度幅值的计算：</p><script type="math/tex; mode=display">m(x,y) = \sqrt{(L(x+1,y)-L(x-1,y))^2+(L(x,y+1)-L(x,y-1))^2}</script><script type="math/tex; mode=display">\theta(x,y) = \arctan\left(\dfrac{L(x,y+1)-L(x,y-1)}{L(x+1,y)-L(x-1,y)}\right)</script><p>高斯加权公式：</p><script type="math/tex; mode=display">W_{i,j} = e^{\dfrac{-(i^2+j^2)}{2\times(1.5\sigma)^2}}</script><ul><li>$i,j$是像素点到关键点的距离</li></ul><h3 id="5-关键点描述"><a href="#5-关键点描述" class="headerlink" title="5. 关键点描述"></a>5. 关键点描述</h3><p>描述符是一组向量，用于描述特征点及其领域点的特征，以便更好地与其他图片匹配</p><ol><li>将坐轴标移到关键点方向</li><li>将特征点的领域划分为$d\times d$个子区域，每个子区域大小为$m\sigma\times m\sigma$，并划分为8个方向。论文推荐值：$m=3$，$d=4$</li><li>每一个子块进行8个方向的直方图统计操作，共$d\times d\times 8=128$个bin，得到一个128维的特征向量（描述符）</li></ol><h3 id="6-特征点匹配"><a href="#6-特征点匹配" class="headerlink" title="6. 特征点匹配"></a>6. 特征点匹配</h3><p>分别对模板图（参考图，reference image）和实时图（观测图，observation image）建立关键点描述子集合。</p><p>目标的识别是通过两点集内关键点描述子的比对来完成，一般采用欧氏距离来衡量两个描述子之间的相似度。</p><p>可以使用<a href="https://oi-wiki.org/ds/kdt/">KD树</a>优化搜索过程。</p><h2 id="SIFT实现"><a href="#SIFT实现" class="headerlink" title="SIFT实现"></a>SIFT实现</h2><p>cv2中已经给出了SIFT算法的实现，可以直接调用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取图像</span></span><br><span class="line">img=cv2.imread(<span class="string">&#x27;nz.jpg&#x27;</span>)</span><br><span class="line">cat=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建SIFT对象</span></span><br><span class="line">sift=cv2.SIFT_create()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关键点检测：kp关键点信息包括方向，尺度，位置信息，des是关键点的描述符</span></span><br><span class="line">kp,des=sift.detectAndCompute(cat,<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在图像上绘制关键点的检测结果</span></span><br><span class="line">cv2.drawKeypoints(img,kp,img,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 图像显示</span></span><br><span class="line">plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))</span><br><span class="line">plt.title(<span class="string">&#x27;SIFT Result&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://source.cclmsy.cc/posts/notes/others/SIFT_Result.png" alt="SIFT Result"></p>]]></content>
    
    
    <summary type="html">尺度不变特征变换匹配算法 Scale-Invariant Feature Transform</summary>
    
    
    
    <category term="DL笔记" scheme="https://www.cclmsy.cc/categories/DL%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="图像检索" scheme="https://www.cclmsy.cc/tags/%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2/"/>
    
    <category term="计算机视觉" scheme="https://www.cclmsy.cc/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
  </entry>
  
  <entry>
    <title>K-means/K-means++</title>
    <link href="https://www.cclmsy.cc/posts/k_means.html"/>
    <id>https://www.cclmsy.cc/posts/k_means.html</id>
    <published>2025-03-14T16:00:00.000Z</published>
    <updated>2025-07-21T05:30:01.676Z</updated>
    
    <content type="html"><![CDATA[<h2 id="K-Means聚类算法"><a href="#K-Means聚类算法" class="headerlink" title="K-Means聚类算法"></a>K-Means聚类算法</h2><h3 id="算法思想"><a href="#算法思想" class="headerlink" title="算法思想"></a>算法思想</h3><p>K-means算法是一种迭代求解的聚类算法，将数据集中的n个样本划分为K个簇（聚类）。<br>每个对象到簇中心的距离之和最小。<br>簇内的对象相似度较高，簇间的对象相似度较低。</p><h3 id="算法步骤"><a href="#算法步骤" class="headerlink" title="算法步骤"></a>算法步骤</h3><h4 id="1-选择K个初始聚类中心"><a href="#1-选择K个初始聚类中心" class="headerlink" title="1. 选择K个初始聚类中心"></a>1. 选择K个初始聚类中心</h4><p>随机选择K个样本作为初始聚类中心。</p><p>选择对最终的聚类结果有一定影响，因此在实际应用中，通常会采用一些启发式的方法来选择较好的初始聚类中心，如K-means++算法</p><h4 id="2-计算每个样本到聚类中心的距离"><a href="#2-计算每个样本到聚类中心的距离" class="headerlink" title="2. 计算每个样本到聚类中心的距离"></a>2. 计算每个样本到聚类中心的距离</h4><p>对于每个样本，计算其到K个聚类中心的距离，将其划分到距离最近的聚类中心所在的簇中。</p><p>通常使用欧式距离：$d(x<em>i, c_j) = \sqrt{\sum</em>{k=1}^{n}(x<em>{ik}-c</em>{jk})^2}$</p><h4 id="3-更新聚类中心"><a href="#3-更新聚类中心" class="headerlink" title="3. 更新聚类中心"></a>3. 更新聚类中心</h4><p>对于每个聚类，重新计算其聚类中心，新的聚类中心是该聚类内所有数据点的均值：$c<em>j = \dfrac{1}{|S_j|}\sum</em>{x_i\in S_j}x_i$</p><h4 id="4-迭代"><a href="#4-迭代" class="headerlink" title="4. 迭代"></a>4. 迭代</h4><p>重复步骤2和3，直到聚类中心不再发生显著变化或者达到最大迭代次数。</p><h3 id="算法优缺点"><a href="#算法优缺点" class="headerlink" title="算法优缺点"></a>算法优缺点</h3><p>优点：逻辑简单、易于实现、收敛速度快</p><p>缺点：需要事先确定聚类数目K，对初始聚类中心敏感，可能收敛到局部最优解</p><h3 id="K-Means-实现"><a href="#K-Means-实现" class="headerlink" title="K-Means 实现"></a>K-Means 实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">k_means</span>(<span class="params">data, k=<span class="number">3</span>, max_iter=<span class="number">100</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;K-means 聚类算法</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        data: 数据集，list[element]，element是一个list[float]</span></span><br><span class="line"><span class="string">        k: 聚类数</span></span><br><span class="line"><span class="string">        max_iter: 最大迭代次数</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 初始化聚类中心</span></span><br><span class="line">    centers = random.sample(data, k)</span><br><span class="line">    <span class="comment"># 初始化聚类结果</span></span><br><span class="line">    clusters = [[] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(k)]</span><br><span class="line">    <span class="comment"># 迭代聚类</span></span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">iter</span> <span class="keyword">in</span> <span class="built_in">range</span>(max_iter):</span><br><span class="line">        <span class="comment"># 分配数据到最近的聚类中心</span></span><br><span class="line">        <span class="keyword">for</span> element <span class="keyword">in</span> data: <span class="comment"># 对于每个数据</span></span><br><span class="line">            min_dist = <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>) <span class="comment"># 最小距离</span></span><br><span class="line">            min_idx = -<span class="number">1</span> <span class="comment"># 最近聚类</span></span><br><span class="line">            <span class="keyword">for</span> i, center <span class="keyword">in</span> <span class="built_in">enumerate</span>(centers):</span><br><span class="line">                dist = <span class="built_in">sum</span>((x-y)**<span class="number">2</span> <span class="keyword">for</span> x, y <span class="keyword">in</span> <span class="built_in">zip</span>(element, center)) <span class="comment"># 计算距离</span></span><br><span class="line">                <span class="keyword">if</span> dist &lt; min_dist:</span><br><span class="line">                    min_dist = dist</span><br><span class="line">                    min_idx = i</span><br><span class="line">            clusters[min_idx].append(element)</span><br><span class="line">        <span class="comment"># 更新聚类中心</span></span><br><span class="line">        new_centers = [<span class="literal">None</span>] * k</span><br><span class="line">        <span class="keyword">for</span> i, cluster <span class="keyword">in</span> <span class="built_in">enumerate</span>(clusters):</span><br><span class="line">            new_centers[i] = [<span class="built_in">sum</span>(x)/<span class="built_in">len</span>(cluster) <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">zip</span>(*cluster)]</span><br><span class="line">        <span class="comment"># 判断是否收敛：中心点是否变化小于eps</span></span><br><span class="line">        eps = <span class="number">1e-6</span></span><br><span class="line">        fl = <span class="built_in">all</span>((<span class="built_in">sum</span>((x-y)**<span class="number">2</span> <span class="keyword">for</span> x, y <span class="keyword">in</span> <span class="built_in">zip</span>(a, b)) &lt; eps) <span class="keyword">for</span> a, b <span class="keyword">in</span> <span class="built_in">zip</span>(centers, new_centers))</span><br><span class="line">        <span class="keyword">if</span> fl <span class="keyword">or</span> <span class="built_in">iter</span> == max_iter-<span class="number">1</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        centers = new_centers</span><br><span class="line">        clusters = [[] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(k)]</span><br><span class="line">    <span class="keyword">return</span> clusters</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试</span></span><br><span class="line">data = [[random.random() <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>)] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>)]</span><br><span class="line">clusters = k_means(data, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结果可视化</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">colors = [<span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;g&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;m&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> i, cluster <span class="keyword">in</span> <span class="built_in">enumerate</span>(clusters):</span><br><span class="line">    <span class="keyword">for</span> element <span class="keyword">in</span> cluster:</span><br><span class="line">        plt.scatter(element[<span class="number">0</span>], element[<span class="number">1</span>], c=colors[i])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://source.cclmsy.cc/posts/notes/others/k_means.png" alt="k_means"></p><h2 id="K-Means-算法"><a href="#K-Means-算法" class="headerlink" title="K-Means++算法"></a>K-Means++算法</h2><p>K-Means++算法是K-means算法的改进，优化了初始聚类中心的选择，使得初始聚类中心更有代表性，收敛速度更快。</p><p>逐个选取k个簇中心，且离其它簇中心越远的样本点越有可能被选为下一个簇中心</p><h3 id="算法步骤（选择K个初始聚类中心的过程）"><a href="#算法步骤（选择K个初始聚类中心的过程）" class="headerlink" title="算法步骤（选择K个初始聚类中心的过程）"></a>算法步骤（选择K个初始聚类中心的过程）</h3><h4 id="1-选择第一个簇中心"><a href="#1-选择第一个簇中心" class="headerlink" title="1. 选择第一个簇中心"></a>1. 选择第一个簇中心</h4><p>随机选择一个样本作为第一个簇中心</p><h4 id="2-选择下一个簇中心"><a href="#2-选择下一个簇中心" class="headerlink" title="2. 选择下一个簇中心"></a>2. 选择下一个簇中心</h4><p>对于样本x，计算其到已有簇中心的最短距离，记为$D(x)$，选取x作为下一个簇中心的概率为$\dfrac{D(x)^2}{\sum_{x\in X}D(x)^2}$</p><h4 id="3-迭代"><a href="#3-迭代" class="headerlink" title="3. 迭代"></a>3. 迭代</h4><p>重复步骤2，直到选取k个簇中心</p><h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 选择第一个聚类中心</span></span><br><span class="line">centers = [random.choice(data)]</span><br><span class="line"><span class="comment"># 选择其他聚类中心</span></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(k-<span class="number">1</span>):</span><br><span class="line">    dists = [<span class="built_in">min</span>(<span class="built_in">sum</span>((x-y)**<span class="number">2</span> <span class="keyword">for</span> x, y <span class="keyword">in</span> <span class="built_in">zip</span>(element, center)) <span class="keyword">for</span> center <span class="keyword">in</span> centers) <span class="keyword">for</span> element <span class="keyword">in</span> data]</span><br><span class="line">    probs = [dist**<span class="number">2</span>/<span class="built_in">sum</span>(dists) <span class="keyword">for</span> dist <span class="keyword">in</span> dists]</span><br><span class="line">    centers.append(random.choices(data, probs)[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">最常用的聚类算法</summary>
    
    
    
    <category term="DL笔记" scheme="https://www.cclmsy.cc/categories/DL%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="聚类算法" scheme="https://www.cclmsy.cc/tags/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>论文笔记&amp;实现|ChatIR：基于对话的图像检索系统</title>
    <link href="https://www.cclmsy.cc/posts/2305.20062.html"/>
    <id>https://www.cclmsy.cc/posts/2305.20062.html</id>
    <published>2025-03-06T16:00:00.000Z</published>
    <updated>2025-07-21T05:33:51.333Z</updated>
    
    <content type="html"><![CDATA[<p>论文：<a href="https://arxiv.org/abs/2305.20062">Chatting Makes Perfect: Chat-based Image Retrival</a></p><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>传统的文本到图像检索方法，用户需要一次性提供全面详细的描述，来搜索目标图像。</p><p>本文提出了一个基于对话的图像检索系统ChatIR，用户可以通过多轮对话逐步细化搜索目标。</p><p>ChatIR系统包含2个部分：对话构建（Dialog Building）和图像搜索（Image Search）</p><ul><li>对话构建：使用问题生成器G，考虑当前对话历史，生成下一个问题</li><li>图像搜索：使用模型F，将不同长度的对话序列映射到视觉嵌入空间</li><li>两个组成部分建立在Instructional LLMs和fundation Vision and Language Models上</li></ul><p><img src="https://source.cclmsy.cc/posts/notes/papers/2305.20062.png" alt="ChatIR"></p><p>考虑三个问题：</p><ol><li>使用什么数据集训练？是否需要新创建和标注数据集？<ul><li>使用VisDial数据集</li><li>问题：VisDial是一个用于“创建关于图像的聊天”的数据集，没有检索目标</li><li>解决：输入输出反置，对话作为输入、图像作为输出</li></ul></li><li>如何独立评估ChatIR系统的不同组件？ <ul><li>测试使用不同的<code>F训练策略</code>和<code>提问模型G</code>对检索性能的影响</li><li>使用了BLIP替代用户回答问题</li></ul></li><li>如何定义评估指标？<ul><li>每一轮对话的成功检索概率Hit@10</li></ul></li></ol><h2 id="2-Related-Work"><a href="#2-Related-Work" class="headerlink" title="2. Related Work"></a>2. Related Work</h2><ol><li>视觉对话（Visual Conversation）领域<ul><li>当前视觉领域工作的重点在于图像理解和生成模型，而不是检索</li><li>生成式视觉对话中，近期的基础模型V&amp;L性能优越，因此ChatIR系统在此基础上构建</li></ul></li><li>视觉搜索（Visual Search）领域<ul><li>CoIR：使用多模态询问查找目标图像</li><li>一些研究基于CoIR，利用用户反馈细化查询结果</li><li>但是，没有考虑用户交互（只有用户反馈，没有机器提问）、没有明确利用对话历史</li></ul></li></ol><h2 id="3-Method"><a href="#3-Method" class="headerlink" title="3. Method"></a>3. Method</h2><h3 id="3-1-Dialog-Builder-Model-对话生成模型"><a href="#3-1-Dialog-Builder-Model-对话生成模型" class="headerlink" title="3.1 Dialog Builder Model 对话生成模型"></a>3.1 Dialog Builder Model 对话生成模型</h3><p>对话记录表示：$D_i = (C, Q_1, A_1, …, Q_i)$</p><ul><li>$C$：目标图像的初始文本描述（标题）</li><li>$Q_i$：第i个问题</li><li>$A_i$：第i个回答</li></ul><p>对话生成模型包含两个部分：</p><ul><li>问题生成器G：一个LLM，根据对话记录生成下一个问题<ul><li>$G: D<em>i \rightarrow Q</em>{i+1}$</li><li>G不知道目标图像T是什么，只知道对话历史</li></ul></li><li>答案提供者A：在实践中，通常是一个脑海中有大致目标图像的人类<ul><li>由于需要大规模实验，不能依赖用户提供答案</li><li>因此，使用了一个现成的模型BLIP2来回答</li></ul></li></ul><h3 id="3-2-Image-Retrieval-Model-图像检索模型"><a href="#3-2-Image-Retrieval-Model-图像检索模型" class="headerlink" title="3.2 Image Retrieval Model 图像检索模型"></a>3.2 Image Retrieval Model 图像检索模型</h3><p>图像搜索过程：在<code>查询</code>和<code>目标图像</code>共享的视觉嵌入空间中，搜索匹配项。</p><ul><li>所有的目标图像先经过图像嵌入模块进行编码，由一个$d$维的特征向量$f\in \mathbb R^d$表示。</li><li>图像检索模块F将对话历史$D_i$映射到视觉嵌入空间，$F: D_i \rightarrow \mathbb R^d$，</li><li>候选对象根据相似度进行排序。</li></ul><p>引入分隔符[SEP]和添加符[CLS]，表示整个对话序列，投射到视觉嵌入空间。</p><p>F采用（使用BLIP）预训练的图像/文本编码器，并通过对比学习，对基于对话的检索进行微调。</p><p>通过提取VisDial数据集中的图像和相应对话，手动标注，训练F。</p><h2 id="4-Evaluation"><a href="#4-Evaluation" class="headerlink" title="4. Evaluation"></a>4. Evaluation</h2><p>在评估环节，原文使用了Hit@10指标，即目标图像在前10个检索结果中的试验占比。</p><p>原文从三个方面进行了对比：</p><ol><li>与现有文本到图像（Text to Image,TTI）检索方法的比较<ol><li>ChatIR使用ChatGPT作为提问者G，BLIP2作为回答者A</li><li>与Zero-shot的BLIP、CLIP以及fine-tuned SoTA TTI BLIP进行比较</li><li>结论：ChatIR在多轮对话环境中，相比传统单跳 TTI 方法表现更优</li></ol></li><li>不同提问者G的比较<ol><li>使用ChatGPT、FLAN-ALPACA-XXL、人类等8中不同提问者</li><li>ChatGPT表现最好</li></ol></li><li>人类参与对话的影响<ol><li>ChatGPT提问，人类回答；ChatGPT提问，BLIP2回答；人类提问，人类回答</li><li>由于人类生成的答案质量明显优于BLIP2，因此人类参与对话时，检索性能会比测试的数据更好</li></ol></li></ol><h2 id="总结和实现"><a href="#总结和实现" class="headerlink" title="总结和实现"></a>总结和实现</h2><ul><li>ChatIR系统是一个基于对话的图像检索系统，包含对话构建和图像搜索两个部分</li><li>对话构建：使用问题生成器G，考虑当前对话历史，生成下一个问题<ul><li>原文测试了不同的问题生成器，其中ChatGPT表现最好</li></ul></li><li>图像搜索：使用模型F，将不同长度的对话序列映射到视觉嵌入空间<ul><li>我使用了论文仓库提供的预训练BLIP_ITM模型</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms.functional <span class="keyword">import</span> InterpolationMode</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os.path</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> multiprocessing <span class="comment"># 多进程处理</span></span><br><span class="line">multiprocessing.set_start_method(<span class="string">&#x27;spawn&#x27;</span>, force=<span class="literal">True</span>) </span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> OpenAI <span class="keyword">import</span> request_chat <span class="comment"># 自己实现的调用API函数 request_chat(dialog:list) -&gt; new_question:str</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys <span class="comment"># 添加import路径</span></span><br><span class="line">sys.path.insert(<span class="number">0</span>, <span class="string">&#x27;./BLIP&#x27;</span>)</span><br><span class="line"><span class="keyword">from</span> BLIP.models.blip_itm <span class="keyword">import</span> blip_itm <span class="comment"># BLIP用于图像文本匹配的预训练模型</span></span><br><span class="line"></span><br><span class="line">config = &#123;</span><br><span class="line">    <span class="string">&quot;corpus_path&quot;</span>: <span class="string">&quot;VisualDial/search_space.json&quot;</span>, <span class="comment"># 图像库路径</span></span><br><span class="line">    <span class="string">&quot;queries_path&quot;</span>: <span class="string">&quot;dialogues/ChatGPT4oMini_BLIP2.json&quot;</span>, <span class="comment"># 测试对话数据路径</span></span><br><span class="line">    <span class="string">&quot;corpus_cache&quot;</span>: <span class="string">&quot;VisualDial/corpus_cache.pth&quot;</span>, <span class="comment"># 处理好的图像库缓存的路径</span></span><br><span class="line">    <span class="string">&quot;device&quot;</span>: <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>,</span><br><span class="line">    <span class="string">&quot;sep&quot;</span>: <span class="string">&quot;, &quot;</span>, <span class="comment"># 对话分隔符</span></span><br><span class="line">    <span class="string">&quot;batch_size&quot;</span>: <span class="number">100</span>, <span class="comment"># 批处理大小</span></span><br><span class="line">    <span class="string">&quot;num_workers&quot;</span>: <span class="number">8</span>, <span class="comment"># 多进程处理数</span></span><br><span class="line">    <span class="string">&quot;image_size&quot;</span> : <span class="number">224</span> <span class="comment"># 图像大小</span></span><br><span class="line">&#125;</span><br><span class="line">corpus = <span class="literal">None</span> <span class="comment"># 处理好的图像库 </span></span><br><span class="line">dialog = [] <span class="comment"># 对话</span></span><br><span class="line">images = [] <span class="comment"># 图像库路径 list[图像路径]</span></span><br></pre></td></tr></table></figure><h3 id="图像数据集类"><a href="#图像数据集类" class="headerlink" title="图像数据集类"></a>图像数据集类</h3><p>继承自Dataset，用于加载图像数据集</p><p>corpus_path：图像数据集.json，包含一个list[str]，每个元素是一个图像的路径</p><p>建立路径字符串到索引的映射，便于赋值传递和查询</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Corpus</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;图像数据集&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, corpus_path, preprocessor</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;加载图像数据集</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            corpus_path: 图片路径列表</span></span><br><span class="line"><span class="string">            preprocessor: 图像预处理函数</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(corpus_path, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            self.corpus = json.load(f)</span><br><span class="line">            f.close()</span><br><span class="line">        self.preprocessor = preprocessor</span><br><span class="line">        <span class="comment"># 图片路径到索引的映射，用于快速查找</span></span><br><span class="line">        self.path2idx = &#123;self.corpus[i]:i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(self.corpus))&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.corpus)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        image = self.preprocessor(self.corpus[idx])</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&quot;idx&quot;</span>: idx, <span class="string">&quot;image&quot;</span>: image&#125;</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">path_to_index</span>(<span class="params">self, path</span>):</span><br><span class="line">        <span class="keyword">return</span> self.path2idx[path]</span><br></pre></td></tr></table></figure><h3 id="图像预处理函数"><a href="#图像预处理函数" class="headerlink" title="图像预处理函数"></a>图像预处理函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">image_preprocessor</span>(<span class="params">image_path</span>):</span><br><span class="line">    transform_prep = transforms.Compose([ </span><br><span class="line">        transforms.Resize((config[<span class="string">&quot;image_size&quot;</span>], config[<span class="string">&quot;image_size&quot;</span>]), </span><br><span class="line">                          interpolation=InterpolationMode.BICUBIC),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize((<span class="number">0.48145466</span>, <span class="number">0.4578275</span>, <span class="number">0.40821073</span>), </span><br><span class="line">                             (<span class="number">0.26862954</span>, <span class="number">0.26130258</span>, <span class="number">0.27577711</span>)) <span class="comment"># 参数参考BLIP的demo</span></span><br><span class="line">    ])</span><br><span class="line">    raw = Image.<span class="built_in">open</span>(image_path).convert(<span class="string">&quot;RGB&quot;</span>)</span><br><span class="line">    img = transform_prep(raw)</span><br><span class="line">    <span class="keyword">return</span> img</span><br></pre></td></tr></table></figure><h3 id="BLIP-ITM模型的图像编码器和对话编码器"><a href="#BLIP-ITM模型的图像编码器和对话编码器" class="headerlink" title="BLIP_ITM模型的图像编码器和对话编码器"></a>BLIP_ITM模型的图像编码器和对话编码器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_funcs</span>():</span><br><span class="line">    <span class="comment"># model_url = &#x27;https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_retrieval_coco.pth&#x27;</span></span><br><span class="line">    model = blip_itm(pretrained=<span class="string">&#x27;chatir_weights.ckpt&#x27;</span>, <span class="comment"># 论文仓库中的预训练模型</span></span><br><span class="line">                    med_config=<span class="string">&quot;BLIP/configs/med_config.json&quot;</span>, </span><br><span class="line">                    image_size=config[<span class="string">&quot;image_size&quot;</span>],</span><br><span class="line">                    vit=<span class="string">&quot;base&quot;</span>)</span><br><span class="line">    device = config[<span class="string">&quot;device&quot;</span>]</span><br><span class="line">    model = model.to(device).<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">image_encoder</span>(<span class="params">img</span>):</span><br><span class="line">        embeddings = model.visual_encoder(img) <span class="comment"># embedding</span></span><br><span class="line">        <span class="comment"># print(embeddings.shape) # (批次大小, patch个数+1, 隐层维度)</span></span><br><span class="line">        vision_proj = model.vision_proj(embeddings[:, <span class="number">0</span>, :]) <span class="comment"># 取[CLS] token，提取全局特征</span></span><br><span class="line">        <span class="keyword">return</span> F.normalize(vision_proj, dim=-<span class="number">1</span>) <span class="comment"># 正则化</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">dialog_encoder</span>(<span class="params">dialog</span>):</span><br><span class="line">        text = model.tokenizer(dialog, padding=<span class="string">&#x27;longest&#x27;</span>, truncation=<span class="literal">True</span>, max_length=<span class="number">200</span>, <span class="comment"># 填充到最长，截断到200</span></span><br><span class="line">                            return_tensors=<span class="string">&quot;pt&quot;</span>).to(device)  <span class="comment"># 返回PyTorch张量</span></span><br><span class="line">        text_out = model.text_encoder(text.input_ids, attention_mask=text.attention_mask, </span><br><span class="line">                                    return_dict=<span class="literal">True</span>, mode=<span class="string">&#x27;text&#x27;</span>) <span class="comment"># embedding</span></span><br><span class="line">        shift = model.text_proj(text_out.last_hidden_state[:, <span class="number">0</span>, :]) <span class="comment"># 同</span></span><br><span class="line">        <span class="keyword">return</span> F.normalize(shift, dim=-<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> image_encoder, dialog_encoder</span><br></pre></td></tr></table></figure><h3 id="处理图像库"><a href="#处理图像库" class="headerlink" title="处理图像库"></a>处理图像库</h3><p>由于加载时间长，一次加载后将数据存储在本地，便于二次调用</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">corpus_dataset = Corpus(config[<span class="string">&quot;corpus_path&quot;</span>], image_preprocessor)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">prepare_corpus</span>(<span class="params">image_encoder</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;处理图像库</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        corpus: tuple[torch.Tensor, torch.Tensor] 图像库索引和对应的图像特征向量</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">global</span> corpus</span><br><span class="line">    corpus_cache = config[<span class="string">&quot;corpus_cache&quot;</span>]</span><br><span class="line">    <span class="keyword">if</span> corpus_cache <span class="keyword">and</span> os.path.exists(corpus_cache): <span class="comment"># 读取缓存</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;-----Loading corpus from <span class="subst">&#123;corpus_cache&#125;</span>-----&quot;</span>)</span><br><span class="line">        corpus = torch.load(corpus_cache)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-----Preparing corpus-----&quot;</span>)</span><br><span class="line">    corpus_dataloader = DataLoader( <span class="comment"># 图像库的DataLoader</span></span><br><span class="line">        corpus_dataset,</span><br><span class="line">        batch_size=config[<span class="string">&quot;batch_size&quot;</span>],</span><br><span class="line">        shuffle=<span class="literal">False</span>,</span><br><span class="line">        num_workers=config[<span class="string">&quot;num_workers&quot;</span>],</span><br><span class="line">        pin_memory=<span class="literal">True</span>,</span><br><span class="line">        drop_last=<span class="literal">False</span></span><br><span class="line">    )</span><br><span class="line">    corpus_vectors = []</span><br><span class="line">    corpus_ids = []</span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> tqdm(corpus_dataloader): <span class="comment"># 预处理图像库</span></span><br><span class="line">        batch_vectors = F.normalize(image_encoder(batch[<span class="string">&quot;image&quot;</span>].to(config[<span class="string">&quot;device&quot;</span>])), dim=-<span class="number">1</span>) <span class="comment"># 正则化</span></span><br><span class="line">        corpus_vectors.append(batch_vectors)</span><br><span class="line">        corpus_ids.append(batch[<span class="string">&quot;idx&quot;</span>].to(config[<span class="string">&quot;device&quot;</span>]))</span><br><span class="line"></span><br><span class="line">    corpus_vectors = torch.cat(corpus_vectors)</span><br><span class="line">    corpus_ids = torch.cat(corpus_ids)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 按照索引排序</span></span><br><span class="line">    arg_ids = torch.argsort(corpus_ids)</span><br><span class="line">    corpus_vectors = corpus_vectors[arg_ids]</span><br><span class="line">    corpus_ids = corpus_ids[arg_ids]</span><br><span class="line"></span><br><span class="line">    corpus = corpus_ids, corpus_vectors</span><br><span class="line">    <span class="keyword">if</span> config[<span class="string">&quot;corpus_cache&quot;</span>]:</span><br><span class="line">        torch.save(corpus, config[<span class="string">&quot;corpus_cache&quot;</span>]) </span><br></pre></td></tr></table></figure><h3 id="提问与匹配函数"><a href="#提问与匹配函数" class="headerlink" title="提问与匹配函数"></a>提问与匹配函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">ask_for_caption</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;询问用户描述&quot;&quot;&quot;</span></span><br><span class="line">    caption = <span class="built_in">input</span>(<span class="string">&quot;Describe the image: &quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> caption</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ask_question</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;询问用户问题，获取回答&quot;&quot;&quot;</span></span><br><span class="line">    question = request_chat(dialog)</span><br><span class="line">    answer = <span class="built_in">input</span>(<span class="string">f&quot;Q: <span class="subst">&#123;question&#125;</span>\nA: &quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> question+<span class="string">&#x27; &#x27;</span>+answer</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_top_results</span>(<span class="params">dialog, dialog_encoder, n=<span class="number">1</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;获取前n最佳匹配结果</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        dialog: str 对话</span></span><br><span class="line"><span class="string">        dialog_encoder: 对话编码器</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        tops: list[int] 前n个匹配结果的索引</span></span><br><span class="line"><span class="string">        topscores: list[float] 前n个匹配结果的得分</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    dialog = config[<span class="string">&quot;sep&quot;</span>].join(dialog)</span><br><span class="line">    dialog_vector = dialog_encoder(dialog) <span class="comment"># 提取特征&amp;正则化</span></span><br><span class="line">    scores = dialog_vector @ corpus[<span class="number">1</span>].T <span class="comment"># 计算点积相似度</span></span><br><span class="line">    top_id = torch.argsort(scores, descending=<span class="literal">True</span>) <span class="comment"># 排序</span></span><br><span class="line">    tops = top_id.tolist()[<span class="number">0</span>][:n]</span><br><span class="line">    topscores = scores[<span class="number">0</span>][tops].tolist()</span><br><span class="line">    <span class="keyword">return</span> tops, topscores</span><br></pre></td></tr></table></figure><h3 id="主函数"><a href="#主函数" class="headerlink" title="主函数"></a>主函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    image_encoder, dialog_encoder = get_funcs()</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(config[<span class="string">&quot;corpus_path&quot;</span>], <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        images = json.load(f)</span><br><span class="line">        f.close()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        prepare_corpus(image_encoder)</span><br><span class="line">    </span><br><span class="line">        dialog.append(ask_for_caption())</span><br><span class="line">        tops,topscores = get_top_results(dialog, dialog_encoder)</span><br><span class="line">        best_image = images[tops[<span class="number">0</span>]]</span><br><span class="line">        best_score = topscores[<span class="number">0</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Best image: <span class="subst">&#123;best_image&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Best score: <span class="subst">&#123;best_score&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="comment"># display(Image.open(best_image))</span></span><br><span class="line">    </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">            dialog.append(ask_question())</span><br><span class="line">            tops,topscores = get_top_results(dialog, dialog_encoder)</span><br><span class="line">            best_image = images[tops[<span class="number">0</span>]]</span><br><span class="line">            best_score = topscores[<span class="number">0</span>]</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Best image: <span class="subst">&#123;best_image&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Best score: <span class="subst">&#123;best_score&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> i==<span class="number">1</span>:</span><br><span class="line">                display(Image.<span class="built_in">open</span>(best_image))</span><br></pre></td></tr></table></figure><h2 id="测试和评估"><a href="#测试和评估" class="headerlink" title="测试和评估"></a>测试和评估</h2><p>原文评估ChatIR性能的指标是Hit@10，即目标图像出现在最匹配的10个候选图像中的概率，我采用相同的评估方式</p><h3 id="对话数据集类"><a href="#对话数据集类" class="headerlink" title="对话数据集类"></a>对话数据集类</h3><p>单个测试对话数据结构：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;image&quot;</span><span class="punctuation">:</span> <span class="string">&quot;image_path&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;dialog&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;caption&quot;</span><span class="punctuation">,</span> <span class="string">&quot;question1? answer1&quot;</span><span class="punctuation">,</span> <span class="string">&quot;question2? answer2&quot;</span><span class="punctuation">,</span> ...<span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Queries</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;对话-图像数据集&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, queries_path, sep</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;加载对话-图像数据集</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            queries_path: str 查询数据集路径</span></span><br><span class="line"><span class="string">            sep: str 分隔符</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(queries_path, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            self.queries = json.load(f)</span><br><span class="line">            f.close()</span><br><span class="line">        self.dialog_length = <span class="literal">None</span></span><br><span class="line">        self.sep = sep</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.queries)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        <span class="keyword">assert</span> self.dialog_length <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span></span><br><span class="line">        target_path = self.queries[idx][<span class="string">&quot;img&quot;</span>]</span><br><span class="line">        <span class="comment"># 保留对话的前dialog_length轮</span></span><br><span class="line">        text = self.sep.join(self.queries[idx][<span class="string">&quot;dialog&quot;</span>][:self.dialog_length + <span class="number">1</span>])</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&quot;text&quot;</span>: text, <span class="string">&quot;target_path&quot;</span>: target_path&#125;</span><br></pre></td></tr></table></figure><h3 id="测试代码"><a href="#测试代码" class="headerlink" title="测试代码"></a>测试代码</h3><p>使用了论文仓库提供的测试代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">corpus_dataset = Corpus(config[<span class="string">&quot;corpus_path&quot;</span>], image_preprocessor)</span><br><span class="line">query_dataset = Queries(config[<span class="string">&quot;queries_path&quot;</span>], config[<span class="string">&quot;sep&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_get_recalls</span>(<span class="params">dataloader, dialog_length, dialog_encoder</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; 计算dataloader中长度为dialog_length的对话的召回结果</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        dataloader: 数据加载器</span></span><br><span class="line"><span class="string">        dialog_length: 对话长度</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    dataloader.dataset.dialog_length = dialog_length  <span class="comment"># 设置对话长度</span></span><br><span class="line">    recalls = []  <span class="comment"># 每个对话的召回结果</span></span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> tqdm(dataloader):</span><br><span class="line">        target_ids = torch.tensor(</span><br><span class="line">            [corpus_dataset.path_to_index(p) <span class="keyword">for</span> p <span class="keyword">in</span> batch[<span class="string">&#x27;target_path&#x27;</span>]]</span><br><span class="line">            ).unsqueeze(<span class="number">1</span>).to(config[<span class="string">&#x27;device&#x27;</span>]) <span class="comment"># 图片路径转换为索引</span></span><br><span class="line">        pred_vec = F.normalize(dialog_encoder(batch[<span class="string">&#x27;text&#x27;</span>]), dim=-<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        scores = pred_vec @ corpus[<span class="number">1</span>].T <span class="comment"># 计算点积，得到相似度分数</span></span><br><span class="line">        arg_ranks = torch.argsort(scores, descending=<span class="literal">True</span>, dim=<span class="number">1</span>).long() <span class="comment"># 对分数进行排序</span></span><br><span class="line">        </span><br><span class="line">        target_recall = ((arg_ranks - target_ids) == <span class="number">0</span>).nonzero()[:, <span class="number">1</span>] <span class="comment"># 目标图像在检索排名中出现的位置</span></span><br><span class="line">        recalls.append(target_recall)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> torch.cat(recalls)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_first_hitting_time</span>(<span class="params">target_recall, hitting_recall=<span class="number">10</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; 返回(11, n)张量，其中包含每轮（0, 11）的命中时间。inf表示未命中（10轮后没有命中） &quot;&quot;&quot;</span></span><br><span class="line">    target_recalls = target_recall.view(<span class="number">11</span>, -<span class="number">1</span>).T <span class="comment"># 转置</span></span><br><span class="line">    hits = (target_recalls &lt; hitting_recall) <span class="comment"># 目标图像是否在前 hitting_recall 轮内出现</span></span><br><span class="line"></span><br><span class="line">    final_hits = torch.inf * torch.ones(target_recalls.shape[<span class="number">0</span>]) <span class="comment"># 初始化为inf</span></span><br><span class="line"></span><br><span class="line">    hitting_times = [] <span class="comment"># 每轮的命中时间</span></span><br><span class="line">    <span class="keyword">for</span> ro_i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">11</span>):</span><br><span class="line">        rh = hits[:, ro_i]</span><br><span class="line">        final_hits[rh] = torch.<span class="built_in">min</span>(final_hits[rh], torch.ones(final_hits[rh].shape) * ro_i)</span><br><span class="line">        hitting_times.append(final_hits.clone())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> torch.stack(hitting_times)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cumulative_hits_per_round</span>(<span class="params">target_recall, hitting_recall=<span class="number">10</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; 返回直到第x轮的平均命中次数 &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span>(hitting_recall) <span class="keyword">is</span> <span class="built_in">tuple</span>:</span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(hitting_recall) == <span class="number">1</span></span><br><span class="line">        hitting_recall = hitting_recall[<span class="number">0</span>]</span><br><span class="line">    ht_times = get_first_hitting_time(target_recall, hitting_recall)</span><br><span class="line">    <span class="keyword">return</span> ((ht_times &lt; torch.inf).<span class="built_in">sum</span>(dim=-<span class="number">1</span>) * <span class="number">100</span> / ht_times[<span class="number">0</span>].shape[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">eval</span>(<span class="params">image_encoder, dialog_encoder, hits_at=<span class="number">10</span></span>):</span><br><span class="line">    prepare_corpus(image_encoder)</span><br><span class="line">    query_dataloader = torch.utils.data.DataLoader(query_dataset, <span class="comment"># 询问数据集</span></span><br><span class="line">                                             batch_size=config[<span class="string">&#x27;batch_size&#x27;</span>], <span class="comment"># 批大小</span></span><br><span class="line">                                             shuffle=<span class="literal">False</span>, <span class="comment"># 不打乱</span></span><br><span class="line">                                             num_workers=config[<span class="string">&#x27;num_workers&#x27;</span>], <span class="comment"># 多线程</span></span><br><span class="line">                                             pin_memory=<span class="literal">True</span>, <span class="comment"># 锁页内存</span></span><br><span class="line">                                             drop_last=<span class="literal">False</span></span><br><span class="line">                                             )</span><br><span class="line">    hits_results = []</span><br><span class="line">    <span class="keyword">for</span> dl <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">11</span>): <span class="comment"># 对话长度从0到10</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Calculate recalls for each dialogues of length <span class="subst">&#123;dl&#125;</span>...&quot;</span>)</span><br><span class="line">        dialog_recalls = _get_recalls(query_dataloader, dialog_length=dl, dialog_encoder=dialog_encoder)</span><br><span class="line">        hits_results.append(dialog_recalls)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用cumulative_hits_per_round计算最终的Hits@10结果</span></span><br><span class="line">    <span class="comment"># Hits@10：`在预测的前 10 个候选项中，包含了正确答案`的比例</span></span><br><span class="line">    hits_results = cumulative_hits_per_round(torch.cat(hits_results).cpu(), hitting_recall=<span class="number">10</span>).tolist()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;====== Results for Hits@10 ====== &quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> dl <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">11</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;\t Dialog Length: <span class="subst">&#123;dl&#125;</span>: <span class="subst">&#123;<span class="built_in">round</span>(hits_results[dl], <span class="number">2</span>)&#125;</span>%&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    image_encoder, dialog_encoder = get_funcs()</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(config[<span class="string">&quot;corpus_path&quot;</span>], <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        images = json.load(f)</span><br><span class="line">        f.close()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="built_in">eval</span>(image_encoder, dialog_encoder)</span><br></pre></td></tr></table></figure><h3 id="对话数据生成"><a href="#对话数据生成" class="headerlink" title="对话数据生成"></a>对话数据生成</h3><p>原文中，为了自动获取测试数据，免除人工回答，使用了BLIP2模型回答问题</p><p>我参考原文的方法，使用BLIP2生成对话数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> lavis.models <span class="keyword">import</span> load_model_and_preprocess <span class="comment"># BLIP2</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> OpenAI <span class="keyword">import</span> request_chat</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">st,ed = <span class="built_in">int</span>(sys.argv[<span class="number">1</span>]), <span class="built_in">int</span>(sys.argv[<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;../dialogues/ChatGPT_BLIP2.json&quot;</span>, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    data = json.load(f)</span><br><span class="line">    f.close()</span><br><span class="line"></span><br><span class="line">images = [d[<span class="string">&quot;img&quot;</span>] <span class="keyword">for</span> d <span class="keyword">in</span> data][st:ed]</span><br><span class="line">captions = [d[<span class="string">&quot;dialog&quot;</span>][<span class="number">0</span>] <span class="keyword">for</span> d <span class="keyword">in</span> data][st:ed]</span><br><span class="line"></span><br><span class="line">config = &#123;</span><br><span class="line">    <span class="string">&quot;device&quot;</span>: <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>,</span><br><span class="line">    <span class="string">&quot;image_size&quot;</span> : <span class="number">224</span>,</span><br><span class="line">    <span class="string">&quot;sep&quot;</span>: <span class="string">&quot;, &quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> config[<span class="string">&quot;device&quot;</span>] == <span class="string">&quot;cuda&quot;</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Using GPU&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_image</span>(<span class="params">image_path</span>):</span><br><span class="line">    raw_image = Image.<span class="built_in">open</span>(image_path).convert(<span class="string">&#x27;RGB&#x27;</span>)</span><br><span class="line">    image = vis_processors[<span class="string">&quot;eval&quot;</span>](raw_image).unsqueeze(<span class="number">0</span>).to(config[<span class="string">&quot;device&quot;</span>])</span><br><span class="line">    <span class="keyword">return</span> image</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">visual_qa</span>(<span class="params">image, question, model</span>):</span><br><span class="line">    answer = model.generate(&#123;<span class="string">&quot;image&quot;</span>: image, <span class="string">&quot;prompt&quot;</span>: <span class="string">f&quot;Question: <span class="subst">&#123;question&#125;</span> Answer:&quot;</span>&#125;)</span><br><span class="line">    <span class="keyword">return</span> answer[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ask_question</span>(<span class="params">dialog</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;询问用户问题&quot;&quot;&quot;</span></span><br><span class="line">    question = request_chat(dialog)</span><br><span class="line">    <span class="keyword">return</span> question</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_dialog</span>(<span class="params">idx, model</span>):</span><br><span class="line">    image = load_image(images[idx])</span><br><span class="line">    caption = captions[idx]</span><br><span class="line">    dialog = [caption]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        question = ask_question(dialog)</span><br><span class="line">        answer = visual_qa(image, question, model)</span><br><span class="line">        dialog.append(question+answer)</span><br><span class="line">    ret = &#123;</span><br><span class="line">        <span class="string">&quot;img&quot;</span>: images[idx],</span><br><span class="line">        <span class="string">&quot;dialog&quot;</span>: dialog</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> ret</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    model, vis_processors, _ = load_model_and_preprocess(</span><br><span class="line">        name=<span class="string">&quot;blip2_opt&quot;</span>, model_type=<span class="string">&quot;caption_coco_opt6.7b&quot;</span>, is_eval=<span class="literal">True</span>, device=config[<span class="string">&quot;device&quot;</span>]</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;ChatGPT4oMini_BLIP2.txt&quot;</span>, <span class="string">&quot;a&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">for</span> idx <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(<span class="built_in">len</span>(images))):</span><br><span class="line">                dialog = generate_dialog(idx, model)</span><br><span class="line">                json.dump(dialog, f)</span><br><span class="line">                f.write(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">            f.close()</span><br></pre></td></tr></table></figure><h3 id="测试日志"><a href="#测试日志" class="headerlink" title="测试日志"></a>测试日志</h3><ol><li>由于OpenAI的token限制，我使用了讯飞星火API作为提问模型G</li><li>论文没读仔细，一开始以为生成对话数据时，代替人类回答的模型和编码用的模型一样，是BLIP</li><li>在以上基础上，测试的Hit@10结果（40%~60%）与原文（63%~80%）有较大差距</li><li>原本认为是提问模型G没有用ChatGPT的原因，微氪token，调整为ChatGPT4o-mini，但结果依然不理想（40%~67%）</li><li>注意到，40%是$D_0$，也就是只有用BLIP生成的第一句描述时的准确率，和提问模型G无关</li><li>对比原文，发现回答模型应该是另一篇paper中的BLIP2，而不是BLIP</li><li>修改数据生成代码，使用BLIP2生成对话数据，测试结果与原文接近（60%~80%）</li></ol><p>客观问题：由于硬件条件有限，跑出一条数据需要3~5分钟，因此只测试了1021条数据，对于整体性能评估可能不够准确</p><h3 id="测试结果"><a href="#测试结果" class="headerlink" title="测试结果"></a>测试结果</h3><p>在使用ChatGPT作为提问模型G，BLIP2作为回答模型A，使用同一测试代码的情况下，测试结果和原文对比如下：</p><div class="table-container"><table><thead><tr><th style="text-align:center">length</th><th style="text-align:center">原文(2064 testcases)</th><th style="text-align:center">实现（1021 testcases）</th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center">63.42%</td><td style="text-align:center">62.98%</td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">69.43%</td><td style="text-align:center">70.62%</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">72.38%</td><td style="text-align:center">72.67%</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">74.47%</td><td style="text-align:center">74.53%</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">76.02%</td><td style="text-align:center">75.32%</td></tr><tr><td style="text-align:center">5</td><td style="text-align:center">77.47%</td><td style="text-align:center">75.42%</td></tr><tr><td style="text-align:center">6</td><td style="text-align:center">78.49%</td><td style="text-align:center">76.00%</td></tr><tr><td style="text-align:center">7</td><td style="text-align:center">79.65%</td><td style="text-align:center">76.20%</td></tr><tr><td style="text-align:center">8</td><td style="text-align:center">80.09%</td><td style="text-align:center">76.69%</td></tr><tr><td style="text-align:center">9</td><td style="text-align:center">80.43%</td><td style="text-align:center">76.98%</td></tr><tr><td style="text-align:center">10</td><td style="text-align:center">80.77%</td><td style="text-align:center">77.18%</td></tr></tbody></table></div><p>在第五轮对话后，对话长度增加对检索性能的提升不再明显</p>]]></content>
    
    
    <summary type="html">实现论文《Chatting Makes Perfect：Chat-based Image Retrival》</summary>
    
    
    
    <category term="论文笔记" scheme="https://www.cclmsy.cc/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="论文实现" scheme="https://www.cclmsy.cc/tags/%E8%AE%BA%E6%96%87%E5%AE%9E%E7%8E%B0/"/>
    
    <category term="图像检索" scheme="https://www.cclmsy.cc/tags/%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2/"/>
    
    <category term="MLLM" scheme="https://www.cclmsy.cc/tags/MLLM/"/>
    
  </entry>
  
  <entry>
    <title>Pretrained BLIP 模型调用</title>
    <link href="https://www.cclmsy.cc/posts/pretrained_blip.html"/>
    <id>https://www.cclmsy.cc/posts/pretrained_blip.html</id>
    <published>2025-03-02T16:00:00.000Z</published>
    <updated>2025-07-20T12:14:16.220Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://github.com/salesforce/BLIP">Github Repo</a></p><p>BLIP全称Bootstrapping Language-Image Pre-training，是一个全新的 统一视觉语言理解与生成的预训练模型</p><p>它统一了视觉语言任务的理解与生成功能，并且通过嵌入 Captioner 和 Filter 去除网络资源中的文本噪声，提高了模型在下游视觉语言任务上的性能</p><h2 id="Colab-Notebook-运行"><a href="#Colab-Notebook-运行" class="headerlink" title="Colab Notebook 运行"></a>Colab Notebook 运行</h2><p>Salesforce在Colab NoteBook中提供了Demo，可以在云端直接运行：<a href="https://colab.research.google.com/github/salesforce/BLIP/blob/main/demo.ipynb">Colab notebook</a></p><p>第一步配置环境时出现<code>ERROR: Failed building wheel for tokenizers</code>问题，在<a href="https://github.com/salesforce/BLIP/issues/151#issuecomment-1537125671">Issue#151的评论</a>中提供了解决方案：修改transformers版本<code>4.25.1</code></p><h2 id="本地调用"><a href="#本地调用" class="headerlink" title="本地调用"></a>本地调用</h2><p>学习在本地使用Pretrained BLIP模型，测试代码置于BLIP目录下</p><p>实验环境：</p><ul><li>Python 3.11.11 on conda</li><li>transformers 4.25.1</li><li>timm 0.4.12</li><li>fairscale 0.4.4</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms.functional <span class="keyword">import</span> InterpolationMode</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_demo_image</span>(<span class="params">image_size,device</span>):</span><br><span class="line">    img_url = <span class="string">&#x27;https://storage.googleapis.com/sfr-vision-language-research/BLIP/demo.jpg&#x27;</span> </span><br><span class="line">    raw_image = Image.<span class="built_in">open</span>(requests.get(img_url, stream=<span class="literal">True</span>).raw).convert(<span class="string">&#x27;RGB&#x27;</span>)   </span><br><span class="line"></span><br><span class="line">    w,h = raw_image.size</span><br><span class="line">    <span class="built_in">print</span>(raw_image.resize((w//<span class="number">5</span>,h//<span class="number">5</span>)))</span><br><span class="line">    </span><br><span class="line">    transform = transforms.Compose([</span><br><span class="line">        transforms.Resize((image_size,image_size),interpolation=InterpolationMode.BICUBIC),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize((<span class="number">0.48145466</span>, <span class="number">0.4578275</span>, <span class="number">0.40821073</span>), (<span class="number">0.26862954</span>, <span class="number">0.26130258</span>, <span class="number">0.27577711</span>))</span><br><span class="line">        ]) </span><br><span class="line">    image = transform(raw_image).unsqueeze(<span class="number">0</span>).to(device)   </span><br><span class="line">    <span class="keyword">return</span> image</span><br></pre></td></tr></table></figure><h3 id="Image-Captioning-图像描述"><a href="#Image-Captioning-图像描述" class="headerlink" title="Image Captioning 图像描述"></a>Image Captioning 图像描述</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> models.blip <span class="keyword">import</span> blip_decoder</span><br><span class="line"></span><br><span class="line">image_size = <span class="number">384</span></span><br><span class="line">image = load_demo_image(image_size=image_size, device=device)</span><br><span class="line"></span><br><span class="line">model_url = <span class="string">&#x27;https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth&#x27;</span></span><br><span class="line">    </span><br><span class="line">model = blip_decoder(pretrained=model_url, image_size=image_size, vit=<span class="string">&#x27;base&#x27;</span>)</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line">model = model.to(device)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="comment"># beam search </span></span><br><span class="line">    caption = model.generate(image, sample=<span class="literal">False</span>, num_beams=<span class="number">3</span>, max_length=<span class="number">20</span>, min_length=<span class="number">5</span>)</span><br><span class="line">    <span class="comment"># nucleus sampling</span></span><br><span class="line">    <span class="comment"># caption = model.generate(image, sample=True, top_p=0.9, max_length=20, min_length=5)  </span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;caption: &#x27;</span>+caption[<span class="number">0</span>])</span><br></pre></td></tr></table></figure><pre><code>The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.Moving 0 files to the new cache system0it [00:00, ?it/s]&lt;PIL.Image.Image image mode=RGB size=409x273 at 0x11139327650&gt;reshape position embedding from 196 to 576load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pthcaption: a woman and her dog on the beach</code></pre><h3 id="Visual-Question-Answering-视觉问答"><a href="#Visual-Question-Answering-视觉问答" class="headerlink" title="Visual Question Answering 视觉问答"></a>Visual Question Answering 视觉问答</h3><p>由于存在和ImageCaptioning中的beam_search相同的版本问题，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> models.blip_vqa <span class="keyword">import</span> blip_vqa</span><br><span class="line"></span><br><span class="line">image_size = <span class="number">480</span></span><br><span class="line">image = load_demo_image(image_size=image_size, device=device)     </span><br><span class="line"></span><br><span class="line">model_url = <span class="string">&#x27;https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_vqa_capfilt_large.pth&#x27;</span></span><br><span class="line">    </span><br><span class="line">model = blip_vqa(pretrained=model_url, image_size=image_size, vit=<span class="string">&#x27;base&#x27;</span>)</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line">model = model.to(device)</span><br><span class="line"></span><br><span class="line">question = <span class="string">&#x27;where is the woman sitting?&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    answer = model(image, question, train=<span class="literal">False</span>, inference=<span class="string">&#x27;generate&#x27;</span>) </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;answer: &#x27;</span>+answer[<span class="number">0</span>])</span><br></pre></td></tr></table></figure><pre><code>&lt;PIL.Image.Image image mode=RGB size=409x273 at 0x11139109090&gt;load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_vqa_capfilt_large.pthanswer: on beach</code></pre><h3 id="Image-Text-Matching-图文匹配"><a href="#Image-Text-Matching-图文匹配" class="headerlink" title="Image-Text Matching 图文匹配"></a>Image-Text Matching 图文匹配</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> models.blip_itm <span class="keyword">import</span> blip_itm</span><br><span class="line"></span><br><span class="line">image_size = <span class="number">384</span></span><br><span class="line">image = load_demo_image(image_size=image_size,device=device)</span><br><span class="line"></span><br><span class="line">model_url = <span class="string">&#x27;https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_retrieval_coco.pth&#x27;</span></span><br><span class="line">    </span><br><span class="line">model = blip_itm(pretrained=model_url, image_size=image_size, vit=<span class="string">&#x27;base&#x27;</span>)</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line">model = model.to(device=device)</span><br><span class="line"></span><br><span class="line">caption = <span class="string">&#x27;a woman sitting on the beach with a dog&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;text: %s&#x27;</span> %caption)</span><br><span class="line"></span><br><span class="line">itm_output = model(image,caption,match_head=<span class="string">&#x27;itm&#x27;</span>)</span><br><span class="line">itm_score = torch.nn.functional.softmax(itm_output,dim=<span class="number">1</span>)[:,<span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;The image and text is matched with a probability of %.4f&#x27;</span>%itm_score)</span><br><span class="line"></span><br><span class="line">itc_score = model(image,caption,match_head=<span class="string">&#x27;itc&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;The image feature and text feature has a cosine similarity of %.4f&#x27;</span>%itc_score)</span><br></pre></td></tr></table></figure><pre><code>&lt;PIL.Image.Image image mode=RGB size=409x273 at 0x11130227FD0&gt;load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_retrieval_coco.pthtext: a woman sitting on the beach with a dogThe image and text is matched with a probability of 0.9960The image feature and text feature has a cosine similarity of 0.5262</code></pre>]]></content>
    
    
    <summary type="html">Salesforce提供的统一视觉语言理解与生成的预训练模型</summary>
    
    
    
    <category term="DL笔记" scheme="https://www.cclmsy.cc/categories/DL%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="模型调用" scheme="https://www.cclmsy.cc/tags/%E6%A8%A1%E5%9E%8B%E8%B0%83%E7%94%A8/"/>
    
  </entry>
  
  <entry>
    <title>复现|手搓Transformer模型</title>
    <link href="https://www.cclmsy.cc/posts/transformer.html"/>
    <id>https://www.cclmsy.cc/posts/transformer.html</id>
    <published>2025-02-27T16:00:00.000Z</published>
    <updated>2025-07-21T05:32:34.685Z</updated>
    
    <content type="html"><![CDATA[<p>论文：<a href="https://arxiv.org/abs/1706.03762">Attention is All You Need</a></p><blockquote><p>2017年Google在论文《Attention is All You Need》中提出了Transformer模型，并成功应用到NLP领域。<br>该模型完全基于自注意力机制Attention mechanism实现，弥补了传统的RNN模型的不足。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="comment"># 全局变量</span></span><br><span class="line">d_model = <span class="number">512</span> <span class="comment"># 词向量维度</span></span><br><span class="line">d_ff = <span class="number">2048</span> <span class="comment"># 前馈神经网络隐层维度</span></span><br><span class="line">src_vocab_size = <span class="number">10</span> <span class="comment"># 源语言词表大小</span></span><br><span class="line">tgt_vocab_size = <span class="number">10</span> <span class="comment"># 目标语言词表大小</span></span><br><span class="line">n_layers = <span class="number">6</span> <span class="comment"># 编码器和解码器堆叠基础块的数量</span></span><br></pre></td></tr></table></figure><h2 id="0-Transformer原理"><a href="#0-Transformer原理" class="headerlink" title="0.Transformer原理"></a>0.Transformer原理</h2><p>宏观上，Transformer可以看作一个黑箱操作的Seq2Seq模型。<br>拆开黑箱，可以看到模型的本质是一个Encoder-Decoder结构。</p><p><img src="https://source.cclmsy.cc/posts/notes/papers/transformer/Transformer整体架构.webp" alt="Transformer整体架构"></p><ul><li>Embedding：词嵌入层，将输入的词转换为词向量</li><li>Positional Encoding：位置编码，为了让模型学习到序列的位置信息</li><li>Multi-Head Attention：多头注意力机制，用于捕捉输入序列的全局依赖关系</li><li>Add &amp; Norm：残差连接和层归一化，用于加速训练、缓解梯度消失问题<ul><li>Add残差连接：把网络的输入和输出相加，有效解决梯度消失问题</li><li>Norm层归一化：对网络的输出进行归一化处理，加速训练</li></ul></li><li>Feed Forward：前馈神经网络，用于对特征进行非线性变换</li><li>Linear：线性变换层，用于将特征映射到输出空间</li><li>Softmax：Softmax层，用于输出概率分布</li></ul><h2 id="1-Encoder"><a href="#1-Encoder" class="headerlink" title="1.Encoder"></a>1.Encoder</h2><p><img src="https://source.cclmsy.cc/posts/notes/papers/transformer/Transformer_Encoder.webp" alt="Transformer_Encoder"></p><h3 id="1-1-Embedding-词嵌入"><a href="#1-1-Embedding-词嵌入" class="headerlink" title="1.1 Embedding 词嵌入"></a>1.1 Embedding 词嵌入</h3><p>模型无法直接处理文本数据，需要把文本数据转换成计算机能够识别的向量形式。<br>将文本转化为向量通常有两种方式：</p><ul><li>One-hot编码：词典大小为N，每个词用一个N维向量表示，当前词对应的维度为1，其余维度为0<ul><li>优点：简单直观</li><li>缺点：向量维度高、稀疏、缺乏语义之间的联系</li></ul></li><li>Embedding词嵌入：通过训练学习到的词向量，将词映射到一个低维空间<ul><li>优点：低维、稠密、能够表达词之间的关系</li></ul></li></ul><p>输入Imput的维度是[batch_size, seq_len]，Embedding层的输出维度是[batch_size, seq_len, d_model]。</p><ul><li>batch_size：批次大小（句子个数）</li><li>seq_len：最长句子长度</li><li>d_model：词向量维度</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Embeddings</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, vocab_size, d_model</span>):</span><br><span class="line">        <span class="built_in">super</span>(Embeddings, self).__init__()</span><br><span class="line">        <span class="comment"># 调用nn.Embedding，获得实例化的词嵌入对象lut(look up table)</span></span><br><span class="line">        self.lut = nn.Embedding(vocab_size, d_model)</span><br><span class="line">        self.d_model = d_model <span class="comment"># 词嵌入维度</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Embedding层的前向传播</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            x: 输入的词索引张量，形状为(batch_size, seq_len)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            词嵌入张量，形状为(batch_size, seq_len, d_model)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> self.lut(x) * math.sqrt(self.d_model)</span><br></pre></td></tr></table></figure><h3 id="1-2-Positional-Encoding-位置编码"><a href="#1-2-Positional-Encoding-位置编码" class="headerlink" title="1.2 Positional Encoding 位置编码"></a>1.2 Positional Encoding 位置编码</h3><p>Embedding层只能表示词的语义信息，无法表示词的位置信息。<br>Transformer使用的是自注意力机制来提取信息，一个句子中的每个字/词是并行计算，虽然处理每个字的时候考虑到了所有字对其的影响，但是并没有考虑到各个字相互之间的位置信息，也就是上下文，所以需要引入位置信息</p><p>为了让模型学习到序列的位置信息，需要在Embedding层的输出上加上位置编码，得到含有位置信息的词向量$\alpha$。</p><p>Transformer中使用Positional Encoding表示每个字、词的位置信息，公式如下：</p><script type="math/tex; mode=display">PE_{(pos, i)} = \begin{cases}sin(w_k \cdot pos), & i = 2k \\\\cos(w_k \cdot pos), & i = 2k+1\end{cases}</script><script type="math/tex; mode=display">w_k = \dfrac{1}{10000^{2k/d_{model}}} \quad k = 0,1,2,...,d_{model}-1</script><p>其中：</p><ul><li>$PE_{(pos, i)}$：表示第$pos$个字/词的Encoding向量第$i$维的编码值</li><li>$pos$：位置信息，表示句子中的第几个字/词，从0开始</li><li>$i$：位置编码的维度，从0开始</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PositionalEncoding</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model, dropout=<span class="number">0.1</span>, max_len=<span class="number">5000</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(PositionalEncoding, self).__init__()</span><br><span class="line">        self.dropout = nn.Dropout(p=dropout)</span><br><span class="line">        <span class="comment"># 初始化一个形状为(max_len, d_model)的位置编码矩阵</span></span><br><span class="line">        pe = torch.zeros(max_len, d_model)</span><br><span class="line">        <span class="comment"># position[i] = i</span></span><br><span class="line">        position = torch.arange(<span class="number">0</span>, max_len).unsqueeze(<span class="number">1</span>).<span class="built_in">float</span>()</span><br><span class="line">        <span class="comment"># w_k=e^(2k*-log10000/d_model)=1/(10000^(2k/d_model))</span></span><br><span class="line">        div_term = torch.exp(torch.arange(<span class="number">0</span>, d_model, <span class="number">2</span>).<span class="built_in">float</span>() * -(math.log(<span class="number">10000.0</span>) / d_model))</span><br><span class="line">        <span class="comment"># 偶数列使用sin函数编码，奇数列使用cos函数编码</span></span><br><span class="line">        pe[:, <span class="number">0</span>::<span class="number">2</span>] = torch.sin(position * div_term)</span><br><span class="line">        pe[:, <span class="number">1</span>::<span class="number">2</span>] = torch.cos(position * div_term)</span><br><span class="line">        <span class="comment"># 在第0维增加一个维度，形状变为(batch_size=1, max_len, d_model)</span></span><br><span class="line">        pe = pe.unsqueeze(<span class="number">0</span>)</span><br><span class="line">        self.register_buffer(<span class="string">&#x27;pe&#x27;</span>, pe)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;位置编码层的前向传播</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            x: 输入的词嵌入张量，形状为(batch_size, seq_len, d_model)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            添加了位置编码的词嵌入张量，形状为(batch_size, seq_len, d_model)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        x = x + self.pe[:, :x.size(<span class="number">1</span>)].clone().detach()</span><br><span class="line">        <span class="keyword">return</span> self.dropout(x)</span><br></pre></td></tr></table></figure><h3 id="1-3-Self-Attention-自注意力机制"><a href="#1-3-Self-Attention-自注意力机制" class="headerlink" title="1.3 Self Attention 自注意力机制"></a>1.3 Self Attention 自注意力机制</h3><p>一句话中，与语义紧密相关的关键词需要予以更多的关注，而无关的连接词和辅助词则可以忽略。<br>在机器翻译时，更多的注意表现为更大的权重，越重要的词权重越大。</p><p><img src="https://source.cclmsy.cc/posts/notes/papers/transformer/Self_Attention.webp" alt="Self Attention"></p><p>包含位置信息的词向量$\alpha^i$（句子的第i+1个词的词向量）作为Self Attention的输入，分别乘以三个权重矩阵$W^Q$、$W^K$、$W^V$，得到：</p><ul><li>$q^i$：Query，查询向量</li><li>$k^i$：Key，键向量，“被查”时的向量</li><li>$v^i$：Value，值向量，“内容”的向量</li></ul><p>以4个字的句子“我是学生”为例，计算第0个字“我”的Self Attention：</p><ol><li>计算 $q^0$ 和 $k^0,k^1,k^2,k^3$ 的点积，得到4个注意力值 $\alpha<em>{00},\alpha</em>{01},\alpha<em>{02},\alpha</em>{03}$</li></ol><ul><li>经过Softmax归一化，得到4个注意力分数 $\hat{\alpha<em>{00}},\hat{\alpha</em>{01}},\hat{\alpha<em>{02}},\hat{\alpha</em>{03}}$ ，它们的和为1</li><li>将这些分数作为权重，对 $v^0,v^1,v^2,v^3$ 进行加权求和，得到Self Attention的输出</li><li>$b^0=\hat{\alpha<em>{00}}v^0+\hat{\alpha</em>{01}}v^1+\hat{\alpha<em>{02}}v^2+\hat{\alpha</em>{03}}v^3$</li></ul><p>为了加速计算，可以使用矩阵运算：</p><p><img src="https://source.cclmsy.cc/posts/notes/papers/transformer/Self_Attention_Matrix.png" alt="Self Attention矩阵运算"></p><ul><li>其中$\alpha_{ij}=\dfrac{q_i * k_j^T}{\sqrt{d_k}}$，$d_k$是词向量的维度<ul><li>为什么要除以$\sqrt{d_k}$？因为当$d_k$很大时，点积的值会很大，导致Softmax函数的梯度消失，影响模型的训练。</li></ul></li><li>最后计算$b^i=\sum<em>{j=0}^{n-1}\hat{\alpha</em>{ij}}v_j$</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ScaledDotProductAttention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, scale_factor, dropout=<span class="number">0.0</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.scale_factor = scale_factor <span class="comment"># 缩放因子</span></span><br><span class="line">        <span class="comment"># Dropout用于防止过拟合</span></span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, Q, K, V, mask=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;前向传播</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        batch_size: 批大小</span></span><br><span class="line"><span class="string">        num_heads: 多头注意力的头数，论文默认为8</span></span><br><span class="line"><span class="string">        seq_len: 序列长度</span></span><br><span class="line"><span class="string">        d_k, d_v: 键和值的维度，默认都是64</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            Q: 查询张量，形状为(batch_size, num_heads, seq_len, d_k)</span></span><br><span class="line"><span class="string">            K: 键张量，形状为(batch_size, num_heads, seq_len, d_k)</span></span><br><span class="line"><span class="string">            V: 值张量，形状为(batch_size, num_heads, seq_len, d_v)</span></span><br><span class="line"><span class="string">            mask: 掩码张量，形状为(batch_size, seq_len, seq_len)，默认为None</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            上下文张量和注意力张量</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        attn = torch.matmul(Q / self.scale_factor, K.transpose(<span class="number">2</span>, <span class="number">3</span>)) <span class="comment"># K的第2和第3维转置</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># if mask is not None:</span></span><br><span class="line">        <span class="comment">#     scores = scores.masked_fill(mask == 0, -1e9)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Softmax计算注意力权重，Dropout减少过拟合</span></span><br><span class="line">        attn = self.dropout(torch.softmax(attn, dim=-<span class="number">1</span>))</span><br><span class="line">        output = torch.matmul(attn, V)</span><br><span class="line">        <span class="keyword">return</span> output, attn <span class="comment"># 返回上下文张量和注意力张量</span></span><br></pre></td></tr></table></figure><h3 id="1-4-Multi-Head-Attention-多头注意力机制"><a href="#1-4-Multi-Head-Attention-多头注意力机制" class="headerlink" title="1.4 Multi-Head Attention 多头注意力机制"></a>1.4 Multi-Head Attention 多头注意力机制</h3><p>多头注意力机制就是把$q^i, k^i, v^i$三个矩阵从特征维度（词向量长度）方向上拆分成为形状相同的小矩阵。<br>再将每个Head Attention的输出拼接起来，得到最终的Multi-Head Attention输出。</p><p>理解：多个头分别关注不同的特征子空间，最后再将这些子空间的信息融合起来。</p><p><img src="https://source.cclmsy.cc/posts/notes/papers/transformer/Multi_Head_Attention.webp" alt="Multi-Head Attention"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MultiHeadAttention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_head=<span class="number">8</span>, d_model=<span class="number">512</span>, d_k=<span class="number">64</span>, d_v=<span class="number">64</span>, droupout=<span class="number">0.1</span></span>):</span><br><span class="line">        <span class="comment"># 论文中，参数分别为：8、512、64、64</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        self.n_head = n_head</span><br><span class="line">        self.d_k = d_k</span><br><span class="line">        self.d_v = d_v</span><br><span class="line"></span><br><span class="line">        self.w_qs = nn.Linear(d_model, n_head * d_k, bias=<span class="literal">False</span>)</span><br><span class="line">        self.w_ks = nn.Linear(d_model, n_head * d_k, bias=<span class="literal">False</span>)</span><br><span class="line">        self.w_vs = nn.Linear(d_model, n_head * d_v, bias=<span class="literal">False</span>)</span><br><span class="line">        self.fc = nn.Linear(n_head * d_v, d_model, bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        self.attention = ScaledDotProductAttention(scale_factor=d_k ** <span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">        self.dropout = nn.Dropout(droupout)</span><br><span class="line">        self.layer_norm = nn.LayerNorm(d_model, eps=<span class="number">1e-6</span>) <span class="comment"># LayerNorm层，用于归一化</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, Q, K, V, mask=<span class="literal">None</span></span>):</span><br><span class="line">        d_k, d_v, n_head = self.d_k, self.d_v, self.n_head</span><br><span class="line">        batch_size, len_q, len_k, len_v = Q.size(<span class="number">0</span>), Q.size(<span class="number">1</span>), K.size(<span class="number">1</span>), V.size(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        residual = Q <span class="comment"># 保留输入用作残差连接</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将Q、K、V归一化后，分别通过线性映射到多头</span></span><br><span class="line">        <span class="comment"># Q: (batch_size, len_q, d_model) -&gt; (batch_size, len_q, n_head * d_k) -&gt; (batch_size, n_head, len_q, d_k)</span></span><br><span class="line">        <span class="comment"># Q：(batch_size, len_q, 512) -&gt; (batch_size, len_q, 8*64) -&gt; (batch_size, len_q, 8, 64)</span></span><br><span class="line">        Q = self.layer_norm(Q)</span><br><span class="line">        K = self.layer_norm(K)</span><br><span class="line">        V = self.layer_norm(V)</span><br><span class="line">        Q = self.w_qs(Q).view(batch_size, len_q, n_head, d_k)</span><br><span class="line">        K = self.w_ks(K).view(batch_size, len_k, n_head, d_k)</span><br><span class="line">        V = self.w_vs(V).view(batch_size, len_v, n_head, d_v)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 转置，使得第1和第2维交换位置，进行Attention计算</span></span><br><span class="line">        <span class="comment"># Q: (batch_size, len_q, n_head, d_k) -&gt; (batch_size, n_head, len_q, d_k)</span></span><br><span class="line">        <span class="comment"># Q：(batch_size, len_q, 8, 64) -&gt; (batch_size, 8, len_q, 64)</span></span><br><span class="line">        Q, K, V = Q.transpose(<span class="number">1</span>, <span class="number">2</span>), K.transpose(<span class="number">1</span>, <span class="number">2</span>), V.transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            mask = mask.unsqueeze(<span class="number">1</span>) <span class="comment"># 增加一个Head维度</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Q=Softmax(Q*K/d + (1-S)σ)V，attn是QK/D</span></span><br><span class="line">        Q, attn = self.attention(Q, K, V, mask=mask) </span><br><span class="line"></span><br><span class="line">        <span class="comment"># Q的形状：[batch_size, n_head, len_q, d_v] [2,8,5,64]</span></span><br><span class="line">        Q = Q.transpose(<span class="number">1</span>, <span class="number">2</span>).contiguous().view(batch_size, len_q, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        Q = self.dropout(self.fc(Q))</span><br><span class="line"></span><br><span class="line">        Q += residual <span class="comment"># 残差连接Add</span></span><br><span class="line">        Q = self.layer_norm(Q) <span class="comment"># LayerNorm</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> Q, attn</span><br></pre></td></tr></table></figure><h3 id="1-5-Add-amp-Norm-残差连接和层归一化"><a href="#1-5-Add-amp-Norm-残差连接和层归一化" class="headerlink" title="1.5 Add &amp; Norm 残差连接和层归一化"></a>1.5 Add &amp; Norm 残差连接和层归一化</h3><p>Add残差链接就是将网络的输入和输出直接相加，主要是为了解决梯度消失问题。</p><p>Layer Normalization是对网络的输出进行归一化处理，加速训练。<br>使$b$的每一行，也就是每个句子，归一化为标准正态分布，输出为$\hat b$，归一化公式如下：</p><ul><li>均值：$\mu<em>i=\dfrac{1}{d}\sum</em>{j=1}^{d}b_{ij}$</li><li>方差：$\sigma<em>i^2=\dfrac{1}{d}\sum</em>{j=1}^{d}(b_{ij}-\mu_i)^2$</li><li>归一化：$\hat b<em>{ij}=\dfrac{b</em>{ij}-\mu_i}{\sqrt{\sigma_i^2+\epsilon}}*\gamma+\beta$</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LayerNorm</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model, eps=<span class="number">1e-12</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(LayerNorm, self).__init__()</span><br><span class="line">        self.gamma = nn.Parameter(torch.ones(d_model))</span><br><span class="line">        self.beta = nn.Parameter(torch.zeros(d_model))</span><br><span class="line">        self.eps = eps <span class="comment"># 防止分母为0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        mean = x.mean(-<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        var = x.var(-<span class="number">1</span>, unbiased=<span class="literal">False</span>, keepdim=<span class="literal">True</span>) <span class="comment"># unbiased=False表示方差计算非无偏估计（除以N而不是N-1）</span></span><br><span class="line"></span><br><span class="line">        out = (x - mean) / torch.sqrt(var + self.eps)</span><br><span class="line">        out = self.gamma * out + self.beta</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><h3 id="1-6-Feed-Forward-前馈神经网络"><a href="#1-6-Feed-Forward-前馈神经网络" class="headerlink" title="1.6 Feed Forward 前馈神经网络"></a>1.6 Feed Forward 前馈神经网络</h3><p>Add &amp; Norm层后接一个全连接的前馈神经网络，用于对特征进行非线性变换</p><p>前馈神经网络的结构是两个全连接层，第一个全连接层的激活函数是ReLU，第二个全连接层没有激活函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PositionwiseFeedForward</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(PositionwiseFeedForward, self).__init__()</span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(d_model, d_ff, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(d_ff, d_model, bias=<span class="literal">False</span>))</span><br><span class="line">        self.layer_norm = nn.LayerNorm(d_model, eps=<span class="number">1e-6</span>) <span class="comment"># LayerNorm层，用于归一化</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs</span>):</span><br><span class="line">        resdual = inputs</span><br><span class="line">        output = self.fc(inputs)</span><br><span class="line">        output = self.layer_norm(output + resdual)</span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure><h3 id="1-7-Mask掉-停用词"><a href="#1-7-Mask掉-停用词" class="headerlink" title="1.7 Mask掉 停用词"></a>1.7 Mask掉 停用词</h3><p>句子中没有意义的占位符，例如“我是学生P”中的P是停止符，没有实际意义，需要将其mask掉。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_attn_pad_mask</span>(<span class="params">seq_q, seq_k</span>):</span><br><span class="line">    batch_size, len_q = seq_q.size()</span><br><span class="line">    batch_size, len_k = seq_k.size()</span><br><span class="line">    <span class="comment"># eq(zero)用于判断 seq_k 中哪些位置是填充符（通常填充符的值是 0），返回一个ByteTensor</span></span><br><span class="line">    pad_attn_mask = seq_k.data.eq(<span class="number">0</span>).unsqueeze(<span class="number">1</span>)  <span class="comment"># (N, 1, len_k)</span></span><br><span class="line">    <span class="keyword">return</span> pad_attn_mask.expand(batch_size, len_q, len_k)  <span class="comment"># (N, len_q, len_k)</span></span><br></pre></td></tr></table></figure><h3 id="1-8-EncoderLayer"><a href="#1-8-EncoderLayer" class="headerlink" title="1.8 EncoderLayer"></a>1.8 EncoderLayer</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">EncoderLayer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(EncoderLayer, self).__init__()</span><br><span class="line">        self.enc_self_attn = MultiHeadAttention() <span class="comment"># 多头自注意力</span></span><br><span class="line">        self.pos_ffn = PositionwiseFeedForward() <span class="comment"># 前馈神经网络</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, enc_inputs, enc_self_attn_mask</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;前向传播</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            enc_inputs: 编码器输入张量，形状为(batch_size, seq_len, d_model)</span></span><br><span class="line"><span class="string">            enc_self_attn_mask: 编码器自注意力掩码，形状为(batch_size, seq_len, seq_len)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            编码器输出张量，形状为(batch_size, seq_len, d_model)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask)</span><br><span class="line">        enc_outputs = self.pos_ffn(enc_outputs)</span><br><span class="line">        <span class="keyword">return</span> enc_outputs, attn</span><br></pre></td></tr></table></figure><h3 id="1-9-Encoder"><a href="#1-9-Encoder" class="headerlink" title="1.9 Encoder"></a>1.9 Encoder</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Encoder</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Encoder, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.src_emb = Embeddings(src_vocab_size, d_model)</span><br><span class="line">        self.pos_emb = PositionalEncoding(d_model)</span><br><span class="line">        self.layers = nn.ModuleList([EncoderLayer() <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n_layers)])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, enc_inputs</span>):</span><br><span class="line">        <span class="comment"># 1. 中文字索引进行Embedding，转换为512维的词向量</span></span><br><span class="line">        enc_outputs = self.src_emb(enc_inputs)</span><br><span class="line">        <span class="comment"># 2. 加上位置编码</span></span><br><span class="line">        enc_outputs = self.pos_emb(enc_outputs)</span><br><span class="line">        <span class="comment"># 3. mask掉padding部分</span></span><br><span class="line">        enc_self_attn_mask = get_attn_pad_mask(enc_inputs, enc_inputs)</span><br><span class="line">        enc_self_attns = []</span><br><span class="line">        <span class="comment"># 4. 通过6层EncoderLayer，上一层的输出作为下一层的输入</span></span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers:</span><br><span class="line">            enc_outputs, enc_self_attn = layer(enc_outputs, enc_self_attn_mask)</span><br><span class="line">            enc_self_attns.append(enc_self_attn)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> enc_outputs, enc_self_attns</span><br></pre></td></tr></table></figure><h2 id="2-Decoder"><a href="#2-Decoder" class="headerlink" title="2.Decoder"></a>2.Decoder</h2><p>Masked Multi-Head Attention：与MultiHead Attention类似，只是在计算Self Attention时，需要mask掉未来的信息</p><p>Multi-Head Attention：与Encoder中的MultiHead Attention相同</p><p>Decoder的输出预测：Decoder输出矩阵形状是[seq_len, word_dim]，经过nn.Linear全连接层，再通过softmax函数得到每个词的概率，然后选择概率最大的词作为预测结果。</p><h3 id="2-1-Decoder-Input-输入处理"><a href="#2-1-Decoder-Input-输入处理" class="headerlink" title="2.1 Decoder Input 输入处理"></a>2.1 Decoder Input 输入处理</h3><p>Decoder的输入是最后一个Encoder的输出，在训练时，同时输入目标句子的词向量，以便计算Loss。</p><p>“我是学生E”-&gt;“S I am a student”</p><ul><li>T0时刻：输入开始符“S”，输出预测的第一个词“I”</li><li>T1时刻：输入“S I”，输出预测的第二个词“am”</li><li>…</li></ul><p>输入使用上三角矩阵进行mask，避免Decoder看到未来的信息。</p><p><img src="https://source.cclmsy.cc/posts/notes/papers/transformer/Input_Mask.webp" alt="Input Mask"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_attn_subsequent_mask</span>(<span class="params">seq</span>): <span class="comment"># seq: [batch_size, tgt_len]</span></span><br><span class="line">    attn_shape = [seq.size(<span class="number">0</span>), seq.size(<span class="number">1</span>), seq.size(<span class="number">1</span>)]</span><br><span class="line">    subsequent_mask = np.triu(np.ones(attn_shape), k=<span class="number">1</span>) <span class="comment"># 返回上三角矩阵</span></span><br><span class="line">    subsequent_mask = torch.from_numpy(subsequent_mask).byte() <span class="comment"># 转换为ByteTensor</span></span><br><span class="line">    <span class="keyword">return</span> subsequent_mask</span><br></pre></td></tr></table></figure><h3 id="2-2-DecoderLayer"><a href="#2-2-DecoderLayer" class="headerlink" title="2.2 DecoderLayer"></a>2.2 DecoderLayer</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DecoderLayer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(DecoderLayer, self).__init__()</span><br><span class="line">        self.dec_self_attn = MultiHeadAttention()</span><br><span class="line">        self.dec_enc_attn = MultiHeadAttention() </span><br><span class="line">        self.pos_ffn = PositionwiseFeedForward()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, dec_inputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;前向传播</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            dec_inputs: 解码器输入张量，形状为(batch_size, tgt_len, d_model)</span></span><br><span class="line"><span class="string">            enc_outputs: 编码器输出张量，形状为(batch_size, seq_len, d_model)</span></span><br><span class="line"><span class="string">            dec_self_attn_mask: 解码器自注意力掩码，形状为(batch_size, tgt_len, tgt_len)</span></span><br><span class="line"><span class="string">            dec_enc_attn_mask: 解码器-编码器注意力掩码，形状为(batch_size, tgt_len, seq_len)</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            解码器输出张量，形状为(batch_size, tgt_len, d_model)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        dec_outputs, dec_self_attn = self.dec_self_attn(dec_inputs, dec_inputs, dec_inputs, dec_self_attn_mask)</span><br><span class="line">        dec_outputs, dec_enc_attn = self.dec_enc_attn(dec_outputs, enc_outputs, enc_outputs, dec_enc_attn_mask)</span><br><span class="line">        dec_outputs = self.pos_ffn(dec_outputs)</span><br><span class="line">        <span class="keyword">return</span> dec_outputs, dec_self_attn, dec_enc_attn</span><br></pre></td></tr></table></figure><h3 id="2-3-Decoder"><a href="#2-3-Decoder" class="headerlink" title="2.3 Decoder"></a>2.3 Decoder</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Decoder</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Decoder, self).__init__()</span><br><span class="line">        </span><br><span class="line">        self.tgt_emb = Embeddings(tgt_vocab_size, d_model)</span><br><span class="line">        self.pos_emb = PositionalEncoding(d_model)</span><br><span class="line">        self.layers = nn.ModuleList([DecoderLayer() <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n_layers)])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, dec_inputs, enc_inputs, enc_outputs</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;前向传播</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            dec_inputs: 解码器输入张量，形状为(batch_size, tgt_len)</span></span><br><span class="line"><span class="string">            enc_inputs: 编码器输入张量，形状为(batch_size, seq_len)</span></span><br><span class="line"><span class="string">            enc_outputs: 编码器输出张量，形状为(batch_size, seq_len, d_model)</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            解码器输出张量，形状为(batch_size, tgt_len, d_model)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 英文字索引进行Embedding，转换为512维的词向量，加上位置编码</span></span><br><span class="line">        dec_outputs = self.tgt_emb(dec_inputs)</span><br><span class="line">        dec_outputs = self.pos_emb(dec_outputs)</span><br><span class="line">        <span class="comment"># mask掉padding部分</span></span><br><span class="line">        dec_self_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs)</span><br><span class="line">        dec_self_attn_subsequent_mask = get_attn_subsequent_mask(dec_inputs)</span><br><span class="line">        dec_self_attn_mask = torch.gt((dec_self_attn_pad_mask + dec_self_attn_subsequent_mask), <span class="number">0</span>)</span><br><span class="line">        dec_enc_attn_mask = get_attn_pad_mask(dec_inputs, enc_inputs)</span><br><span class="line">        dec_self_attns, dec_enc_attns = [], []</span><br><span class="line">        <span class="comment"># 通过6层DecoderLayer，上一层的输出作为下一层的输入</span></span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers:</span><br><span class="line">            dec_outputs, dec_self_attn, dec_enc_attn = layer(dec_outputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask)</span><br><span class="line">            dec_self_attns.append(dec_self_attn)</span><br><span class="line">            dec_enc_attns.append(dec_enc_attn)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">return</span> dec_outputs, dec_self_attns, dec_enc_attns</span><br></pre></td></tr></table></figure><h2 id="3-Transformer代码实现"><a href="#3-Transformer代码实现" class="headerlink" title="3. Transformer代码实现"></a>3. Transformer代码实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Transformer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Transformer, self).__init__()</span><br><span class="line">        self.encoder = Encoder()</span><br><span class="line">        self.decoder = Decoder()</span><br><span class="line">        <span class="comment"># 解码器最后的分类器，分类器的输入d_model是解码层每个token的输出维度大小</span></span><br><span class="line">        <span class="comment"># 需要将其转为词表大小，再计算softmax；计算哪个词出现的概率最大</span></span><br><span class="line">        self.projection = nn.Linear(d_model, tgt_vocab_size, bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, enc_inputs, dec_inputs</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;前向传播</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            enc_inputs: 编码器输入张量，形状为(batch_size, seq_len)</span></span><br><span class="line"><span class="string">            dec_inputs: 解码器输入张量，形状为(batch_size, tgt_len)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            解码器输出张量，形状为(batch_size * tgt_len, tgt_vocab_size)</span></span><br><span class="line"><span class="string">            enc_self_attns: 编码器自注意力张量列表</span></span><br><span class="line"><span class="string">            dec_self_attns: 解码器自注意力张量列表</span></span><br><span class="line"><span class="string">            dec_enc_attns: 解码器-编码器注意力张量列表</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        </span><br><span class="line">        enc_outputs, enc_self_attns = self.encoder(enc_inputs)</span><br><span class="line"></span><br><span class="line">        dec_outputs, dec_self_attns, dec_enc_attns = self.decoder(dec_inputs, enc_inputs, enc_outputs)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># dec_logits : [batch_size x src_vocab_size x tgt_vocab_size]</span></span><br><span class="line">        dec_logits = self.projection(dec_outputs) </span><br><span class="line">        <span class="keyword">return</span> dec_logits.view(-<span class="number">1</span>, dec_logits.size(-<span class="number">1</span>)), enc_self_attns, dec_self_attns, dec_enc_attns</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="4-Transformer模型训练"><a href="#4-Transformer模型训练" class="headerlink" title="4. Transformer模型训练"></a>4. Transformer模型训练</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line">model = Transformer()</span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 词典</span></span><br><span class="line">word2idx = &#123;</span><br><span class="line">    <span class="string">&quot;S&quot;</span>: <span class="number">0</span>,</span><br><span class="line">    <span class="string">&quot;我&quot;</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="string">&quot;是&quot;</span>: <span class="number">2</span>,</span><br><span class="line">    <span class="string">&quot;学&quot;</span>: <span class="number">3</span>,</span><br><span class="line">    <span class="string">&quot;生&quot;</span>: <span class="number">4</span>,</span><br><span class="line">    <span class="string">&quot;I&quot;</span>: <span class="number">5</span>,</span><br><span class="line">    <span class="string">&quot;am&quot;</span>: <span class="number">6</span>,</span><br><span class="line">    <span class="string">&quot;a&quot;</span>: <span class="number">7</span>,</span><br><span class="line">    <span class="string">&quot;student&quot;</span>: <span class="number">8</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">idx2word = &#123;i: w <span class="keyword">for</span> w, i <span class="keyword">in</span> word2idx.items()&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入数据</span></span><br><span class="line">enc_inputs = torch.LongTensor([[word2idx[w] <span class="keyword">for</span> w <span class="keyword">in</span> [<span class="string">&quot;我&quot;</span>, <span class="string">&quot;是&quot;</span>, <span class="string">&quot;学&quot;</span>, <span class="string">&quot;生&quot;</span>, <span class="string">&quot;S&quot;</span>]]])</span><br><span class="line">dec_inputs = torch.LongTensor([[word2idx[w] <span class="keyword">for</span> w <span class="keyword">in</span> [<span class="string">&quot;S&quot;</span>, <span class="string">&quot;I&quot;</span>, <span class="string">&quot;am&quot;</span>, <span class="string">&quot;a&quot;</span>, <span class="string">&quot;student&quot;</span>]]])</span><br><span class="line">target_batch = torch.LongTensor([[word2idx[w] <span class="keyword">for</span> w <span class="keyword">in</span> [<span class="string">&quot;S&quot;</span>, <span class="string">&quot;I&quot;</span>, <span class="string">&quot;am&quot;</span>, <span class="string">&quot;a&quot;</span>, <span class="string">&quot;student&quot;</span>]]])</span><br><span class="line"><span class="built_in">print</span>(enc_inputs, dec_inputs, target_batch)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">20</span>):</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    outputs, enc_self_attns, dec_self_attns, dec_enc_attns = model(enc_inputs, dec_inputs)</span><br><span class="line">    loss = criterion(outputs, target_batch.view(-<span class="number">1</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Epoch:&#x27;</span>, <span class="string">&#x27;%04d&#x27;</span> % (epoch + <span class="number">1</span>), <span class="string">&#x27;cost =&#x27;</span>, <span class="string">&#x27;&#123;:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(loss))</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型预测</span></span><br><span class="line">predict, _, _, _ = model(enc_inputs, dec_inputs)</span><br><span class="line">predict = predict.data.<span class="built_in">max</span>(<span class="number">1</span>, keepdim=<span class="literal">True</span>)[<span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(enc_inputs, <span class="string">&#x27;-&gt;&#x27;</span>, [idx2word[n.item()] <span class="keyword">for</span> n <span class="keyword">in</span> predict.squeeze()])</span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>tensor([[1, 2, 3, 4, 0]]) tensor([[0, 5, 6, 7, 8]]) tensor([[0, 5, 6, 7, 8]])Epoch: 0001 cost = 2.244576Epoch: 0002 cost = 0.970345Epoch: 0003 cost = 2.741649Epoch: 0004 cost = 3.185768Epoch: 0005 cost = 4.521887Epoch: 0006 cost = 3.544580Epoch: 0007 cost = 3.160498Epoch: 0008 cost = 2.823286Epoch: 0009 cost = 0.625107Epoch: 0010 cost = 0.672708Epoch: 0011 cost = 0.561514Epoch: 0012 cost = 0.959138Epoch: 0013 cost = 0.673696Epoch: 0014 cost = 0.326180Epoch: 0015 cost = 0.268545Epoch: 0016 cost = 0.215698Epoch: 0017 cost = 0.168979Epoch: 0018 cost = 0.057510Epoch: 0019 cost = 0.087601Epoch: 0020 cost = 0.056923tensor([[1, 2, 3, 4, 0]]) -&gt; [&#39;S&#39;, &#39;I&#39;, &#39;am&#39;, &#39;a&#39;, &#39;student&#39;]</code></pre>]]></content>
    
    
    <summary type="html">实现与测试Transformer模型</summary>
    
    
    
    <category term="DL笔记" scheme="https://www.cclmsy.cc/categories/DL%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Pytorch" scheme="https://www.cclmsy.cc/tags/Pytorch/"/>
    
    <category term="论文复现" scheme="https://www.cclmsy.cc/tags/%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/"/>
    
    <category term="深度学习" scheme="https://www.cclmsy.cc/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>深度学习笔记4-循环神经网络RNN</title>
    <link href="https://www.cclmsy.cc/posts/deep_learning_4.html"/>
    <id>https://www.cclmsy.cc/posts/deep_learning_4.html</id>
    <published>2025-02-26T16:00:00.000Z</published>
    <updated>2025-08-12T00:19:26.816Z</updated>
    
    <content type="html"><![CDATA[<h2 id="4-1-循环神经网络"><a href="#4-1-循环神经网络" class="headerlink" title="4.1 循环神经网络"></a>4.1 循环神经网络</h2><h3 id="4-1-1-序列模型"><a href="#4-1-1-序列模型" class="headerlink" title="4.1.1 序列模型"></a>4.1.1 序列模型</h3><p>序列模型：自然语言、音频、视频等序列数据的模型</p><ul><li>应用：语音识别、情感分类、机器翻译等</li></ul><p>为什么不使用CNN？</p><ul><li>序列数据的前后之间具有强关联性</li><li>输入输出长度不固定</li></ul><h3 id="4-1-2-循环神经网络"><a href="#4-1-2-循环神经网络" class="headerlink" title="4.1.2 循环神经网络"></a>4.1.2 循环神经网络</h3><p>循环（递归）神经网络（Recurrent Neural Network，RNN）是神经网络的一种，将“状态”在自身网络中循环传递，可以接受时间序列结构输入</p><h4 id="4-1-2-1-RNN类型"><a href="#4-1-2-1-RNN类型" class="headerlink" title="4.1.2.1 RNN类型"></a>4.1.2.1 RNN类型</h4><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/RNN结构.png" alt="RNN结构"></p><ul><li>一对一：固定输入到固定输出，如图像分类</li><li>一对多：固定输入到序列输出，如图像的文字描述</li><li>多对一：序列输入到固定输出，如情感分类</li><li>（异步）多对多：序列输入到序列输出，如机器翻译，称为Encoder-Decoder（编码-解码）结构</li><li>同步多对多：同步序列到同步输出，如文本生成、视频帧分类</li></ul><h4 id="4-1-2-2-基础循环神经网络"><a href="#4-1-2-2-基础循环神经网络" class="headerlink" title="4.1.2.2 基础循环神经网络"></a>4.1.2.2 基础循环神经网络</h4><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/基础RNN结构.png" alt="基础RNN结构"></p><ul><li>$x_t$：t时刻的输入</li><li>$o_t$：t时刻的输出</li><li>$s_t$：t时刻的隐层输出</li><li>所有单元的参数$U, V, W$共享</li></ul><p>统一公式（$f$采用TanH/RuLU，$g$采用Softmax/Sigmoid）：</p><script type="math/tex; mode=display">\begin{split}    & s_0 = 0 \\\\    & s_t = f(Ux_t + Ws_{t-1}) \\\\    & o_t = g(Vs_t)\end{split}</script><p>输出的$o<em>t$受前面时刻的隐层$s</em>{t-1}$影响，即RNN具有记忆功能</p><h4 id="4-1-2-3-序列生成案例"><a href="#4-1-2-3-序列生成案例" class="headerlink" title="4.1.2.3 序列生成案例"></a>4.1.2.3 序列生成案例</h4><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/序列例子.png" alt="序列例子"></p><ul><li>输入到网络当中的是一个个的分词结果，每一个词的输入是一个时刻</li><li>每一个时刻有一个输出，表示最可能的下一个词</li></ul><h4 id="4-1-2-4-词的表示"><a href="#4-1-2-4-词的表示" class="headerlink" title="4.1.2.4 词的表示"></a>4.1.2.4 词的表示</h4><p>为了能够让网络理解输入，需要将词进行向量表示。</p><ul><li>建立一个包含所有序列词的词典，每个词在词典中有唯一编号</li><li>记词典大小为$N$，任意一个词都可以用一个$N$维的One-Hot向量表示</li><li>得到一个高维稀疏矩阵</li></ul><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/词向量表示.png" alt="词向量表示"></p><h4 id="4-1-2-4-输出的表示-Softmax"><a href="#4-1-2-4-输出的表示-Softmax" class="headerlink" title="4.1.2.4 输出的表示-Softmax"></a>4.1.2.4 输出的表示-Softmax</h4><p>RNN这种模型，每一个时刻的输出是下一个最可能的词，可以用概率表示，总长度为词的总数长度</p><ul><li>每个时刻的隐层输出$s_t$经过Softmax函数，得到概率分布</li></ul><h4 id="4-1-2-5-交叉熵损失"><a href="#4-1-2-5-交叉熵损失" class="headerlink" title="4.1.2.5 交叉熵损失"></a>4.1.2.5 交叉熵损失</h4><p>总损失定义：一整个序列（一个句子）作为一个训练实例，总误差是各个时刻误差的和</p><script type="math/tex; mode=display">\begin{split}    & E_t(y_t, \hat{y}_t) = -y_t \log(\hat{y}_t) \\\\    & E(y, \hat{y}) = \sum_t E_t(y_t, \hat{y}_t) = -\sum_t y_t \log(\hat{y}_t)\end{split}</script><ul><li>$y_t$：时刻t上正确的输出</li><li>$\hat{y}_t$：时刻t上预测的输出</li></ul><h4 id="4-1-2-6-时序反向传播算法（BPTT）"><a href="#4-1-2-6-时序反向传播算法（BPTT）" class="headerlink" title="4.1.2.6 时序反向传播算法（BPTT）"></a>4.1.2.6 时序反向传播算法（BPTT）</h4><p>Backpropagation Through Time，时序反向传播算法：对于RNN有一个时间概念，需要把梯度沿时间通道进行反向传播</p><p>需要更新的参数：$U, V, W, b_x, b_y$</p><ul><li>计算每个时间的梯度$dW_t$，相加作为每次$W$更新的梯度值</li><li>$s<em>t=tanh(Ux_t+Ws</em>{t-1}+b_x)$，$o_t=Softmax(Vs_t+b_y)$</li><li>利用链式法则，计算出每个时间下各参数的梯度</li></ul><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/RNN反向传播总结.png" alt="RNN反向传播总结"></p><h4 id="4-1-2-7-梯度消失与梯度爆炸"><a href="#4-1-2-7-梯度消失与梯度爆炸" class="headerlink" title="4.1.2.7 梯度消失与梯度爆炸"></a>4.1.2.7 梯度消失与梯度爆炸</h4><p>由于RNN中也存在链式求导法则，因此也会发生梯度消失与梯度爆炸的问题</p><h3 id="4-1-8-RNN改进"><a href="#4-1-8-RNN改进" class="headerlink" title="4.1.8 RNN改进"></a>4.1.8 RNN改进</h3><p>通过门控机制控制信息的流动</p><h4 id="4-1-8-1-门控循环单元GRU"><a href="#4-1-8-1-门控循环单元GRU" class="headerlink" title="4.1.8.1 门控循环单元GRU"></a>4.1.8.1 门控循环单元GRU</h4><p>Gated Recurrent Unit，门控循环单元</p><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/GRU单元.png" alt="GRU单元"></p><p>GRU增加了两个门，一个重置门（reset gate）和一个更新门（update gate）</p><ul><li>重置门：决定如何将新的输入和前一时刻的输出相结合</li><li>更新门：定义前面的记忆保存到当前时间的量</li><li>重置门1，更新门0，即为标准RNN模型</li></ul><p>GRU本质解决的问题：</p><ul><li>解决短期问题，每个递归单元能够自适应捕捉不同尺度的依赖关系</li><li>处理了隐层输出，$h<em>t=(1-z_t)*h</em>{t-1}+z_t*\tilde{h}_t$，解决了梯度消失问题</li></ul><h4 id="4-1-8-2-长短时记忆网络LSTM"><a href="#4-1-8-2-长短时记忆网络LSTM" class="headerlink" title="4.1.8.2 长短时记忆网络LSTM"></a>4.1.8.2 长短时记忆网络LSTM</h4><p>Long Short Term Memory，长短记忆网络</p><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/LSTM.png" alt="LSTM"></p><ul><li>$h_t$：当前cell的输出</li><li>$c_t$：隐层的记忆</li><li>三个门：遗忘门f，输入门u，输出门o</li></ul><p>作用：便于记忆长更长距离的状态</p><h2 id="4-2-词嵌入与NLP"><a href="#4-2-词嵌入与NLP" class="headerlink" title="4.2 词嵌入与NLP"></a>4.2 词嵌入与NLP</h2><h3 id="4-2-1-在RNN中使用one-hot表示的问题"><a href="#4-2-1-在RNN中使用one-hot表示的问题" class="headerlink" title="4.2.1 在RNN中使用one-hot表示的问题"></a>4.2.1 在RNN中使用one-hot表示的问题</h3><ul><li>假设有n个词，每个词的one-hot表示是n维的，整体大小为$n*n$，非常稀疏</li><li>无法表示词之间的相似性，例如Apple对Banana的相似性远高于Monkey</li></ul><h3 id="4-2-2-词嵌入（Word-Embedding）"><a href="#4-2-2-词嵌入（Word-Embedding）" class="headerlink" title="4.2.2 词嵌入（Word Embedding）"></a>4.2.2 词嵌入（Word Embedding）</h3><p>把一个维数为$N$的高维空间嵌入到一个维数低的多的连续向量空间中，每个单词或词组被映射为实数域上的向量，例如：</p><div class="table-container"><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">Man</th><th style="text-align:center">Woman</th><th style="text-align:center">King</th><th style="text-align:center">Queen</th><th style="text-align:center">Apple</th><th style="text-align:center">Banana</th></tr></thead><tbody><tr><td style="text-align:center">Gender</td><td style="text-align:center">1</td><td style="text-align:center">-1</td><td style="text-align:center">-0.95</td><td style="text-align:center">0.97</td><td style="text-align:center">0.01</td><td style="text-align:center">-0.02</td></tr><tr><td style="text-align:center">Royal</td><td style="text-align:center">0.01</td><td style="text-align:center">0.02</td><td style="text-align:center">0.98</td><td style="text-align:center">0.99</td><td style="text-align:center">-0.03</td><td style="text-align:center">0.04</td></tr><tr><td style="text-align:center">Age</td><td style="text-align:center">0.01</td><td style="text-align:center">0.02</td><td style="text-align:center">0.75</td><td style="text-align:center">0.69</td><td style="text-align:center">0.03</td><td style="text-align:center">-0.04</td></tr><tr><td style="text-align:center">Food</td><td style="text-align:center">0.01</td><td style="text-align:center">0.02</td><td style="text-align:center">-0.03</td><td style="text-align:center">0.04</td><td style="text-align:center">0.95</td><td style="text-align:center">0.97</td></tr></tbody></table></div><p>词嵌入的特点：能够体现词与词之间的关系</p><p>Man-Woman≈King-?(Queen!) </p><p>算法/工具：Skip-gram、CBOW、GenSim</p><h2 id="4-3-Seq2Seq与Attention机制"><a href="#4-3-Seq2Seq与Attention机制" class="headerlink" title="4.3 Seq2Seq与Attention机制"></a>4.3 Seq2Seq与Attention机制</h2><h3 id="4-3-1-Seq2Seq"><a href="#4-3-1-Seq2Seq" class="headerlink" title="4.3.1 Seq2Seq"></a>4.3.1 Seq2Seq</h3><p>Seq2Seq：Sequence to Sequence，由Google Brain团队和Yoshua Bengio 两个团队各自独立的提出来</p><h4 id="4-3-1-1-定义"><a href="#4-3-1-1-定义" class="headerlink" title="4.3.1.1 定义"></a>4.3.1.1 定义</h4><p>Seq2Seq模型是一个Encoder-Decoder结构的模型，输入是一个序列，输出也是一个序列</p><p>Encoder中将一个可变长度的信号序列变为固定长度的向量表达，<br>Decoder中将这个固定长度的向量表达变为可变长度的目标信号序列</p><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/seq2seq.png" alt="seq2seq"></p><ul><li>相当于把RNN模型的$s_0$输入变成一个Encoder</li></ul><h4 id="4-3-1-2-条件语言模型"><a href="#4-3-1-2-条件语言模型" class="headerlink" title="4.3.1.2 条件语言模型"></a>4.3.1.2 条件语言模型</h4><p>Encoder编码器的作用：</p><ul><li>将一个边长输入序列输出到一个编码状态$C$</li><li>解码器输出$y<em>t$的条件概率基于之前的输出序列$y_1y_2…y</em>{t-1}$和编码状态$C$</li><li>$argmaxP(y_1,y_2,…,y_T|x_1,x_2,…,x_T)$，给定输入的序列，最大化输出序列的概率</li></ul><p>根据最大似然估计，最大化输出序列的概率</p><script type="math/tex; mode=display">\begin{split}    & P(y_1,y_2,...,y_T|x_1,x_2,...,x_T) \\\\    & = \prod_{t=1}^T P(y_t|y_1,y_2,...,y_{t-1},x_1,x_2,...,x_T) \\\\    & = \prod_{t=1}^T P(y_t|y_1,y_2,...,y_{t-1},C)\end{split}</script><p>这个公式需要求出$P(y<em>1|C),P(y_2|y_1,C),…,P(y_T|y_1,y_2,…,y</em>{T-1},C)$，概率连乘极小，不利于存储，因此取对数进行计算，这样就将连乘式转换为累加式</p><script type="math/tex; mode=display">\log P(y_1,y_2,...,y_T|x_1,x_2,...,x_T) = \sum_{t=1}^T \log P(y_t|y_1,y_2,...,y_{t-1},C)</script><p>应用场景：机器翻译（NMT）</p><h3 id="4-3-2-Attention机制"><a href="#4-3-2-Attention机制" class="headerlink" title="4.3.2 Attention机制"></a>4.3.2 Attention机制</h3><h4 id="4-3-2-1-长句子问题"><a href="#4-3-2-1-长句子问题" class="headerlink" title="4.3.2.1 长句子问题"></a>4.3.2.1 长句子问题</h4><p>对于长句子，Seq2Seq模型的性能会下降，无法做到准确翻译。<br>句子非常长时，BLEU（Bilingual Evaluation Understudy）评价得分会很低</p><p>本质原因：在Encoder-Decoder结构中，Encoder把所有的输入序列都编码成一个统一的语义特征$C$再解码，$C$中必须包含原始序列中的所有信息，它的长度就成了模型性能的瓶颈。<br>当需要翻译的句子很长时，一个$C$可能存不下那么多信息，就会造成翻译精度的下降。</p><h4 id="4-3-2-2-Attention机制"><a href="#4-3-2-2-Attention机制" class="headerlink" title="4.3.2.2 Attention机制"></a>4.3.2.2 Attention机制</h4><ul><li>把Encoder的所有隐层输出$s_1,s_2,…,s_T$都保留下来，不再只保留最后一个隐层输出$C$</li><li>将这些信息提供给Decoder</li></ul><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/Attention机制.png" alt="Attention机制"></p><h4 id="4-3-2-3-Attention机制的计算"><a href="#4-3-2-3-Attention机制的计算" class="headerlink" title="4.3.2.3 Attention机制的计算"></a>4.3.2.3 Attention机制的计算</h4><p>假设Encoder的时刻为$t$，Decoder的时刻为$t’$</p><ol><li>$c<em>{t’}=\sum</em>{t=1}^T \alpha_{t’t}s_t$<ul><li>$\alpha_{t’t}$：参数，训练得到，表示Decoder的$t’$时刻对Encoder的$t$时刻的注意力权重</li><li>理解：Encoder的每个时刻加权求和，得到Decoder的$t’$时刻的输入</li><li>$c<em>4=\alpha</em>{41}s<em>1+\alpha</em>{42}s<em>2+…+\alpha</em>{4T}s_T$</li></ul></li><li>$\alpha_{t’t}$的$N$个权重系数的由来<ul><li>权重系数通过Softmax函数得到，$\alpha<em>{t’t}=\frac{exp(e</em>{t’t})}{\sum<em>{k=1}^T exp(e</em>{t’k})}$</li><li>$e<em>{t’t}=g(s</em>{t’-1},h_t)=v^T \tanh(W_ss+W_hh)$<ul><li>$e_{t’t}$：由t时刻的编码器隐层状态输出和t’-1时刻的解码器隐层状态输出计算得到的一个值</li><li>s为Decoder的隐层输出，h为Encoder的隐层输出</li><li>$W_s, W_h, v$：参数，训练得到</li></ul></li></ul></li></ol>]]></content>
    
    
    <summary type="html">把输出和新的输入混合来处理序列数据的网络</summary>
    
    
    
    <category term="DL笔记" scheme="https://www.cclmsy.cc/categories/DL%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="深度学习" scheme="https://www.cclmsy.cc/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Pytorch|Dataset&amp;DataLoader</title>
    <link href="https://www.cclmsy.cc/posts/dataset&amp;dataloader.html"/>
    <id>https://www.cclmsy.cc/posts/dataset&amp;dataloader.html</id>
    <published>2025-02-21T16:00:00.000Z</published>
    <updated>2025-07-18T12:42:11.061Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Dataset-数据集"><a href="#Dataset-数据集" class="headerlink" title="Dataset 数据集"></a>Dataset 数据集</h2><p>Pytorch中表示数据集的抽象类//</p><p>任何自定义的数据集都需要继承这个类并覆写相关方法</p><p>Dataset的描述：</p><blockquote><p>所有表示从键到数据样本的映射的数据集都应继承它。<br>所有子类都应覆写<strong>getitem</strong>，以支持获取给定键的数据样本。<br>子类还可以选择性地覆盖<strong>len</strong>，许多~torch.utils.data.Sampler类实现和~torch.utils.data.DataLoader类的默认选项都希望它返回数据集的大小。<br>子类也可以选择实现<strong>getitems</strong>，以加快成批样本的加载速度。<br>此方法接受批次样本的索引列表，并返回样本列表。</p></blockquote><p>假设需要加载的是当前目录下<code>images</code>文件夹中的42张png图片</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, path, processor=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Dataset类的初始化方法</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            path: 数据路径列表</span></span><br><span class="line"><span class="string">            processor: 数据预处理的函数，f:数据路径-&gt;目标数据</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.path = path</span><br><span class="line">        self.processor = processor</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;返回数据集的大小&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;根据索引返回处理后的数据&quot;&quot;&quot;</span></span><br><span class="line">        data_path = self.path[idx]</span><br><span class="line">        data = self.processor(data_path)</span><br><span class="line">        <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">processor</span>(<span class="params">data_path</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;预处理函数，这里&quot;&quot;&quot;</span></span><br><span class="line">    img = Image.<span class="built_in">open</span>(data_path).size</span><br><span class="line">    <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_images_path</span>(<span class="params">data_dir</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;获取data_dir目录下所有png图片的路径，不含子目录&quot;&quot;&quot;</span></span><br><span class="line">    images_path = [os.path.join(data_dir,image)</span><br><span class="line">                   <span class="keyword">for</span> image <span class="keyword">in</span> os.listdir(data_dir)</span><br><span class="line">                   <span class="keyword">if</span> image.endswith(<span class="string">&#x27;.png&#x27;</span>)]</span><br><span class="line">    <span class="keyword">return</span> images_path</span><br><span class="line"></span><br><span class="line">data_dir = <span class="string">&#x27;images&#x27;</span> <span class="comment"># 数据目录</span></span><br><span class="line">images_path = get_images_path(data_dir) <span class="comment"># 获取数据路径</span></span><br><span class="line">dataset = MyDataset(images_path, processor=processor) <span class="comment"># 创建数据集</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(dataset[<span class="number">0</span>]) <span class="comment"># 打印第一个数据</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(dataset)) <span class="comment"># 打印数据集大小</span></span><br></pre></td></tr></table></figure><pre><code>(367, 126)42</code></pre><h2 id="DataLoader-数据迭代器"><a href="#DataLoader-数据迭代器" class="headerlink" title="DataLoader 数据迭代器"></a>DataLoader 数据迭代器</h2><p>Pytorch加载和处理数据集的可迭代对象//</p><div class="table-container"><table><thead><tr><th style="text-align:center">参数</th><th style="text-align:center">Default</th><th style="text-align:center">说明</th></tr></thead><tbody><tr><td style="text-align:center">dataset</td><td style="text-align:center">必选</td><td style="text-align:center">用于加载数据的数据集<br>必须是torch.utils.data.Dataset的子类实例</td></tr><tr><td style="text-align:center">batch_size</td><td style="text-align:center">1</td><td style="text-align:center">每个batch的样本数</td></tr><tr><td style="text-align:center">shuffle</td><td style="text-align:center">False</td><td style="text-align:center">是否在每个epoch开始时打乱数据</td></tr><tr><td style="text-align:center">sampler</td><td style="text-align:center">None</td><td style="text-align:center">定义从数据集中提取样本的策略<br>如果指定这个参数，则忽略shuffle参数</td></tr><tr><td style="text-align:center">batch_sampler</td><td style="text-align:center">None</td><td style="text-align:center">与sampler类似，但返回的是一个batch的索引<br>不能与batch_size、shuffle、sampler同时使用</td></tr><tr><td style="text-align:center">num_workers</td><td style="text-align:center">0</td><td style="text-align:center">用于数据加载的子进程数</td></tr><tr><td style="text-align:center">collate_fn</td><td style="text-align:center">None</td><td style="text-align:center">将多个样本组合成一个mini-batch的函数</td></tr><tr><td style="text-align:center">drop_last</td><td style="text-align:center">False</td><td style="text-align:center">如果数据集大小不能被batch_size整除，是否丢弃最后一个不完整的batch</td></tr></tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line">data_loader = DataLoader(dataset,batch_size=<span class="number">5</span>,shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> data_loader:</span><br><span class="line">        <span class="built_in">print</span>(data)</span><br></pre></td></tr></table></figure><pre><code>[tensor([1866,  439,  970, 1378, 1416]), tensor([660, 159, 354, 554, 498])][tensor([2018, 1116, 1720,  812, 1500]), tensor([ 968,  556, 1302,  465, 1168])][tensor([2260, 1378, 1046, 1774, 1521]), tensor([648, 612, 514, 524, 375])][tensor([ 956,  962,  412, 1700,  978]), tensor([530, 542, 640, 904, 465])][tensor([1202, 1434, 1686, 1583, 3873]), tensor([1006,  598,  540,  844, 5041])][tensor([1402, 1824, 1580, 1422, 1638]), tensor([1414, 1454,  630,  570, 1044])][tensor([1944, 1390, 1408,  367, 1320]), tensor([592, 568, 864, 126, 364])][tensor([1983, 1844,  912, 1400, 1564]), tensor([482, 866, 501, 602, 514])][tensor([1144, 1594]), tensor([718, 494])]</code></pre>]]></content>
    
    
    <summary type="html">Pytorch中的数据处理类</summary>
    
    
    
    <category term="DL笔记" scheme="https://www.cclmsy.cc/categories/DL%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="Pytorch" scheme="https://www.cclmsy.cc/tags/Pytorch/"/>
    
  </entry>
  
  <entry>
    <title>DL笔记3|卷积神经网络CNN</title>
    <link href="https://www.cclmsy.cc/posts/deep_learning_3.html"/>
    <id>https://www.cclmsy.cc/posts/deep_learning_3.html</id>
    <published>2025-02-21T16:00:00.000Z</published>
    <updated>2025-08-12T00:19:29.652Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、卷积神经网络基础"><a href="#一、卷积神经网络基础" class="headerlink" title="一、卷积神经网络基础"></a>一、卷积神经网络基础</h2><h3 id="1-1-计算机视觉（Computer-Vision，CV）"><a href="#1-1-计算机视觉（Computer-Vision，CV）" class="headerlink" title="1.1 计算机视觉（Computer Vision，CV）"></a>1.1 计算机视觉（Computer Vision，CV）</h3><p>在CV领域，通常要做的是用机器程序代替人眼对目标图像进行识别、分析、处理。<br>深度学习在CV领域的应用非常广泛。</p><p>假设需要处理1024x1024的彩色图像，每个像素有RGB三个通道，共有1024x1024x3=3,145,728个特征。<br>假设第一个隐藏层有10个神经元，那么第一层的权重矩阵有3,145,728x10=31,457,280个参数，计算量极大，难以达到好的效果。</p><p>相比多层神经网络，卷积神经网络（CNN）更适合处理图像数据。</p><p>1962年Hubel和Wiesel通过对猫视觉皮层细胞的研究，提出了感受野的概念。<br>Fukushima基于感受野概念提出的神经认知机(Neocognitron)可以看作是卷积神经网络的第一个实现网络。</p><p>单个感受器与许多感觉神经纤维相联系，感觉信息是通过许多感受神经纤维发放总和性的空间与时间类型不同的冲动，相当于经过编码来传递。</p><h3 id="1-2-边缘检测"><a href="#1-2-边缘检测" class="headerlink" title="1.2 边缘检测"></a>1.2 边缘检测</h3><p>为了使用更少的参数检测出更多的信息，通常神经网络需要检测出物体最明显的垂直和水平边缘来区分物体。</p><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/边缘检测.png" alt="边缘检测"></p><p>随着深度学习的发展，我们需要检测更复杂的图像中的边缘。<br>与其使用由人手工设计的过滤器，还可以将过滤器中的数值作为参数，通过反向传播来学习得到。</p><p>算法可以根据实际数据来选择合适的检测目标，无论是检测水平边缘、垂直边缘还是其他角度的边缘，并习得图像的低层特征。</p><h2 id="二、卷积神经网络原理"><a href="#二、卷积神经网络原理" class="headerlink" title="二、卷积神经网络原理"></a>二、卷积神经网络原理</h2><h3 id="2-1-卷积神经网络的组成"><a href="#2-1-卷积神经网络的组成" class="headerlink" title="2.1 卷积神经网络的组成"></a>2.1 卷积神经网络的组成</h3><p>CNN由一个或多个卷积层（Convolutions）、池化层（Pooling）、全连接层（Full Connection）组成。</p><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/CNN结构.png" alt="CNN结构"></p><p>与其他深度学习结构相比，CNN在图像等方面能够给出更好的结果。<br>CNN也可以用反向传播算法进行训练。<br>与其他浅层或深层神经网络相比，CNN的参数更少，更容易训练。</p><h3 id="2-2-卷积层（Convolutions）"><a href="#2-2-卷积层（Convolutions）" class="headerlink" title="2.2 卷积层（Convolutions）"></a>2.2 卷积层（Convolutions）</h3><ul><li>目的：提取输入的不同特征<ul><li>某些卷积层可能只能提取一些低级特征，如线条、边缘等，更多层的网络能从低级特征中提取更高级更复杂的特征。</li></ul></li><li>参数<ul><li>size：卷积核（filter）大小，如3x3、5x5等</li><li>padding：0填充，保持输出和输入的大小一致，Valid/Same</li><li>stride：步长，卷积核每次移动的距离，通常为1</li></ul></li><li>计算公式<ul><li>四个超参数：Filter数量$K$、Filter大小$F$、步长$S$、0填充大小$P$</li><li>输入体积：$H_1 \times W_1 \times D_1$</li><li>输出体积：$H_2 \times W_2 \times D_2$<ul><li>$H_2 = \dfrac{H_1-F+2P}{S}+1$</li><li>$W_2 = \dfrac{W_1-F+2P}{S}+1$</li><li>$D_2 = K$</li></ul></li></ul></li></ul><h4 id="2-2-1-卷积运算"><a href="#2-2-1-卷积运算" class="headerlink" title="2.2.1 卷积运算"></a>2.2.1 卷积运算</h4><p>卷积运算（符号$\ast$）：将一个矩阵（卷积核）应用到另一个矩阵的所有位置，求出每个位置的点积，得到一个新的矩阵。</p><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/卷积运算.png" alt="卷积运算"></p><p>在这个6x6的矩阵中，左边一半都是1，右边一半都是0，中间是一条非常明显的垂直边缘。<br>经过卷积后，得到一个4x4的矩阵，中间的值非常大，其他值非常小，表明检测到了垂直边缘。</p><p>卷积运算的产生的问题：边缘像素的信息丢失、输出的图像尺寸变小</p><h4 id="2-2-2-padding-零填充"><a href="#2-2-2-padding-零填充" class="headerlink" title="2.2.2 padding-零填充"></a>2.2.2 padding-零填充</h4><p>在图片像素的最外层加上$P$层0，使得卷积后的输出和输入的尺寸一致。</p><p>0对最终结果不产生影响，避免图片增加噪声。</p><ul><li>Valid卷积：不填充，输出尺寸减小</li><li>Same卷积（一般采用）：填充0以维持输出尺寸与原图一致</li></ul><h4 id="2-2-3-size-卷积核大小"><a href="#2-2-3-size-卷积核大小" class="headerlink" title="2.2.3 size-卷积核大小"></a>2.2.3 size-卷积核大小</h4><p>卷积核大小$F$通常为3x3、5x5、7x7等奇数，保证能够确定一个中心点。</p><p>小卷积核可以保留更多的信息，大卷积核可以检测更大的特征。</p><h4 id="2-2-4-stride-步长"><a href="#2-2-4-stride-步长" class="headerlink" title="2.2.4 stride-步长"></a>2.2.4 stride-步长</h4><p>步长$S$通常为1，即卷积核每次移动一个像素。</p><p>步长为2时，卷积核每次移动两个像素，输出尺寸减小，示例如下：</p><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/2步长卷积.png" alt="2步长卷积"></p><h4 id="2-2-5-多通道卷积"><a href="#2-2-5-多通道卷积" class="headerlink" title="2.2.5 多通道卷积"></a>2.2.5 多通道卷积</h4><p>当输入有多个通道（Channel）时（例如图片可以有 RGB 三个通道），卷积核需要拥有相同的通道数</p><p>但最终的输出只有一个通道，其结果是多个通道的卷积结果的和。</p><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/多通道卷积.png" alt="多通道卷积"></p><h4 id="2-2-6-多卷积核"><a href="#2-2-6-多卷积核" class="headerlink" title="2.2.6 多卷积核"></a>2.2.6 多卷积核</h4><p>当有多个卷积核时，可以学习到多种不同的特征，输出结果的通道数等于卷积核的数量，多卷积核可以理解为多神经元</p><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/多卷积核.png" alt="多卷积核"></p><h4 id="2-2-7-卷积层的运算结果"><a href="#2-2-7-卷积层的运算结果" class="headerlink" title="2.2.7 卷积层的运算结果"></a>2.2.7 卷积层的运算结果</h4><script type="math/tex; mode=display">\begin{split}&Z^{[l]} = W^{[l]} \ast A^{[l-1]} + b^{[l]} \\\\&A^{[l]} = g(Z^{[l]}) \end{split}</script><h3 id="2-3-池化层（Pooling）"><a href="#2-3-池化层（Pooling）" class="headerlink" title="2.3 池化层（Pooling）"></a>2.3 池化层（Pooling）</h3><p>池化层主要对卷积层的输出进行下采样（Subsampling）处理，主要分为：</p><ul><li>最大池化（Max Pooling）：取池化窗口中的最大值</li><li>平均池化（Average Pooling）：取池化窗口中的平均值</li></ul><p>池化通常为2x2的filter，步长为2，即每次取2x2的窗口中的最大值或平均值。</p><p>特点：没有参数，不需要学习，只是对输入数据进行简单的处理。</p><p>目的：降低数据维度；减少计算量、提高计算速度；防止过拟合，提高了鲁棒性。</p><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/池化层.png" alt="池化层"></p><h3 id="2-4-全连接层（Fully-Connected）与CNN结构"><a href="#2-4-全连接层（Fully-Connected）与CNN结构" class="headerlink" title="2.4 全连接层（Fully Connected）与CNN结构"></a>2.4 全连接层（Fully Connected）与CNN结构</h3><p>全连接层即此前提到的多层神经网络，每个神经元与上一层的所有神经元相连。</p><p>卷积层+激活层+池化层可以看成是CNN的特征学习/特征提取层，学习到的特征（Feature Map）最终应用于模型任务（分类、回归）</p><ul><li>先对所有Feature Map进行扁平化（Flatten），即转化为一维向量</li><li>再连接到一个或多个全连接层，进行分类或回归任务</li></ul><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/CNN结构2.png" alt="CNN结构2"></p><h2 id="三、经典分类网络结构"><a href="#三、经典分类网络结构" class="headerlink" title="三、经典分类网络结构"></a>三、经典分类网络结构</h2><p>通常采用从现成的经典网络结构进行优化，而不是从头开始设计网络结构。</p><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/经典网络结构.png" alt="经典网络结构"></p><ul><li>NIN：引入了1x1卷积核</li><li>VGG：参数量巨大（1.4亿），19层网络</li><li>GoogleNet：500万参数，22层网络<ul><li>2014年比赛冠军的model，证明了用更多的卷积、更深的层次可以得到更好的结构</li><li>引入了Inception模块，多个不同大小的卷积核</li></ul></li></ul><h3 id="3-1-LeNet-5"><a href="#3-1-LeNet-5" class="headerlink" title="3.1 LeNet-5"></a>3.1 LeNet-5</h3><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/LeNet5.png" alt="LeNet-5"></p><p>LeNet-5最初的目的用于手写数字识别，当时使用的激活函数是Sigmoid和Tanh，还没有出现Relu</p><h4 id="参数形状"><a href="#参数形状" class="headerlink" title="参数形状"></a>参数形状</h4><div class="table-container"><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">Shape</th><th style="text-align:center">Size</th><th style="text-align:center">Params</th></tr></thead><tbody><tr><td style="text-align:center">Input</td><td style="text-align:center">(32, 32, 1)</td><td style="text-align:center">1024</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">Conv1(f=5,s=1)</td><td style="text-align:center">(28, 28, 6)</td><td style="text-align:center">4704</td><td style="text-align:center">5x5（卷积核大小）x3（通道数）x6（卷积核数量）+6（偏置）=456</td></tr><tr><td style="text-align:center">Pool1</td><td style="text-align:center">(14, 14, 6)</td><td style="text-align:center">1176</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">Conv2(f=5,s=1)</td><td style="text-align:center">(10, 10, 16)</td><td style="text-align:center">1600</td><td style="text-align:center">5x5x6x16+16=2416</td></tr><tr><td style="text-align:center">Pool2</td><td style="text-align:center">(5, 5, 16)</td><td style="text-align:center">400</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">FC3</td><td style="text-align:center">(120, 1)</td><td style="text-align:center">120</td><td style="text-align:center">400x120+120=48120</td></tr><tr><td style="text-align:center">FC4</td><td style="text-align:center">(84, 1)</td><td style="text-align:center">84</td><td style="text-align:center">120x84+84=10164</td></tr><tr><td style="text-align:center">Output:Sofmax</td><td style="text-align:center">(10, 1)</td><td style="text-align:center">10</td><td style="text-align:center">84x10+10=850</td></tr></tbody></table></div><ul><li>中间特征值的大小变化不宜过大，否则会导致信息丢失</li></ul><h3 id="3-2-AlexNet"><a href="#3-2-AlexNet" class="headerlink" title="3.2 AlexNet"></a>3.2 AlexNet</h3><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/AlexNet.png" alt="AlexNet"></p><ul><li>总参数量：6000万，8层神经网络，5个卷积层+3个全连接层</li><li>使用了非线性激活函数ReLU</li><li>使用Dropout防止过拟合，数据扩充</li><li>使用批标准化（Batch Normalization）加速训练</li></ul><h4 id="参数形状-1"><a href="#参数形状-1" class="headerlink" title="参数形状"></a>参数形状</h4><div class="table-container"><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">Shape</th><th style="text-align:center">Size</th><th style="text-align:center">Params</th></tr></thead><tbody><tr><td style="text-align:center">Input</td><td style="text-align:center">(227, 227, 3)</td><td style="text-align:center">154,587</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">Conv1(f=11,s=4)</td><td style="text-align:center">(55, 55, 96)</td><td style="text-align:center">290,400</td><td style="text-align:center">11×11×3×96 + 96 = 34,944</td></tr><tr><td style="text-align:center">Pool1</td><td style="text-align:center">(27, 27, 96)</td><td style="text-align:center">69,984</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">Conv2(f=5,s=1)</td><td style="text-align:center">(27, 27, 256)</td><td style="text-align:center">186,624</td><td style="text-align:center">5×5×48×256 + 256 = 307,456（group卷积）</td></tr><tr><td style="text-align:center">Pool2</td><td style="text-align:center">(13, 13, 256)</td><td style="text-align:center">43,264</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">Conv3(f=3,s=1)</td><td style="text-align:center">(13, 13, 384)</td><td style="text-align:center">64,896</td><td style="text-align:center">3×3×256×384 + 384 = 885,120</td></tr><tr><td style="text-align:center">Conv4(f=3,s=1)</td><td style="text-align:center">(13, 13, 384)</td><td style="text-align:center">64,896</td><td style="text-align:center">3×3×192×384 + 384 = 663,936（group卷积）</td></tr><tr><td style="text-align:center">Conv5(f=3,s=1)</td><td style="text-align:center">(13, 13, 256)</td><td style="text-align:center">43,264</td><td style="text-align:center">3×3×192×256 + 256 = 442,624（group卷积）</td></tr><tr><td style="text-align:center">Pool3</td><td style="text-align:center">(6, 6, 256)</td><td style="text-align:center">9,216</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">FC6</td><td style="text-align:center">(4096, 1)</td><td style="text-align:center">4096</td><td style="text-align:center">6×6×256×4096 + 4096 = 37,752,832</td></tr><tr><td style="text-align:center">FC7</td><td style="text-align:center">(4096, 1)</td><td style="text-align:center">4096</td><td style="text-align:center">4096×4096 + 4096 = 16,781,312</td></tr><tr><td style="text-align:center">FC8</td><td style="text-align:center">(1000, 1)</td><td style="text-align:center">1000</td><td style="text-align:center">4096×1000 + 1000 = 4,097,000</td></tr><tr><td style="text-align:center">Output:Softmax</td><td style="text-align:center">(1000, 1)</td><td style="text-align:center">1000</td><td style="text-align:center">0</td></tr></tbody></table></div><h3 id="3-3-Inception结构"><a href="#3-3-Inception结构" class="headerlink" title="3.3 Inception结构"></a>3.3 Inception结构</h3><p>Inception结构是GoogleNet中的一个模块，由多个不同大小的卷积核组成，可以提取不同尺度的特征。</p><h4 id="3-1-MLP卷积（1x1卷积）"><a href="#3-1-MLP卷积（1x1卷积）" class="headerlink" title="3.1 MLP卷积（1x1卷积）"></a>3.1 MLP卷积（1x1卷积）</h4><p>一种新的深度网络结构Network in Network（NIN）提出了MLP卷积取代传统线性卷积核</p><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/MLP卷积.png" alt="MLP卷积"></p><ul><li>1x1卷积核对每个像素点的所有通道进行了线性组合</li><li>激活函数将feature map由多通道的线性组合变为非线性组合（信息整合）</li><li>提高特征抽象能力（Multilayer Perceptron，缩写MLP，就是一个多层神经网络）</li><li>主要作用：调整通道数（升维降维）、减少参数量</li></ul><h4 id="3-2-Inception层"><a href="#3-2-Inception层" class="headerlink" title="3.2 Inception层"></a>3.2 Inception层</h4><p>也称盗梦空间结构）</p><p>目的：代替人决定，使用哪种卷积核，或是需要MaxPool层，由网络自己学习寻找合适的结构，节省计算</p><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/Inception层.png" alt="Inception层"></p><p>提供以下4种不同的卷积核：</p><ul><li>1x1卷积核（64个）</li><li>3x3卷积核（128个），padding=same</li><li>5x5卷积核（32个），padding=same</li><li>2x2最大池化（32个），stride=1，padding=same</li><li>最终结果为这4种卷积核的拼接，27x27x256，使用更少的参数达到和AlexNet相当的效果</li></ul><h4 id="3-3-Inception改进"><a href="#3-3-Inception改进" class="headerlink" title="3.3 Inception改进"></a>3.3 Inception改进</h4><p>上一节中，计算量还是太大，参数还是太多，需要进一步改进。以5x5卷积核为例：</p><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/Inception改进.png" alt="Inception改进"></p><ul><li>上面为原方法，参数：$5\times5\times192\times32=153600$</li><li>下面为改进方法，网络缩小后再扩大，参数：$1\times1\times192\times16+5\times5\times16\times32=15872$</li></ul><h4 id="3-4-GoogleNet"><a href="#3-4-GoogleNet" class="headerlink" title="3.4 GoogleNet"></a>3.4 GoogleNet</h4><p>Inception模块的堆叠，形成GoogleNet网络结构</p><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/Inception模块.png" alt="Inception模块"></p><p>详细结构略</p><h2 id="四、卷积神经网络实战技巧"><a href="#四、卷积神经网络实战技巧" class="headerlink" title="四、卷积神经网络实战技巧"></a>四、卷积神经网络实战技巧</h2><h3 id="4-1-学习特征可视化"><a href="#4-1-学习特征可视化" class="headerlink" title="4.1 学习特征可视化"></a>4.1 学习特征可视化</h3><p>可以将网络学习过程中产生的特征图可视化出来，并且对比原图来看看每一层都干了什么</p><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/LeNet5例.webp" alt="LeNet5例"></p><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/学习特征可视化.png" alt="学习特征可视化"></p><ul><li>Layer1,2：颜色、边缘等基本特征</li><li>Layer3：纹理、形状等中级特征</li><li>Layer4：稍复杂的特征，如狗的头部形状</li><li>Layer5：高级特征，如关键性区分特征</li></ul><h3 id="4-2-迁移学习（Transfer-Learning）"><a href="#4-2-迁移学习（Transfer-Learning）" class="headerlink" title="4.2 迁移学习（Transfer Learning）"></a>4.2 迁移学习（Transfer Learning）</h3><p>如果需要做一个具体场景的计算机视觉任务，可以使用已经训练好的模型，然后在此基础上进行微调。</p><h4 id="4-2-1-介绍"><a href="#4-2-1-介绍" class="headerlink" title="4.2.1 介绍"></a>4.2.1 介绍</h4><p>迁移学习就是利用数据、任务或模型之间的相似性（例如都是图像分类任务），将在旧的领域学习过或训练好的模型，应用于新的领域的过程。</p><p>从以下两个方面考虑训练模型的现实问题：</p><ol><li>数据集大小：如果新任务的数据集很小，迁移学习可以帮助提高模型的泛化能力<ul><li>如果有海量的数据集支持，可以不需要迁移学习，直接从海量数据中训练出一个学习到一个鲁棒性很强的模型</li><li>但是，通常情况下，需要研究的领域数据集非常有限，导致模型的泛化能力极差</li></ul></li><li>训练成本：从头开始训练一个CNN模型需要大量的时间和计算资源</li></ol><h4 id="4-2-2-微调（Fine-tuning）"><a href="#4-2-2-微调（Fine-tuning）" class="headerlink" title="4.2.2 微调（Fine-tuning）"></a>4.2.2 微调（Fine-tuning）</h4><p>在一个已经训练好的模型（Pre-trained Model）上进行针对性优化，以提升模型在特定任务上的性能。</p><p>假设有两个任务$A$和$B$。<br>任务$A$拥有海量数据，以$a$为条件区分1000个类别，已经训练好了一个模型。<br>目标任务为$B$，以$b$为条件区分250个类别，数据集很小。</p><p>步骤：</p><ol><li>在$A$模型的基础上，将最后一层的输出层替换为250个类别的输出层，保持前面的参数不变</li><li>根据数据量，决定是否冻结（Freeze）前面的层（权重不变），只训练最后若干层并更新参数<ul><li>数据越多，就保留越多的层，从后往前逐渐解冻</li><li>数据很少，只保留输出层，其他层全部解冻</li></ul></li><li>重新训练模型</li></ol>]]></content>
    
    
    <summary type="html">利用卷积运算处理图像数据提取特征的网络</summary>
    
    
    
    <category term="DL笔记" scheme="https://www.cclmsy.cc/categories/DL%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="深度学习" scheme="https://www.cclmsy.cc/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>DL笔记2|改善深层神经网络</title>
    <link href="https://www.cclmsy.cc/posts/deep_learning_2.html"/>
    <id>https://www.cclmsy.cc/posts/deep_learning_2.html</id>
    <published>2025-02-20T16:00:00.000Z</published>
    <updated>2025-07-20T12:54:24.596Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、神经网络实践相关"><a href="#一、神经网络实践相关" class="headerlink" title="一、神经网络实践相关"></a>一、神经网络实践相关</h2><h3 id="1-1-数据集划分"><a href="#1-1-数据集划分" class="headerlink" title="1.1 数据集划分"></a>1.1 数据集划分</h3><p>数据集：</p><ul><li>训练集（Training Set）：用于模型的训练过程</li><li>验证集（Validation Set）：利用验证集（又称为简单交叉验证集，hold-out cross validation set）进行交叉验证，选择出最好的模型</li><li>测试集（Test Set）：用于评估模型的能力</li></ul><p>数据集划分比例：</p><ul><li>小数据量（小于10万）比例：无验证集7:3，有验证集6:2:2</li><li>大数据量比例：98:1:1、99.5:0.25:0.25、99.5:0.4:0.1</li></ul><h3 id="1-2-偏差和方差"><a href="#1-2-偏差和方差" class="headerlink" title="1.2 偏差和方差"></a>1.2 偏差和方差</h3><p>“偏差-方差分解”（bias-variance decomposition）是解释学习算法泛化性能的一种重要工具。</p><p>泛化误差可分解为偏差、方差与噪声，泛化性能是由学习算法的能力、数据的充分性以及学习任务本身的难度所共同决定的。</p><ul><li>偏差（Bias）：度量学习算法的期望预测与真实结果的偏离程度，反映了<strong>模型本身的拟合能力</strong></li><li>方差（Variance）：度量同样大小的训练集的变动所导致的学习性能的变化，反映了<strong>模型的稳定性</strong></li><li>噪声：当前任务下任何学习算法所能达到的期望泛化误差的下界，反映了<strong>问题本身的难度</strong></li></ul><p>偏差、方差与数据集划分的关系及解决方法：</p><ol><li>训练集错误率小、测试集错误率大：高方差，可能出现了<strong>过拟合</strong><ul><li>增大数据集，使训练尽可能包含所有情况</li><li>寻找更合适的网络结构</li><li>正则化</li></ul></li><li>训练集错误率大、测试集错误率大：高偏差，可能出现了<strong>欠拟合</strong><ul><li>扩大网络规模，例如增加隐藏层或神经元数量</li><li>寻找更合适的网络结构，使用更大的网络</li><li>增加训练时间、迭代次数</li></ul></li><li>训练集错误率小、测试集错误率小：方差和偏差都小，模型效果较好</li></ol><h3 id="1-3-逻辑回归的L1和L2正则化"><a href="#1-3-逻辑回归的L1和L2正则化" class="headerlink" title="1.3 逻辑回归的L1和L2正则化"></a>1.3 逻辑回归的L1和L2正则化</h3><p><strong>正则化（Regularization）</strong>：在成本函数中加入一个正则化项（惩罚项），惩罚模型的复杂度，防止网络过拟合</p><p>逻辑回归中，参数$W$的数量由特征数决定，正则化如下：</p><ul><li>L1正则化：$J(W,b) = \dfrac{1}{m}\sum\limits_{i=1}^{m}L(\hat{y}^{(i)},y^{(i)})+\dfrac{\lambda}{2m}||W||_1$</li><li>L2正则化：$J(W,b) = \dfrac{1}{m}\sum\limits_{i=1}^{m}L(\hat{y}^{(i)},y^{(i)})+\dfrac{\lambda}{2m}||W||_2^2$<ul><li>L2范数：$\dfrac{\lambda}{2m}||W||<em>2^2 = \dfrac{\lambda}{2m}\sum\limits</em>{i=1}^{n}W_i^2=\dfrac{\lambda}{2m}W^TW$</li><li>解释：所有W参数的平方和</li></ul></li></ul><p>正则化因子$\lambda$：超参数，控制正则化项的权重，$\lambda$越大，正则化项的影响越大，模型越简单，防止过拟合。</p><p>L1正则化后，$W$的某些参数会变为0，使模型变稀疏，因此L2正则化更常用。</p><p>梯度下降的目的是减小损失函数$J(W,b)$值的大小。<br>在损失函数中增加了一项，导致$dW$增大，$W$减小的更多（多减去一项），因此L2范数也称为权重衰减（Weight Decay）。</p><h3 id="1-4-神经网络中的L2正则化、Frobenius范数"><a href="#1-4-神经网络中的L2正则化、Frobenius范数" class="headerlink" title="1.4 神经网络中的L2正则化、Frobenius范数"></a>1.4 神经网络中的L2正则化、Frobenius范数</h3><p>对每一层的权重矩阵$W^{[l]}$进行正则化，每一层都有若干个权重，可以理解为矩阵</p><script type="math/tex; mode=display">J(W^{[1]},b^{[1]},...,W^{[L]},b^{[L]}) = \dfrac{1}{m}\sum\limits_{i=1}^{m}L(\hat{y}^{(i)},y^{(i)})+\dfrac{\lambda}{2m}\sum\limits_{l=1}^{L}||W^{[l]}||_F^2</script><p>其中，$||W^{[l]}||_F^2$为Frobenius范数，表示矩阵的所有元素的平方和。</p><h3 id="1-5-正则化减少过拟合的原理"><a href="#1-5-正则化减少过拟合的原理" class="headerlink" title="1.5 正则化减少过拟合的原理"></a>1.5 正则化减少过拟合的原理</h3><p>正则化因子设置的足够大的情况下，为了使损失函数最小化，权重矩阵会趋向于0，削弱隐藏层影响，使得模型变得简单。</p><p>选取一个适合的$\lambda$，可以使得模型的复杂度适中，防止过拟合。</p><h3 id="1-6-Dropout正则化"><a href="#1-6-Dropout正则化" class="headerlink" title="1.6 Dropout正则化"></a>1.6 Dropout正则化</h3><p>Dropout正则化：在训练过程中，随机关闭一些神经元，减少神经元之间的依赖关系，防止过拟合。</p><p>Inverted Dropout：在训练过程中，对每一层的神经元，以概率$keep_prob$保留。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">keep_prob = <span class="number">0.8</span>  <span class="comment"># 保留概率</span></span><br><span class="line">dl = np.random.rand(A.shape[<span class="number">0</span>], A.shape[<span class="number">1</span>]) &lt; keep_prob  </span><br><span class="line">A = np.multiply(A, dl)  <span class="comment"># 保留神经元</span></span><br><span class="line"></span><br><span class="line"> 部分神经元被关闭，期望值预计下降为原来的$keep_prob$，需要缩放激活值保持期望值不变</span><br><span class="line">A = A / keep_prob </span><br></pre></td></tr></table></figure><p>加入了Droupout后，输入的特征都存在被随机清除的可能，所以该神经元不会再特别依赖于任何一个输入特征。<br>通过传播过程，Dropout将产生和L2正则化相同的收缩权重的效果。</p><p>对于神经元较多的层，设置较小的keep_prob，对于神经元较少的层，设置keep_prob=1。</p><p>在CV领域，图像具有更多的特征，Dropout是一种非常有效的正则化方法。</p><p>缺点：</p><ol><li>因为每次会随机消除一部分神经元，成本函数无法被明确定义</li><li>参数无法确定具体是哪些，在反向传播的时候带来计算上的麻烦，无法保证当前网络是否损失函数下降的</li></ol><h3 id="1-7-其他正则化方法"><a href="#1-7-其他正则化方法" class="headerlink" title="1.7 其他正则化方法"></a>1.7 其他正则化方法</h3><h4 id="早停止法（Early-Stopping）"><a href="#早停止法（Early-Stopping）" class="headerlink" title="早停止法（Early Stopping）"></a>早停止法（Early Stopping）</h4><p>如果训练迭代的次数过高，会发生过拟合，损失函数图像如下：</p><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/早停止法.png" alt="早停止法"></p><p>早停止法：在测试集上的损失减少到一定程度后，停止训练，防止过拟合。</p><p>这种方法治标不治本，还是需要从根本上解决数据或模型的问题。</p><h4 id="数据增强（Data-Augmentation）"><a href="#数据增强（Data-Augmentation）" class="headerlink" title="数据增强（Data Augmentation）"></a>数据增强（Data Augmentation）</h4><p>算法在学习区分两种类别时，可能会寻找到一个最明显的特征。</p><p>例如在区分两种不同型号的车时，如果训练集中，型号1的车都朝左，型号2的车都朝右，那么模型可能会认为车的朝向是区分两种车的最重要特征。<br>在测试集中，如果出现了朝右的型号1车，模型可能认为是型号2车。<br>因此，需要减少数据集中不相关的特征的数量。</p><p>数据增强：通过对训练集进行一系列的随机变换（如剪切、旋转、翻转、缩放等），增加训练集的样本数量，提高模型的泛化能力。</p><p>在上面的例子中，可以通过水平翻转图像，以防止模型学习到不相关的模式。</p><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/数据增强.png" alt="数据增强"></p><ul><li>离线增强：预先进行所有的必要转换，从根本上增大数据集规模（如水平翻转后，保存为新的图像，数据集增大为原来的两倍）</li><li>在线增强：在训练过程中，对即将输入模型的小批量数据进行相应变换，同一张图每次训练被随机执行一些变化操作，相当于不同数据集</li></ul><p>数据增强的效果如下</p><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/数据增强的效果.png" alt="数据增强的效果"></p><h3 id="1-8-正则化输入"><a href="#1-8-正则化输入" class="headerlink" title="1.8 正则化输入"></a>1.8 正则化输入</h3><p>对于输入数据进行正则化处理，使数据都服从同一分布，能够缓解梯度消失和梯度爆炸问题，并且加速算法的收敛。</p><ul><li>正则化公式：$X = \dfrac{X-\mu}{\sigma}$，其中$\mu$为均值，$\sigma$为标准差</li></ul><h3 id="1-9-梯度消失与梯度爆炸"><a href="#1-9-梯度消失与梯度爆炸" class="headerlink" title="1.9 梯度消失与梯度爆炸"></a>1.9 梯度消失与梯度爆炸</h3><p>由于链式法则是一个连乘的过程，当层数越深时，梯度以指数速度增长传播。</p><ul><li>梯度消失：梯度小于1，多次连乘后，梯度趋近于0，导致参数几乎不更新、模型难收敛</li><li>梯度爆炸：梯度大于1，多次连乘后，梯度趋近于无穷，导致参数更新过大甚至溢出</li></ul><p>局部最优解：损失函数可能存在鞍点/局部最小值</p><ul><li>较大的神经网络，局部最优解的可能性较小</li><li>鞍点附近的平稳段会使得学习非常缓慢，需要优化算法加速学习</li></ul><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/局部最优解.gif" alt="局部最优解"></p><p>解决方法：</p><ol><li>初始化参数策略：将权重初始化为较小的随机数</li><li>批梯度下降、Mini-batch梯度下降、随机梯度下降</li><li>梯度下降算法内部优化：动量梯度下降、RMSProp算法、Adam算法</li><li>学习率衰减</li><li>标准化输入</li></ol><h3 id="1-10-权重初始化"><a href="#1-10-权重初始化" class="headerlink" title="1.10 权重初始化"></a>1.10 权重初始化</h3><p>为了避免对称性，权重初始化不能全为0，通常使用较小的随机数进行初始化。</p><p>在逻辑回归的笔记中，权重初始化为<code>np.random.randn(k, n) * 0.01</code>。</p><p>Xavier初始化：$w^{[l]} = np.random.randn(k, n) \times \sqrt{\dfrac{1}{n^{[l-1]}}}$，其中$n^{[l-1]}$为上一层的神经元数量。</p><p>如果使用ReLU激活函数，权重初始化为 $w^{[l]} = np.random.randn(k, n) \times \sqrt{\dfrac{2}{n^{[l-1]}}}$。</p><h2 id="二、优化算法"><a href="#二、优化算法" class="headerlink" title="二、优化算法"></a>二、优化算法</h2><h3 id="2-1-批梯度下降、Mini-batch梯度下降、随机梯度下降"><a href="#2-1-批梯度下降、Mini-batch梯度下降、随机梯度下降" class="headerlink" title="2.1 批梯度下降、Mini-batch梯度下降、随机梯度下降"></a>2.1 批梯度下降、Mini-batch梯度下降、随机梯度下降</h3><p>批梯度下降（Batch Gradient Descent）：同时处理整个训练集</p><ul><li>在更新参数前，必须先处理整个训练参数集，才能进行一步梯度下降</li><li>如果训练集很大，计算量会很大，训练速度很慢</li><li>噪声低，代价函数值平滑减小</li><li>训练样本的大小较小（小于2048）时，选择Batch梯度下降</li></ul><p>Mini-batch梯度下降：将训练集分为多个固定大小的批次，每次只处理一个批次的数据</p><ul><li>训练样本的大小较大时，选择Mini-batch梯度下降，通常为64、128、256、512等</li></ul><p>随机梯度下降（Stochastic Gradient Descent, SGD）：mini-batch大小为1，每次只处理一个样本</p><ul><li>训练速度快，但丢失了向量化编程的优势</li><li>代价函数值波动大，噪声大，总体向全局最小值靠近，但难以收敛，容易在鞍点震荡</li></ul><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/梯度下降代价函数值变化趋势.png" alt="梯度下降代价函数值变化趋势"></p><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/梯度下降代价函数值变化趋势2.png" alt="梯度下降代价函数值变化趋势2"></p><h3 id="2-2-指数加权平均"><a href="#2-2-指数加权平均" class="headerlink" title="2.2 指数加权平均"></a>2.2 指数加权平均</h3><p>指数加权平均（Exponentially Weight Average）是一种常用的序列数据处理方式，通常用在序列场景，如金融序列分析、温度变化序列分析。</p><script type="math/tex; mode=display">S_t = \begin{cases}x_t &, t=1 \\\\ \beta S_{t-1}+(1-\beta)x_t &, t>1\end{cases}</script><p>理解：上一结果的权重为$\beta$，当前数据的权重为$1-\beta$。</p><p>下图，黄色$\beta=0.5$，红色$\beta=0.9$，绿色$\beta=0.98$</p><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/指数加权平均.png" alt="指数加权平均"></p><h3 id="2-3-动量梯度下降"><a href="#2-3-动量梯度下降" class="headerlink" title="2.3 动量梯度下降"></a>2.3 动量梯度下降</h3><p>动量梯度下降（Momentum Gradient Descent）：利用梯度的指数加权平均来更新参数</p><script type="math/tex; mode=display">\begin{split}&S_{dW} = \beta S_{dW}+(1-\beta)dW \\\\ &S_{db} = \beta S_{db}+(1-\beta)db \\\\ &W = W-\alpha S_{dW} \\\\ &b = b-\alpha S_{db}\end{split}</script><p>利用累加的梯度值，减少梯度下降的震荡，加速收敛</p><ul><li>前后梯度方向不一致时，梯度值减小，减少震荡</li><li>前后梯度方向一致时，梯度值增大，加速收敛</li></ul><h3 id="2-2-5-RMSProp算法"><a href="#2-2-5-RMSProp算法" class="headerlink" title="2.2.5 RMSProp算法"></a>2.2.5 RMSProp算法</h3><p>RMSProp算法（Root Mean Square Propagation）：再对梯度进行指数加权平均的基础上，引入平方和平方根</p><script type="math/tex; mode=display">\begin{split}&S_{dW} = \beta S_{dW}+(1-\beta)dW^2 \\\\ &S_{db} = \beta S_{db}+(1-\beta)db^2 \\\\ &W = W-\alpha \dfrac{dW}{\sqrt{S_{dW}+\epsilon}} \\\\ &b = b-\alpha \dfrac{db}{\sqrt{S_{db}+\epsilon}}\end{split}</script><p>其中，$\epsilon$是一个很小的数，避免分母过小导致数值不稳定。</p><p>RMSProp 有助于减少抵达最小值路径上的摆动，并允许使用一个更大的学习率$\alpha$，加快算法学习速度。</p><h3 id="2-2-6-Adam算法"><a href="#2-2-6-Adam算法" class="headerlink" title="2.2.6 Adam算法"></a>2.2.6 Adam算法</h3><p>Adam算法（Adaptive Moment Estimation，自适应矩估计）：结合了Momentum和RMSProp算法，同时考虑梯度的一阶矩估计和二阶矩估计</p><p>假设用一个mini-batch计算$dW$和$db$，第$t$次迭代时，计算动量梯度结果：</p><script type="math/tex; mode=display">\begin{split}&V_{dW} = \beta_1 V_{dW}+(1-\beta_1)dW \\\\ &V_{db} = \beta_1 V_{db}+(1-\beta_1)db \\\\ &V_{dW}^{corrected} = \dfrac{V_{dW}}{1-\beta_1^t} \end{split}</script><p>计算RMSProp结果：</p><script type="math/tex; mode=display">\begin{split}&S_{dW} = \beta_2 S_{dW}+(1-\beta_2)dW^2 \\\\ &S_{db} = \beta_2 S_{db}+(1-\beta_2)db^2 \\\\ &S_{dW}^{corrected} = \dfrac{S_{dW}}{1-\beta_2^t}\end{split}</script><p>计算移动平均数时，使用系数$\dfrac{1}{1-\beta_1^t}$进行修正。<br>例如$m_0=0,m_1=0.9m_0+0.1m_1$，导致$m_1$的值过小，修正后恰好为$m_1$的值。<br>随着迭代次数增加，修正系数趋近于1，保证了移动平均数的准确性。</p><p>Adam算法更新参数：</p><script type="math/tex; mode=display">\begin{split}&W = W-\alpha \dfrac{V_{dW}^{corrected}}{\sqrt{S_{dW}^{corrected}}+\epsilon} \\\\ &b = b-\alpha \dfrac{V_{db}^{corrected}}{\sqrt{S_{db}^{corrected}}+\epsilon}\end{split}</script><h3 id="2-2-7-学习率衰减"><a href="#2-2-7-学习率衰减" class="headerlink" title="2.2.7 学习率衰减"></a>2.2.7 学习率衰减</h3><p>如果随着时间慢慢减少学习率$\alpha$的大小，在初期$\alpha$较大时，下降的步长较大，能以较快的速度进行梯度下降；而后期逐步减小$\alpha$的值，即减小步长，有助于算法的收敛，更容易接近最优解。</p><p>最常用的学习率衰减方法：$\alpha = \dfrac{1}{1+decay_ rate \times epoch_ num} \times \alpha_0$</p><ul><li>$\alpha_0$：初始学习率</li><li>$decay_ rate$：衰减率，超参数</li><li>$epoch_ num$：迭代次数</li></ul><p>一种指数衰减学习率：$\alpha = 0.95^{epoch_ num} \times \alpha_0$</p><h2 id="三、超参数调试、Batch正则化和编程框架"><a href="#三、超参数调试、Batch正则化和编程框架" class="headerlink" title="三、超参数调试、Batch正则化和编程框架"></a>三、超参数调试、Batch正则化和编程框架</h2><h3 id="3-1-神经网络调优"><a href="#3-1-神经网络调优" class="headerlink" title="3.1 神经网络调优"></a>3.1 神经网络调优</h3><p>算法层面：</p><ul><li>学习率$\alpha$</li><li>$\beta_1,\beta_2,\epsilon$：Adam算法的超参数，常用值$\beta_1=0.9,\beta_2=0.999,\epsilon=10^{-8}$</li><li>正则化参数$\lambda$</li></ul><p>模型层面：</p><ul><li>hidden units：隐藏层神经元数</li><li>layers：隐藏层层数</li></ul><p>调参技巧</p><ul><li>网格搜索：遍历所有可能的参数组合，测试每一组的效果，选择效果最好的参数组合。</li><li>尽量让每一组差别明显，避免重复测试</li><li>合理的参数设置：为超参数选择合适的范围<ul><li>学习率$\alpha$：通常设置为0.0001、0.001、0.01、0.1等</li><li>动量梯度因子$\beta$: 通常设置为0.999、0.9995、0.9999等，尽可能接近1（指数增加效应）</li></ul></li></ul><p>问题：调参过程麻烦、训练时间长</p><h3 id="2-4-2-批标准化（批标准化）"><a href="#2-4-2-批标准化（批标准化）" class="headerlink" title="2.4.2 批标准化（批标准化）"></a>2.4.2 批标准化（批标准化）</h3><p>论文地址：<a href="https://arxiv.org/abs/1502.03167">批标准化: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a></p><blockquote><p>训练深度神经网络很复杂，因为在训练期间每层输入的分布发生变化，因为前一层的参数发生了变化。<br>这通过要求较低的学习率和仔细的参数初始化来减慢训练速度，并且使得训练具有饱和非线性的模型变得非常困难。<br>我们将这种现象称为<strong>内部协变量偏移</strong>，并通过<strong>标准化层</strong>输入来解决问题。<br>我们的方法的优势在于使标准化成为模型体系结构的一部分，并为每个培训小批量执行标准化。<br>批标准化允许我们使用更高的学习率并且不太关心初始化。<br>它还可以充当调节器，在某些情况下可以消除对Dropout的需求。<br>应用于最先进的图像分类模型，批量标准化实现了相同的精度，培训步骤减少了14倍，并且显着地超过了原始模型。<br>使用批量标准化网络的集合，我们改进了ImageNet分类的最佳发布结果：达到4.9％的前5个验证错误（和4.8％的测试错误），超出了人类评估者的准确性。</p></blockquote><p>批标准化：在神经网络的每一层的<strong>激活函数之前</strong>，对每一层的<strong>输入</strong>进行标准化处理，使得每一层的输入数据服从均值为0、方差为1的正态分布。</p><p>批标准化公式：</p><script type="math/tex; mode=display">\begin{split}&\mu = \dfrac{1}{m}\sum\limits_{i=1}^{m}Z^{(i)} \\\\ &\sigma^2 = \dfrac{1}{m}\sum\limits_{i=1}^{m}(Z^{(i)}-\mu)^2 \\\\ &Z_{norm}^{(i)} = \dfrac{Z^{(i)}-\mu}{\sqrt{\sigma^2+\epsilon}}\end{split}</script><p>其中，$\mu$为均值，$\sigma^2$为方差，$\epsilon$为一个很小的数，避免分母为0。</p><p>如果各隐藏层的输入均值在靠近0的区域，即处于激活函数的线性区域，不利于训练非线性神经网络，从而得到效果较差的模型。<br>因此添加两个可学习的参数$\gamma$和$\beta$，对标准化后的数据进行缩放和平移。</p><script type="math/tex; mode=display">\tilde{Z}^{(i)} = \gamma Z_{norm}^{(i)}+\beta</script><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/批标准化过程.png" alt="批标准化过程"></p><p>批标准化优化训练过程的原理：</p><p>数据的分布会随着不同数据集改变。<br>网络的参数会因训练集数据分布的变化而变化；测试的数据分布与训练集的数据分布不同，也会导致准确性下降。</p><p>批标准化的作用就是减小了数据分布的变化带来的影响，让模型更健壮，鲁棒性更强。<br>即使输入的值改变，由于批标准化的作用，均值和方差的变化会被消除，后续的学习更加容易。<br>批标准化减少了各层W和b之间的耦合性，让各层更加独立，实现自我训练学习的效果</p><p>批标准化也起到微弱的正则化效果，但是不能将批标准化作为正则化的手段，而是当作加速学习的方式。<br>批标准化 主要解决的还是反向传播过程中的梯度问题（梯度消失和爆炸）。</p>]]></content>
    
    
    <summary type="html">超参数调试、正则化以及优化</summary>
    
    
    
    <category term="DL笔记" scheme="https://www.cclmsy.cc/categories/DL%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="深度学习" scheme="https://www.cclmsy.cc/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>DL笔记1|神经网络和深度学习</title>
    <link href="https://www.cclmsy.cc/posts/deep_learning_1.html"/>
    <id>https://www.cclmsy.cc/posts/deep_learning_1.html</id>
    <published>2025-02-19T16:00:00.000Z</published>
    <updated>2025-07-20T12:54:25.950Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、深度学习概论"><a href="#一、深度学习概论" class="headerlink" title="一、深度学习概论"></a>一、深度学习概论</h2><h3 id="1-1-什么是深度学习"><a href="#1-1-什么是深度学习" class="headerlink" title="1.1 什么是深度学习"></a>1.1 什么是深度学习</h3><p>简单来说，深度学习（Deep Learning）就是更复杂的神经网络（Neural Network）</p><p>人工神经网络包含：输入层、隐藏层、输出层，每层包含多个神经元，每个神经元包含激活函数</p><p>神经网络需要从大量的数据中学习，学习的过程就是调整网络中的参数，使得网络的输出结果与实际结果尽可能接近。</p><p>学习的目标是，建立起一个特殊的函数，输入一些数据就能输出想要的结果。</p><h3 id="1-2-深度学习的应用"><a href="#1-2-深度学习的应用" class="headerlink" title="1.2 深度学习的应用"></a>1.2 深度学习的应用</h3><p>监督学习（Supervised Learning）与无监督学习本质区别就是：训练样本是否已知的输出y</p><p>不同的任务通常交给不同的神经网络：</p><ul><li>分类/回归任务：神经网络（Neural Network, NN）</li><li>图像识别任务：卷积神经网络（Convolutional Neural Network, CNN）</li><li>文本/语音等序列任务：循环神经网络（Recurrent Neural Network, RNN）</li><li>生成任务：生成对抗网络（Generative Adversarial Network, GAN）</li></ul><p>机器学习应用于结构化数据（Structured Data）和非结构化数据（Unstructured Data）</p><ul><li>结构化数据：数据的数据库，意味着每个特征都有清晰的定义，比较容易理解。</li><li>非结构化数据：通常指的是比较抽象的数据，比如音频、原始音频、图像、文本。</li></ul><p>正是因为神经网络，计算机现在能更好地解释非结构化数据，甚至在某些方面优于人类。例如，语音识别，图像识别，自然语音处理等。</p><h3 id="1-3-深度学习的优点"><a href="#1-3-深度学习的优点" class="headerlink" title="1.3 深度学习的优点"></a>1.3 深度学习的优点</h3><p>深度学习兴起的原因：数据（Data）、计算（Computation）、算法（Algorithm）</p><p>深度学习的优点：</p><ul><li>不需要人工处理设计特征，只需通过神经网络输出结果</li><li>更适用于难提取特征的任务：图像、语音、自然语言处理</li><li>能够应对处理更大规模数据</li></ul><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/data_performance.jpeg" alt="性能随数据量增大的变化"></p><h2 id="二、神经网络基础"><a href="#二、神经网络基础" class="headerlink" title="二、神经网络基础"></a>二、神经网络基础</h2><h3 id="2-1-逻辑回归（Logistic-Regression-LR）"><a href="#2-1-逻辑回归（Logistic-Regression-LR）" class="headerlink" title="2.1 逻辑回归（Logistic Regression, LR）"></a>2.1 逻辑回归（Logistic Regression, LR）</h3><p>逻辑回归是一种用于解决二分类问题的分类算法，给定一个输入x，输出y=1的预测概率 $\hat{y}=P(y=1|x)$</p><p>记输入层特征数$n$，参数：</p><ul><li>输入$x \in R^{n}$，x是一个n维的特征向量</li><li>权重$w \in R^{n}$，w是一个n维的权重向量</li><li>标签$y \in {0,1}$，y是一个二分类标签</li><li>偏置$b \in R$，b是一个标量</li><li>输出$\hat{y} = \sigma(w^{T}x+b)=\sigma(w_1x_1+w_2x_2+…+w_nx_n+b)$<ul><li>激活函数：Sigmoid函数：$\sigma(t)=\dfrac{1}{1+e^{-t}}$</li><li>t非常大时，s接近1；t非常小时，s接近0；t=0时，s等于0.5</li></ul></li></ul><h3 id="2-2-与梯度下降算法（Gradient-Descent）"><a href="#2-2-与梯度下降算法（Gradient-Descent）" class="headerlink" title="2.2 与梯度下降算法（Gradient Descent）"></a>2.2 与梯度下降算法（Gradient Descent）</h3><p>通过迭代更新参数w和b，使成本函数$J(w,b)$找到最小值（损失函数和成本函数见2.7）</p><p>梯度下降算法：函数的梯度（gradient）指出了函数的最陡增长方向。梯度的方向走，函数增长得就越快。那么按梯度的负方向走，函数值自然就降低得最快了</p><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/损失函数图.png" alt="损失函数图"></p><p>参数更新：</p><ul><li>$w:=w-\alpha \dfrac{\partial J(w,b)}{\partial w}$</li><li>$b:=b-\alpha \dfrac{\partial J(w,b)}{\partial b}$</li><li>$\alpha$：学习率（Learning Rate），控制参数更新的步长，太大会导致震荡，太小会导致收敛速度慢</li></ul><h3 id="2-3-逻辑回归的梯度下降"><a href="#2-3-逻辑回归的梯度下降" class="headerlink" title="2.3 逻辑回归的梯度下降"></a>2.3 逻辑回归的梯度下降</h3><p>以2维样本 $x_1,x_2$ 为例，参数$w_1,w_2,b$，计算梯度下降</p><p>已知：</p><script type="math/tex; mode=display">\begin{split}&z = w_1x_1+w_2x_2+b \\\\&记 a = \hat{y} = \sigma(z) \\\\&J(a,y) = -y\log(a)-(1-y)\log(1-a) \\\\\end{split}</script><p>计算J对z的导数：</p><script type="math/tex; mode=display">\begin{split}&\frac{\partial J}{\partial a} = \frac{-y}{a}+\frac{1-y}{1-a} \\\\&\frac{\partial a}{\partial z} = a(1-a) \\\\&dz = \frac{\partial J}{\partial a} \cdot \frac{\partial a}{\partial z} = a-y\end{split}</script><p>这样可以求出总损失相对于$w_1,w_2,b$的导数</p><ul><li>$dw_1 = \frac{\partial J}{\partial z} \cdot \frac{\partial z}{\partial w_1} = x_1(a-y)$</li><li>$dw_2 = \frac{\partial J}{\partial z} \cdot \frac{\partial z}{\partial w_2} = x_2(a-y)$</li><li>$db = \frac{\partial J}{\partial z} \cdot \frac{\partial z}{\partial b} = a-y = dz$</li></ul><p>然后更新参数：</p><ul><li>$w_1:=w_1-\alpha dw_1$</li><li>$w_2:=w_2-\alpha dw_1$</li><li>$b:=b-\alpha dw_1$</li></ul><h3 id="2-4-前向传播和反向传播"><a href="#2-4-前向传播和反向传播" class="headerlink" title="2.4 前向传播和反向传播"></a>2.4 前向传播和反向传播</h3><ul><li>前向传播：从前往后计算梯度和损失的过程</li><li>反向传播：从后往前计算参数的更新梯度值</li></ul><h3 id="2-5-向量化-逻辑回归实现"><a href="#2-5-向量化-逻辑回归实现" class="headerlink" title="2.5 向量化/逻辑回归实现"></a>2.5 向量化/逻辑回归实现</h3><p>向量化编程的优点：多样本下，向量计算比循环计算快的多，代码更简洁</p><ol><li>输入层$X$：形状$n \times m$，$n$为特征数，$m$为样本数</li><li>权重参数$W$：形状$n \times 1$</li><li>偏置参数$b$：标量</li><li>输出层$Z$：$Z=W^{T}X+b$，形状$(1,n) \times (n,m) + b = (1,m)$  </li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">n = <span class="number">20</span>  <span class="comment"># 特征数</span></span><br><span class="line">m = <span class="number">100</span>  <span class="comment"># 样本数</span></span><br><span class="line">alpha = <span class="number">0.001</span>  <span class="comment"># 学习率</span></span><br><span class="line">iterations = <span class="number">1000</span>  <span class="comment"># 迭代次数</span></span><br><span class="line"></span><br><span class="line">X = np.random.randn(n, m)  <span class="comment"># 生成特征矩阵</span></span><br><span class="line">Y = np.random.randint(<span class="number">0</span>, <span class="number">2</span>, [<span class="number">1</span>, m])  <span class="comment"># 生成标签</span></span><br><span class="line"></span><br><span class="line">J = <span class="number">0</span>  <span class="comment"># 损失函数值</span></span><br><span class="line"></span><br><span class="line"> 初始化权重和偏置</span><br><span class="line">W = np.random.randn(n, <span class="number">1</span>) * <span class="number">0.01</span></span><br><span class="line">b = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid</span>(<span class="params">t</span>): <span class="comment"># Sigmoid函数</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-t))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">log_loss</span>(<span class="params">A, Y</span>):  <span class="comment"># 对数损失函数</span></span><br><span class="line">    <span class="keyword">return</span> -<span class="number">1</span> / m * np.<span class="built_in">sum</span>(Y * np.log(A) + (<span class="number">1</span> - Y) * np.log(<span class="number">1</span> - A))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calc_accuracy</span>(<span class="params">A, Y</span>):  <span class="comment"># 计算准确率</span></span><br><span class="line">    A = np.where(A &gt; <span class="number">0.5</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> np.mean(A == Y)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(iterations):</span><br><span class="line">    <span class="comment"># 前向传播</span></span><br><span class="line">    Z = np.dot(W.T, X) + b</span><br><span class="line">    A = sigmoid(Z)  <span class="comment"># 激活值（预测）</span></span><br><span class="line">    J = log_loss(A, Y)  <span class="comment"># 计算损失函数值</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 反向传播</span></span><br><span class="line">    <span class="comment"># 计算梯度</span></span><br><span class="line">    dZ = A - Y</span><br><span class="line">    dW = <span class="number">1</span> / m * np.dot(X, dZ.T) <span class="comment"># 1/m * X * dZ</span></span><br><span class="line">    db = <span class="number">1</span> / m * np.<span class="built_in">sum</span>(dZ) <span class="comment"># 1/m * dZ</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 更新权重和偏置</span></span><br><span class="line">    W = W - alpha * dW</span><br><span class="line">    b = b - alpha * db</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Loss:&quot;</span>, J)  <span class="comment"># 打印损失函数值</span></span><br><span class="line"></span><br><span class="line"> 训练集上的准确率</span><br><span class="line">Z = np.dot(W.T, X) + b</span><br><span class="line">A = <span class="number">1</span> / (<span class="number">1</span> + np.exp(-Z))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Accuracy:&quot;</span>, calc_accuracy(A, Y))</span><br></pre></td></tr></table></figure><h3 id="2-6-激活函数（Activation-Function）"><a href="#2-6-激活函数（Activation-Function）" class="headerlink" title="2.6 激活函数（Activation Function）"></a>2.6 激活函数（Activation Function）</h3><p>涉及到网络的优化时候，会有不同的激活函数选择。<br>有一个问题是神经网络的隐藏层和输出单元用什么激活函数。<br>在逻辑回归中选用了Sigmoid函数，但有时其他函数的效果会好得多。<br>大多数结论通过实践得来，没有很好的解释性。</p><p>为什么使用非线性的激活函数：使用线性函数，在这一层上的神经元的输出仅仅是输入的线性组合，失去了效果。</p><script type="math/tex; mode=display">a^{[1]} = W^{[1]}x+b^{[1]}</script><script type="math/tex; mode=display">\begin{align}    b^{[1]} &= W^{[2]}a^{[1]}+b^{[2]} \\\\    &= W^{[2]}(W^{[1]}x+b^{[1]})+b^{[2]} \\\\    &= (W^{[2]}W^{[1]})x+(W^{[2]}b^{[1]}+b^{[2]}) \\\\    &= Wx+b\end{align}</script><p>本节提及的几种常用激活函数：Sigmoid函数、tanH函数、ReLU函数</p><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/激活函数.png" alt="激活函数"></p><p>Sigmoid函数</p><script type="math/tex; mode=display">\begin{split} &\sigma(t)=\dfrac{1}{1+e^{-t}} \\\\&\sigma'(t)=\sigma(t)(1-\sigma(t)) \\\\&t\in(-\infty,+\infty), \sigma(t)\in(0,1)\end{split}</script><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/Sigmoid函数.png" alt="Sigmoid函数"></p><p>双曲正切函数（Hyperbolic Tangent, tanH）</p><p>效果比Sigmoid函数好，因为函数输出在(-1,1)之间，收敛速度更快</p><p>存在和Sigmoid函数一样的缺点：当t趋紧无穷，导数的梯度（即函数的斜率）就趋紧于 0，这使得梯度算法的速度会减慢。</p><script type="math/tex; mode=display">\begin{split} &tanh(t)=\dfrac{e^{t}-e^{-t}}{e^{t}+e^{-t}} \\\\&tanh'(t)=1-tanh^2(t)\end{split}</script><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/tanH函数.png" alt="tanH函数"></p><p>ReLU函数：修正线性单元（Rectified Linear Unit, ReLU）</p><p>当 $t&gt;0$ 时，梯度始终为1，从而提高神经网络基于梯度算法的运算速度，收敛速度远大于Sigmoid和tanH函数</p><script type="math/tex; mode=display">\begin{split}&f(t)=max(0,t) \\\\&f'(t)=\begin{cases}0 & \text{if } t<0 \\\\1 & \text{if } t \geq 0\end{cases}\end{split}</script><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/ReLU函数.png" alt="ReLU函数"></p><h3 id="2-7-损失函数（Loss-Function）与成本函数（Cost-Function）"><a href="#2-7-损失函数（Loss-Function）与成本函数（Cost-Function）" class="headerlink" title="2.7 损失函数（Loss Function）与成本函数（Cost Function）"></a>2.7 损失函数（Loss Function）与成本函数（Cost Function）</h3><p>损失函数用于衡量预测结果与真实值之间的误差。</p><p>平方差损失函数：$L(\hat{y},y)=\frac{1}{2}(\hat{y}-y)^2$</p><ul><li>最简单的损失函数</li><li>具有多个局部最小值，不适合逻辑回归</li></ul><p>对数损失函数：$L(\hat{y},y)=-(y\log(\hat{y})+(1-y)\log(1-\hat{y}))$</p><ul><li>逻辑回归通常采用的损失函数</li><li>y=1时，损失函数为$-log(\hat{y})$，$\hat{y}$越大，损失越小</li><li>y=0时，损失函数为$log(1-\hat{y})$，$\hat{y}$越小，损失越小</li></ul><p>损失函数：衡量了在单个训练样本上的表现</p><p>成本函数（Cost Function）：$J(w,b)=\dfrac{1}{m}\sum\limits_{i=1}^{m}L(\hat{y}^{(i)},y^{(i)})$</p><ul><li>所有训练样本的损失平均值</li><li>衡量在全体训练样本上的表现、参数w和b的效果</li></ul><h2 id="三、浅层神经网络"><a href="#三、浅层神经网络" class="headerlink" title="三、浅层神经网络"></a>三、浅层神经网络</h2><h3 id="3-1-浅层神经网络"><a href="#3-1-浅层神经网络" class="headerlink" title="3.1 浅层神经网络"></a>3.1 浅层神经网络</h3><p>神经网络（Neural Network, NN）是一种模拟人脑神经元工作方式的计算模型，包含输入层、隐藏层、输出层，每层包含多个神经元</p><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/浅层神经网络.png" alt="浅层神经网络"></p><p>以上图（单隐藏层神经网络）为例，输入层有$n=3$个特征，隐藏层一层，有$4$个神经元。记隐藏层 $[1]$ ，输出层 $[2]$ ，则：</p><ul><li>输入层：$x \in R^{3}$，$x$是一个$3$维的特征向量<ul><li>形状：(3, m)，$m$为样本数</li></ul></li><li>隐藏层具有4行3列的权重矩阵$W^{[1]} \in R^{4 \times 3}$，偏置向量$b^{[1]} \in R^{4}$<ul><li>隐藏层的每个神经元$i$具有权重$W^{[1]}<em>{i} \in R^{3}$，偏置$b^{[1]}</em>{i} \in R$</li><li>形状：输入(3, m) * 权重(4, 3) + 偏置(4, 1) = 输出(4, m)</li></ul></li><li>输出层具有1行4列的权重矩阵$W^{[2]} \in R^{1 \times 4}$，偏置$b^{[2]} \in R$<ul><li>形状：输入(4, m) * 权重(1, 4) + 偏置(1, 1) = 输出(1, m)、</li></ul></li></ul><p>总结：第i层的权重矩阵$W^{[i]}$的形状为$(n^{[i]}, n^{[i-1]})$，偏置$b^{[i]}$的形状为$(n^{[i]}, 1)$</p><h3 id="3-2-前向传播"><a href="#3-2-前向传播" class="headerlink" title="3.2 前向传播"></a>3.2 前向传播</h3><script type="math/tex; mode=display">\begin{split}&Z^{[1]} = W^{[1]}X+b^{[1]} \\\\&A^{[1]} = tanh(Z^{[1]}) \\\\&Z^{[2]} = W^{[2]}A^{[1]}+b^{[2]} \\\\&A^{[2]} = \sigma(Z^{[2]})\end{split}</script><h3 id="3-3-反向传播"><a href="#3-3-反向传播" class="headerlink" title="3.3 反向传播"></a>3.3 反向传播</h3><p>输出层以Sigmoid函数作为激活函数，根据<a href="#14-逻辑回归的梯度下降">逻辑回归的梯度下降</a>的推导，可以得到：</p><script type="math/tex; mode=display">\begin{split}&dZ^{[2]} = A^{[2]}-Y \\\\&dW^{[2]} = \dfrac{1}{m}dZ^{[2]}A^{[1]T} \\\\&db^{[2]} = \dfrac{1}{m}np.sum(dZ^{[2]}, axis=1)\end{split}</script><p>隐藏层以tanh函数作为激活函数，已知：</p><script type="math/tex; mode=display">\begin{split}&tanh'(t) = 1-tanh^2(t) \\\\&Z^{[1]} = W^{[1]}X+b^{[1]} \\\\&A^{[1]} = tanh(Z^{[1]}) \\\\&J(A^{[2]},Y) = -Y\log(A^{[2]})-(1-Y)\log(1-A^{[2]})\end{split}</script><p>根据链式求导法则（步骤略），可以得到：</p><script type="math/tex; mode=display">\begin{split}&dZ^{[1]} = \frac{\partial J}{\partial A^{[2]}} \cdot \frac{\partial A^{[2]}}{\partial Z^{[2]}} \cdot \frac{\partial Z^{[2]}}{\partial A^{[1]}} \cdot \frac{\partial A^{[1]}}{\partial Z^{[1]}} = W^{[2]T}dZ^{[2]} \cdot (1-A^{[1]2}) \\\\&dW^{[1]} = \dfrac{1}{m}dZ^{[1]}X^T \\\\&db^{[1]} = \dfrac{1}{m}np.sum(dZ^{[1]}, axis=1)\end{split}</script><h3 id="实践：浅层神经网络实现"><a href="#实践：浅层神经网络实现" class="headerlink" title="实践：浅层神经网络实现"></a>实践：浅层神经网络实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">n = <span class="number">20</span>  <span class="comment"># 特征数</span></span><br><span class="line">m = <span class="number">100</span>  <span class="comment"># 样本数</span></span><br><span class="line">k = <span class="number">4</span>  <span class="comment"># 隐藏层神经元数</span></span><br><span class="line">alpha = <span class="number">0.001</span>  <span class="comment"># 学习率</span></span><br><span class="line">iterations = <span class="number">1000</span>  <span class="comment"># 迭代次数</span></span><br><span class="line"></span><br><span class="line">X = np.random.randn(n, m)  <span class="comment"># 生成特征矩阵</span></span><br><span class="line">Y = np.random.randint(<span class="number">0</span>, <span class="number">2</span>, [<span class="number">1</span>, m])  <span class="comment"># 生成标签</span></span><br><span class="line"></span><br><span class="line">J = <span class="number">0</span>  <span class="comment"># 损失函数值</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 隐藏层权重和偏置（随机初始化）</span></span><br><span class="line">W1 = np.random.randn(k, n) * <span class="number">0.01</span></span><br><span class="line">b1 = np.zeros([k, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出层权重和偏置</span></span><br><span class="line">W2 = np.random.randn(<span class="number">1</span>, k) * <span class="number">0.01</span></span><br><span class="line">b2 = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid</span>(<span class="params">t</span>): <span class="comment"># Sigmoid函数</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-t))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">tanh</span>(<span class="params">t</span>): <span class="comment"># tanH函数</span></span><br><span class="line">    <span class="keyword">return</span> (np.exp(t) - np.exp(-t)) / (np.exp(t) + np.exp(-t))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">log_loss</span>(<span class="params">A, Y</span>):  <span class="comment"># 对数损失函数</span></span><br><span class="line">    <span class="keyword">return</span> -<span class="number">1</span> / m * np.<span class="built_in">sum</span>(Y * np.log(A) + (<span class="number">1</span> - Y) * np.log(<span class="number">1</span> - A))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calc_accuracy</span>(<span class="params">A, Y</span>):  <span class="comment"># 计算准确率</span></span><br><span class="line">    A = np.where(A &gt; <span class="number">0.5</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> np.mean(A == Y)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(iterations):</span><br><span class="line">    <span class="comment"># 前向传播</span></span><br><span class="line">    Z1 = np.dot(W1, X) + b1 <span class="comment"># [k, m]</span></span><br><span class="line">    A1 = tanh(Z1)  <span class="comment"># 隐藏层激活值 [k, m]</span></span><br><span class="line">    Z2 = np.dot(W2, A1) + b2 <span class="comment"># [1, m]</span></span><br><span class="line">    A2 = sigmoid(Z2)  <span class="comment"># 输出层激活值（预测） [1, m]</span></span><br><span class="line">    J = log_loss(A2, Y)  <span class="comment"># 计算损失函数值 </span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 反向传播</span></span><br><span class="line">    <span class="comment"># 输出层</span></span><br><span class="line">    dZ2 = A2 - Y <span class="comment"># [1, m]</span></span><br><span class="line">    dW2 = <span class="number">1</span> / m * np.dot(dZ2, A1.T) <span class="comment"># [1, k]</span></span><br><span class="line">    db2 = <span class="number">1</span> / m * np.<span class="built_in">sum</span>(dZ2) <span class="comment"># [1, 1]</span></span><br><span class="line">    <span class="comment"># 隐藏层</span></span><br><span class="line">    dZ1 = np.dot(W2.T, dZ2) * (<span class="number">1</span> - A1 ** <span class="number">2</span>)</span><br><span class="line">    dW1 = <span class="number">1</span> / m * np.dot(dZ1, X.T)</span><br><span class="line">    db1 = <span class="number">1</span> / m * np.<span class="built_in">sum</span>(dZ1)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 更新权重和偏置</span></span><br><span class="line">    W1 = W1 - alpha * dW1</span><br><span class="line">    b1 = b1 - alpha * db1</span><br><span class="line">    W2 = W2 - alpha * dW2</span><br><span class="line">    b2 = b2 - alpha * db2</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Loss:&quot;</span>, J)  <span class="comment"># 打印损失函数值</span></span><br><span class="line"></span><br><span class="line"> 训练集上的准确率</span><br><span class="line">Z1 = np.dot(W1, X) + b1</span><br><span class="line">A1 = tanh(Z1)</span><br><span class="line">Z2 = np.dot(W2, A1) + b2</span><br><span class="line">A2 = <span class="number">1</span> / (<span class="number">1</span> + np.exp(-Z2))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Accuracy:&quot;</span>, calc_accuracy(A2, Y))</span><br></pre></td></tr></table></figure><h2 id="四、深层神经网络"><a href="#四、深层神经网络" class="headerlink" title="四、深层神经网络"></a>四、深层神经网络</h2><h3 id="4-1-深层神经网络"><a href="#4-1-深层神经网络" class="headerlink" title="4.1 深层神经网络"></a>4.1 深层神经网络</h3><p>为什么需要深层神经网络：</p><ul><li>神经网络从第一层开始，从原始数据中提取特征</li><li>下一层将上一层习得的信息组合起来，形成更高级的特征</li><li>随着层数增多，特征从简单到复杂，学习的能力更强</li></ul><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/深层神经网络.jpeg" alt="深层神经网络"> </p><h3 id="4-2-前向传播"><a href="#4-2-前向传播" class="headerlink" title="4.2 前向传播"></a>4.2 前向传播</h3><script type="math/tex; mode=display">\begin{split}&x=a^{[0]} \\\\&z^{[L]}=W^{[L]}a^{[L-1]}+b^{[L]} \\\\&a^{[L]}=g^{[L]}(z^{[L]})\end{split}</script><p>输入$a^{[L-1]}$，输出$a^{[L]}$</p><h3 id="4-3-反向传播"><a href="#4-3-反向传播" class="headerlink" title="4.3 反向传播"></a>4.3 反向传播</h3><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/深层神经网络反向传播.png" alt="深层神经网络反向传播"></p><script type="math/tex; mode=display">\begin{split}&dZ^{[L]} = \frac{\partial J}{\partial A^{[L]}} \cdot \frac{\partial A^{[L]}}{\partial Z^{[L]}} = dA^{[L]} \cdot g^{[L]'}(Z^{[L]}) \\\\&dW^{[L]} = \frac{\partial J}{\partial Z^{[L]}} \cdot \frac{\partial Z^{[L]}}{\partial W^{[L]}} = \frac{1}{m}dZ^{[L]}A^{[L-1]T} \\\\&db^{[L]} = \frac{1}{m}np.sum(dZ^{[L]}, axis=1) \\\\&dA^{[L]} = W^{[L+1]T}dZ^{[L+1]}\end{split}</script><h3 id="4-4-参数和超参数"><a href="#4-4-参数和超参数" class="headerlink" title="4.4 参数和超参数"></a>4.4 参数和超参数</h3><p>参数（Parameters）：在训练过程中希望模型学习到的信息，模型自己调整的参数</p><ul><li>权重W通常使用随机初始化，避免对称性，$randn*0.01$<ul><li>对称性：如果所有的神经元都具有相同的权重，那么在反向传播过程中，所有的神经元都会学习到相同的特征</li><li>乘系数0.01：使用Sigmoid函数或者tanH函数作为激活函数时，W比较小，则Z=WX+b所得的值趋近于0，梯度较大，能够提高算法的更新速度；ReLU函数则没有这个问题</li></ul></li><li>偏置b没有对称性问题，通常初始化为0</li></ul><p>超参数（Hyper parameters）：通过人的经验判断、手动调整的网络信息，会影响最终的参数</p><ul><li>典型的超参数：学习速率$\alpha$、迭代次数$N$、隐藏层数$L$、每层神经元数$n_i$、激活函数$g^{[i]}()$的选择</li><li>开发新应用时，很难预先准确知道最佳的超参数，需要通过不同的尝试和调整来找到最佳的超参数</li></ul><h2 id="五、多分类与Softmax回归"><a href="#五、多分类与Softmax回归" class="headerlink" title="五、多分类与Softmax回归"></a>五、多分类与Softmax回归</h2><h3 id="5-1-Softmax回归"><a href="#5-1-Softmax回归" class="headerlink" title="5.1 Softmax回归"></a>5.1 Softmax回归</h3><p>对于多分类问题，种类个数C，则输出层的神经元个数必须为C，每个神经元的输出依次对应为每个类别的概率。</p><p><img src="https://source.cclmsy.cc/posts/notes/deep_learning/多分类问题.png" alt="多分类问题"></p><p>输出层：$Z^{[L]}=W^{[L]}A^{[L-1]}+b^{[L]}$$</p><p>Softmax公式：$a<em>i^{[L]} = \dfrac{e^{Z_i^{[L]}}}{\sum\limits</em>{j=1}^{C}e^{Z<em>j^{[L]}}}$，满足$\sum\limits</em>{i=1}^{C}a_i^{[L]}=1$</p><p>理解：$e^{z_i}$的占比</p><h3 id="5-2-交叉熵损失与One-hot编码"><a href="#5-2-交叉熵损失与One-hot编码" class="headerlink" title="5.2 交叉熵损失与One-hot编码"></a>5.2 交叉熵损失与One-hot编码</h3><p>对于Softmax回归，使用交叉熵损失（Cross Entropy Loss）函数：</p><script type="math/tex; mode=display">L(\hat{y},y)=-\sum\limits_{i=1}^{C}y_i\log(\hat{y}_i)</script><p>$C=2$时，即对应逻辑回归的对数损失函数$L(\hat{y},y)=-(y\log(\hat{y})+(1-y)\log(1-\hat{y}))$</p><p>one-hot编码（独热编码）：将标签转换为向量，只有一个元素为1，其他元素为0。</p><p>以图2.1.1为例，$y=7$，则one-hot编码对应为$y=[0,0,0,0,0,0,0,1,0,0]$。</p><p>由于除了正确类别外，其他类别$y_i=0$，因此可以简单计算交叉熵：$L(\hat{y},y)=-1\times\log(0.10)$</p><p>这一项的预测值越接近1，交叉熵越接近0，模型效果越好</p>]]></content>
    
    
    <summary type="html">深度学习基础、从浅层网络到深层网络</summary>
    
    
    
    <category term="DL笔记" scheme="https://www.cclmsy.cc/categories/DL%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="深度学习" scheme="https://www.cclmsy.cc/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="神经网络" scheme="https://www.cclmsy.cc/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>ST表</title>
    <link href="https://www.cclmsy.cc/posts/st.html"/>
    <id>https://www.cclmsy.cc/posts/st.html</id>
    <published>2025-02-07T16:00:00.000Z</published>
    <updated>2025-07-18T11:14:52.562Z</updated>
    
    <content type="html"><![CDATA[<h2 id="ST表"><a href="#ST表" class="headerlink" title="ST表"></a>ST表</h2><p>实现的功能：固定数组询问区间最值RMQ/区间GCD</p><p>原数组v下标从0开始；ST表下标从1开始，首元素为0</p><p>洛谷模板题：<a href="https://www.luogu.com.cn/problem/P3865">Luogu P3865</a></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;bits/stdc++.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> int long long</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> endl <span class="string">&#x27;\n&#x27;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// ST表</span></span><br><span class="line"><span class="comment">// 实现的功能：固定数组 区间最值询问RMQ/区间GCD</span></span><br><span class="line"><span class="comment">// 下标从0开始</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">SparseTable</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> n;</span><br><span class="line">    vector&lt;T&gt; a; <span class="comment">// 原数组</span></span><br><span class="line">    vector&lt;vector&lt;T&gt;&gt; st; <span class="comment">// st[i][j]表示[i,i+2^j-1]的最值</span></span><br><span class="line">    <span class="function">T <span class="title">op</span><span class="params">(<span class="type">const</span> T &amp;a, <span class="type">const</span> T &amp;b)</span> </span>&#123; <span class="keyword">return</span> <span class="built_in">max</span>(a, b); &#125; <span class="comment">// 可选：max,min,__gcd</span></span><br><span class="line">    <span class="built_in">SparseTable</span>(vector&lt;T&gt; _v)&#123;</span><br><span class="line">        a = _v;</span><br><span class="line">        n = a.<span class="built_in">size</span>();</span><br><span class="line">        st.<span class="built_in">resize</span>(n+<span class="number">5</span>);</span><br><span class="line">        <span class="type">int</span> len = <span class="built_in">log2</span>(n)+<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i=<span class="number">0</span>; i&lt;n; i++) st[i].<span class="built_in">resize</span>(<span class="number">21</span>, <span class="number">0</span>); <span class="comment">// n&lt;=2e6开21</span></span><br><span class="line">        <span class="built_in">solve</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">solve</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) st[i][<span class="number">0</span>] = a[i];</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">1</span>; (<span class="number">1</span> &lt;&lt; j) &lt;= n; j++)&#123;</span><br><span class="line">            <span class="type">int</span> len = (<span class="number">1</span> &lt;&lt; j);</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i + len - <span class="number">1</span> &lt; n; i++)&#123;</span><br><span class="line">                st[i][j] = <span class="built_in">op</span>(st[i][j - <span class="number">1</span>], st[i + (<span class="number">1</span> &lt;&lt; (j - <span class="number">1</span>))][j - <span class="number">1</span>]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">T <span class="title">query</span><span class="params">(<span class="type">int</span> l, <span class="type">int</span> r)</span></span>&#123;</span><br><span class="line">        <span class="type">int</span> j = <span class="built_in">log2</span>(r - l + <span class="number">1</span>);<span class="comment">//已向下取整</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">op</span>(st[l][j], st[r - (<span class="number">1</span> &lt;&lt; j) + <span class="number">1</span>][j]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">signed</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    ios::<span class="built_in">sync_with_stdio</span>(<span class="literal">false</span>);</span><br><span class="line">    cin.<span class="built_in">tie</span>(<span class="number">0</span>); cout.<span class="built_in">tie</span>(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> n, q;</span><br><span class="line">    cin &gt;&gt; n &gt;&gt; q;</span><br><span class="line">    <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">v</span><span class="params">(n)</span></span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span> &amp;i : v) cin &gt;&gt; i;</span><br><span class="line">    <span class="function">SparseTable&lt;<span class="type">int</span>&gt; <span class="title">st</span><span class="params">(v)</span></span>;</span><br><span class="line">    <span class="keyword">while</span> (q--)&#123;</span><br><span class="line">        <span class="type">int</span> l, r;</span><br><span class="line">        cin &gt;&gt; l &gt;&gt; r;</span><br><span class="line">        cout &lt;&lt; st.<span class="built_in">query</span>(l<span class="number">-1</span>, r<span class="number">-1</span>) &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">求区间最大/最小/GCD</summary>
    
    
    
    <category term="算法模板" scheme="https://www.cclmsy.cc/categories/%E7%AE%97%E6%B3%95%E6%A8%A1%E6%9D%BF/"/>
    
    
    <category term="算法模板" scheme="https://www.cclmsy.cc/tags/%E7%AE%97%E6%B3%95%E6%A8%A1%E6%9D%BF/"/>
    
    <category term="数据结构" scheme="https://www.cclmsy.cc/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>AC自动机</title>
    <link href="https://www.cclmsy.cc/posts/ac_auto.html"/>
    <id>https://www.cclmsy.cc/posts/ac_auto.html</id>
    <published>2025-01-21T16:00:00.000Z</published>
    <updated>2025-07-18T11:14:52.108Z</updated>
    
    <content type="html"><![CDATA[<h2 id="AC自动机"><a href="#AC自动机" class="headerlink" title="AC自动机"></a>AC自动机</h2><p>解决的问题：<strong>写题自动AC</strong>统计多个模式串在主串中出现的次数</p><p>M(26)*N(2e5)-&gt;Luogu150ms/60MB</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;bits/stdc++.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="keyword">typedef</span> <span class="type">long</span> ll;</span><br><span class="line"><span class="comment">//字符转换为数字，以全62字符为例，根据题意修改</span></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">int</span> <span class="title">trans</span><span class="params">(<span class="type">char</span> c)</span></span>&#123; </span><br><span class="line">    <span class="keyword">if</span>(c&gt;=<span class="string">&#x27;a&#x27;</span>&amp;&amp;c&lt;=<span class="string">&#x27;z&#x27;</span>) <span class="keyword">return</span> c-<span class="string">&#x27;a&#x27;</span>;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(c&gt;=<span class="string">&#x27;A&#x27;</span>&amp;&amp;c&lt;=<span class="string">&#x27;Z&#x27;</span>) <span class="keyword">return</span> c-<span class="string">&#x27;A&#x27;</span>+<span class="number">26</span>;</span><br><span class="line">    <span class="keyword">return</span> c-<span class="string">&#x27;0&#x27;</span>+<span class="number">52</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">const</span> ll N = <span class="number">2e5</span>+<span class="number">5</span>; <span class="comment">//（本题单个数据）**字典**字符串最大总长度</span></span><br><span class="line"><span class="type">const</span> ll M = <span class="number">26</span>; <span class="comment">//字符集大小</span></span><br><span class="line"><span class="comment">// AC自动机</span></span><br><span class="line"><span class="comment">// 解决的问题：统计多个模式串在主串中出现的次数</span></span><br><span class="line"><span class="comment">// M(26)*N(2e5)-&gt;Luogu150ms/60MB</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">ACauto</span>&#123;</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">Node</span>&#123;</span><br><span class="line">        ll  nxt[M], <span class="comment">//经过字符边到达的下一状态</span></span><br><span class="line">            fail, <span class="comment">//失配指针</span></span><br><span class="line">            flag, <span class="comment">//flag</span></span><br><span class="line">            ans, <span class="comment">//临时答案</span></span><br><span class="line">            rev, <span class="comment">//反向flag</span></span><br><span class="line">            indeg, <span class="comment">//入度</span></span><br><span class="line">            cnt; <span class="comment">//出现的次数</span></span><br><span class="line">        <span class="built_in">Node</span>():nxt&#123;<span class="number">0</span>&#125;,<span class="built_in">fail</span>(<span class="number">0</span>),<span class="built_in">flag</span>(<span class="number">0</span>),<span class="built_in">ans</span>(<span class="number">0</span>),<span class="built_in">rev</span>(<span class="number">0</span>),<span class="built_in">indeg</span>(<span class="number">0</span>),<span class="built_in">cnt</span>(<span class="number">0</span>)&#123;&#125;</span><br><span class="line">        <span class="function"><span class="type">void</span> <span class="title">clear</span><span class="params">()</span></span>&#123;</span><br><span class="line">            <span class="built_in">memset</span>(nxt,<span class="number">0</span>,<span class="built_in">sizeof</span>(nxt));</span><br><span class="line">            fail=flag=ans=rev=indeg=cnt=<span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;trie[N]; <span class="comment">//trie树</span></span><br><span class="line">    ll curn,cnts; <span class="comment">//curn是当前节点数，cnts是模式串个数</span></span><br><span class="line">    <span class="built_in">ACauto</span>():<span class="built_in">curn</span>(<span class="number">0</span>),<span class="built_in">cnts</span>(<span class="number">0</span>)&#123;&#125;</span><br><span class="line">    <span class="comment">// 重置AC自动机</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">clear</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">for</span>(ll i=<span class="number">0</span>;i&lt;=curn;i++) trie[i].<span class="built_in">clear</span>();</span><br><span class="line">        <span class="keyword">for</span>(ll i=<span class="number">1</span>;i&lt;N;i++) trie[i].cnt=<span class="number">0</span>;</span><br><span class="line">        curn=<span class="number">1</span>; cnts=<span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 加入模式串s，编号为num</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">insert</span><span class="params">(string s,ll num)</span></span>&#123;</span><br><span class="line">        ll u=<span class="number">1</span>,len=s.<span class="built_in">length</span>();</span><br><span class="line">        <span class="keyword">for</span>(ll i=<span class="number">0</span>;i&lt;len;i++)&#123;</span><br><span class="line">            ll v=<span class="built_in">trans</span>(s[i]);</span><br><span class="line">            <span class="keyword">if</span>(!trie[u].nxt[v]) trie[u].nxt[v]=++curn;</span><br><span class="line">            u=trie[u].nxt[v];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(!trie[u].flag) trie[u].flag=num;</span><br><span class="line">        trie[num].rev=trie[u].flag;</span><br><span class="line">        cnts++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 构造失配指针</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">getfail</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">for</span>(ll i=<span class="number">0</span>;i&lt;M;i++) trie[<span class="number">0</span>].nxt[i]=<span class="number">1</span>;</span><br><span class="line">        queue&lt;ll&gt; q; q.<span class="built_in">push</span>(<span class="number">1</span>);</span><br><span class="line">        trie[<span class="number">1</span>].fail=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(!q.<span class="built_in">empty</span>())&#123;</span><br><span class="line">            ll u=q.<span class="built_in">front</span>();</span><br><span class="line">            q.<span class="built_in">pop</span>();</span><br><span class="line">            ll Fail=trie[u].fail;</span><br><span class="line">            <span class="keyword">for</span>(ll i=<span class="number">0</span>;i&lt;M;i++)&#123;</span><br><span class="line">                ll v=trie[u].nxt[i];</span><br><span class="line">                <span class="keyword">if</span>(!v)&#123;</span><br><span class="line">                    trie[u].nxt[i]=trie[Fail].nxt[i];</span><br><span class="line">                    <span class="keyword">continue</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                trie[v].fail=trie[Fail].nxt[i];</span><br><span class="line">                trie[trie[Fail].nxt[i]].indeg++;</span><br><span class="line">                q.<span class="built_in">push</span>(v);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 拓扑排序优化建图</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">topu</span><span class="params">()</span></span>&#123;</span><br><span class="line">        queue&lt;ll&gt; q;</span><br><span class="line">        <span class="keyword">for</span>(ll i=<span class="number">1</span>;i&lt;=curn;i++)</span><br><span class="line">            <span class="keyword">if</span>(!trie[i].indeg) q.<span class="built_in">push</span>(i);</span><br><span class="line">        <span class="keyword">while</span>(!q.<span class="built_in">empty</span>())&#123;</span><br><span class="line">            ll fr=q.<span class="built_in">front</span>();</span><br><span class="line">            q.<span class="built_in">pop</span>();</span><br><span class="line">            trie[trie[fr].flag].cnt=trie[fr].ans;</span><br><span class="line">            ll u=trie[fr].fail;</span><br><span class="line">            trie[u].ans+=trie[fr].ans;</span><br><span class="line">            trie[u].indeg--;</span><br><span class="line">            <span class="keyword">if</span>(!trie[u].indeg) q.<span class="built_in">push</span>(u);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 在主串s中匹配模式串</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">solve</span><span class="params">(string s)</span></span>&#123;</span><br><span class="line">        <span class="built_in">getfail</span>();</span><br><span class="line">        ll u=<span class="number">1</span>,len=s.<span class="built_in">length</span>();</span><br><span class="line">        <span class="keyword">for</span>(ll i=<span class="number">0</span>;i&lt;len;i++)&#123;</span><br><span class="line">            ll v=<span class="built_in">trans</span>(s[i]);</span><br><span class="line">            u=trie[u].nxt[v];</span><br><span class="line">            trie[u].ans++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">topu</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// O(1)查询编号为idx的模式串出现的次数</span></span><br><span class="line">    <span class="function">ll <span class="title">query</span><span class="params">(ll idx)</span></span>&#123; <span class="keyword">return</span> trie[trie[idx].rev].cnt; &#125;</span><br><span class="line">    <span class="comment">// 查询出现过的模式串个数</span></span><br><span class="line">    <span class="function">ll <span class="title">count</span><span class="params">()</span></span>&#123;</span><br><span class="line">        ll ret=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(ll i=<span class="number">1</span>;i&lt;=curn;i++) </span><br><span class="line">            <span class="keyword">if</span>(<span class="built_in">query</span>(i)) ret++;</span><br><span class="line">        <span class="keyword">return</span> ret;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;ac;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">solve</span><span class="params">()</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    ll n; cin &gt;&gt; n;</span><br><span class="line">    ac.<span class="built_in">clear</span>();</span><br><span class="line">    <span class="function">vector&lt;string&gt; <span class="title">s</span><span class="params">(n+<span class="number">1</span>)</span></span>;</span><br><span class="line">    string ts;</span><br><span class="line">    <span class="keyword">for</span>(ll i=<span class="number">1</span>;i&lt;=n;i++)&#123;</span><br><span class="line">        cin &gt;&gt; ts;</span><br><span class="line">        ac.<span class="built_in">insert</span>(ts,i);</span><br><span class="line">        s[i]=ts;</span><br><span class="line">    &#125;</span><br><span class="line">    cin &gt;&gt; ts;</span><br><span class="line">    ac.<span class="built_in">solve</span>(ts);</span><br><span class="line">    <span class="comment">// Luogu P5357</span></span><br><span class="line">    <span class="keyword">for</span>(ll i=<span class="number">1</span>;i&lt;=n;i++) cout &lt;&lt; ac.<span class="built_in">query</span>(i) &lt;&lt; endl;</span><br><span class="line">    <span class="comment">// Luogu P3808</span></span><br><span class="line">    <span class="comment">// cout &lt;&lt; ac.count() &lt;&lt; endl;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/*----------Code Area----------*/</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    ios::<span class="built_in">sync_with_stdio</span>(<span class="literal">false</span>);</span><br><span class="line">    cin.<span class="built_in">tie</span>(<span class="number">0</span>);</span><br><span class="line">    cout.<span class="built_in">tie</span>(<span class="number">0</span>);</span><br><span class="line">    </span><br><span class="line">    ll T=<span class="number">1</span>; <span class="comment">// cin &gt;&gt; T;</span></span><br><span class="line">    <span class="keyword">while</span>(T--) <span class="built_in">solve</span>();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">统计多个模式串在主串中出现的次数</summary>
    
    
    
    <category term="算法模板" scheme="https://www.cclmsy.cc/categories/%E7%AE%97%E6%B3%95%E6%A8%A1%E6%9D%BF/"/>
    
    
    <category term="算法模板" scheme="https://www.cclmsy.cc/tags/%E7%AE%97%E6%B3%95%E6%A8%A1%E6%9D%BF/"/>
    
    <category term="数据结构" scheme="https://www.cclmsy.cc/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    <category term="字符串" scheme="https://www.cclmsy.cc/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"/>
    
  </entry>
  
  <entry>
    <title>Python对拍器</title>
    <link href="https://www.cclmsy.cc/posts/python_check.html"/>
    <id>https://www.cclmsy.cc/posts/python_check.html</id>
    <published>2025-01-09T16:00:00.000Z</published>
    <updated>2025-07-18T11:14:52.548Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Python对拍器"><a href="#Python对拍器" class="headerlink" title="Python对拍器"></a>Python对拍器</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对拍器</span></span><br><span class="line"><span class="comment"># 用gen.cpp生成数据，用std.cpp生成标准答案，用test.cpp生成测试答案，用check.py对拍</span></span><br><span class="line"><span class="comment"># 所有文件都在同一文件夹下</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 一直循环，直到对拍出错</span></span><br><span class="line"><span class="comment"># 正确输出：#序号 Accepted</span></span><br><span class="line"><span class="comment"># 错误输出：#序号 Wrong Answer!!</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment"># 不含后缀的文件名</span></span><br><span class="line">filename_mycode = <span class="string">&#x27;test&#x27;</span> <span class="comment"># 测试代码</span></span><br><span class="line">filename_std = <span class="string">&#x27;std&#x27;</span> <span class="comment"># 标准答案</span></span><br><span class="line">filename_generate = <span class="string">&#x27;gen&#x27;</span> <span class="comment"># 生成数据</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 确认文件存在，否则报错</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">checkfile</span>(<span class="params">filename</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Checking&#x27;</span>, filename)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(filename):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;File not found:&#x27;</span>, filename)</span><br><span class="line">        exit(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">checkfile(filename_mycode + <span class="string">&#x27;.cpp&#x27;</span>)</span><br><span class="line">checkfile(filename_std + <span class="string">&#x27;.cpp&#x27;</span>)</span><br><span class="line">checkfile(filename_generate + <span class="string">&#x27;.cpp&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编译</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compile</span>(<span class="params">filename</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Compiling&#x27;</span>, filename)</span><br><span class="line">    os.system(<span class="string">&#x27;g++ &#x27;</span> + filename + <span class="string">&#x27;.cpp -o &#x27;</span> + filename )</span><br><span class="line"></span><br><span class="line"><span class="built_in">compile</span>(filename_mycode)</span><br><span class="line"><span class="built_in">compile</span>(filename_std)</span><br><span class="line"><span class="built_in">compile</span>(filename_generate)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成数据和答案</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate</span>():</span><br><span class="line">    os.system(<span class="string">&#x27;.\\&#x27;</span> + filename_generate + <span class="string">&#x27; &gt; in.txt&#x27;</span>)</span><br><span class="line">    os.system(<span class="string">&#x27;.\\&#x27;</span> + filename_std + <span class="string">&#x27; &lt; in.txt &gt; std.txt&#x27;</span>)</span><br><span class="line">    os.system(<span class="string">&#x27;.\\&#x27;</span> + filename_mycode + <span class="string">&#x27; &lt; in.txt &gt; out.txt&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 比较2个文件是否相同，不同则返回行列号</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compare</span>(<span class="params">file1, file2</span>):</span><br><span class="line">    f1 = <span class="built_in">open</span>(file1, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">    f2 = <span class="built_in">open</span>(file2, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">    lines1 = f1.readlines()</span><br><span class="line">    lines2 = f2.readlines()</span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">len</span>(lines1) != <span class="built_in">len</span>(lines2)):</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span>, <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(lines1)):</span><br><span class="line">        obj1 = lines1[i].split()</span><br><span class="line">        obj2 = lines2[i].split()</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(obj1) != <span class="built_in">len</span>(obj2):</span><br><span class="line">            <span class="keyword">return</span> i, lines1[i], lines2[i]</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(obj1)):</span><br><span class="line">            <span class="keyword">if</span> obj1[j] != obj2[j]:</span><br><span class="line">                <span class="keyword">return</span> i, obj1[j], obj2[j]</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>, <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对拍</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">check</span>():</span><br><span class="line">    i = <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        generate()</span><br><span class="line">        line, line1, line2 = compare(<span class="string">&#x27;std.txt&#x27;</span>, <span class="string">&#x27;out.txt&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> line == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;#&#x27;</span>, i, <span class="string">&#x27;Accepted&#x27;</span>)</span><br><span class="line">        <span class="keyword">elif</span> line == -<span class="number">1</span>: <span class="comment"># 行数不同</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;#&#x27;</span>, i, <span class="string">&#x27;Wrong Answer!!&#x27;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Line:&#x27;</span>, <span class="string">&#x27;Different number of lines&#x27;</span>) </span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">else</span>: <span class="comment"># 内容不同</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;#&#x27;</span>, i, <span class="string">&#x27;Wrong Answer!!&#x27;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Line:&#x27;</span>, line)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Standard:&#x27;</span>, line1)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Output:&#x27;</span>, line2)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">check()</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">生成数据，将代码和暴力算法比较</summary>
    
    
    
    <category term="算法模板" scheme="https://www.cclmsy.cc/categories/%E7%AE%97%E6%B3%95%E6%A8%A1%E6%9D%BF/"/>
    
    
    <category term="算法模板" scheme="https://www.cclmsy.cc/tags/%E7%AE%97%E6%B3%95%E6%A8%A1%E6%9D%BF/"/>
    
  </entry>
  
</feed>
